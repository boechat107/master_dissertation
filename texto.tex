\chapter{Introdução}

Na indústria petrolífera, o emprego de sensores nos poços de produção possui papel
fundamental tanto na segurança quanto no desempenho das operações. Os dados coletados
fornecem medidas das condições de funcionamento de equipamentos e de parâmetros
diretamente relacionados com as ações de controle, otimização da produção e monitoramento.
O operador da planta interpreta as medições baseado na sua experiência e conhecimento do
sistema, e toma decisões que podem ser cruciais durante situações de emergência.
Entretanto, devido às condições degradantes a que ficam submetidos, os sensores de poços
normalmente apresentam algum tipo de falha ou \textit{drift} (desvio nas medidas) durante
o período produtivo de um poço. Trocas ou reparos desses sensores raramente ocorrem, mesmo
quando se sabe que as medições estão incorretas, uma vez que possuem difícil acesso e alto
custo de manutenção \cite{Davies2007}, principalmente em plataformas \textit{offshore}.
Por isso, a validação das leituras dos sensores e a determinação de seus estados de
funcionamento são competências altamente desejáveis.

Em diversos setores da indústria, a validação de sensores é realizada através dos métodos
tradicionais de manutenção, os quais envolvem a calibração periódica dos instrumentos.
Várias técnicas de calibração periódica necessitam de paradas dos processos de produção
e/ou de se retirar de operação os instrumentos de medição. Entretanto, como apresentado
por Hines et al.~\cite{Hines2008}, estudos recentes mostraram que menos de 5\% da calibração manual
realizada é sequer necessária. Além disso, a confiabilidade de um instrumento pode ser
afetado de forma adversa pelas intervenções manuais.

Por essas e outras razões, como a competitividade de mercado, tem crescido a procura por
estratégias menos invasivas e mais eficientes. Técnicas de manutenção baseadas na condição
(CBM --- \textit{Condition Based Maintenance})
tendem à manutenção ótima, pois a condição de funcionamento dos instrumentos é monitorada
durante a operação da planta e recalibrações físicas são realizadas apenas quando uma
degradação do desempenho é detectada.
Na literatura, esses métodos têm sido chamados de monitoramento
\textit{on-line} de calibração (OLM --- \textit{On-line
Monitoring}).

\abreviatura{CBM}{Manutenção baseada na condição}
\abreviatura{OLM}{On-line Monitoring}

O monitoramento de calibração baseia-se essencialmente em estimar as medidas corretas que
deveriam ser realizadas pelos sensores, comparando-as com as reais medidas efetuadas pelos
mesmos. Para isso, existem duas abordagens atualmente utilizadas: redundância por
\textit{hardware} e redundância analítica \cite{Ma2011}.

Na redundância por
\textit{hardware}, sensores redundantes são utilizados para medirem uma mesma variável,
possibilitando formas mais simples e intuitivas de estimação dos valores corretos das
medições (pela média das medições, por exemplo). 
Entretanto, além da necessidade de aquisição de sensores extras, a redundância por
\textit{hardware} apresenta dificuldades na detecção de sensores descalibrados que
apresentam \textit{drift} na mesma direção.
Além disso, no caso dos sensores de fundo de poço, componentes redundantes ocupam
um valioso e limitado espaço, e consomem uma energia preciosa.

A outra abordagem, por redundância analítica, consiste na estimação das medidas
dos sensores baseando-se em outras medidas correlacionadas disponíveis no sistema. Existem
duas formas principais de modelagem dessas correlações: a modelagem por equações físicas
que descrevem as interações entre as variáveis e modelagem baseada em dados. 
Os modelos
baseados em equações físicas, apesar de serem normalmente muito precisos, necessitam de
significativos esforços de engenharia e são muito sensíveis à mudanças ou degradações não
previstas no sistema. 
Os modelos empíricos baseados em dados, ou histórico, também se
baseiam em medidas correlacionadas dentro do sistema, mas essas correlações ficam
implícitas, capturadas por técnicas de inteligência artificial e aprendizado de
máquinas
durante a análise de dados de medições livres de falhas, coletados
durante situações normais de operação da planta. Apesar de serem normalmente limitados a
trabalharem em pontos de operação da planta semelhantes aos quais foram treinados, os
modelos empíricos possuem diversos benefícios práticos, como: aplicabilidade livre de contexto, ou
seja, a essência dos modelos pode ser aplicada a quaisquer tipos de sistemas, sem a
necessidade de conhecimentos profundos sobre este; simplicidade de desenvolvimento, uma
vez que não existe a necessidade de modelos explícitos, o que torna-se um atrativo quando
se trata de sistemas complexos; e flexibilidade de configuração,
facilitando a configuração dos modelos para atender a novos requisitos de
desempenho ou a mudanças na própria planta. 

Esta dissertação tem como foco o desenvolvimento e implementação de um sistema de
monitoramento do desempenho de sensores de poços de petróleo, cujas técnicas são baseadas
em técnicas de aprendizado de máquina e modelos empíricos construídos com histórico de
dados. 
Como as técnicas baseadas em modelos empíricos são livres de contexto, este
trabalho possui potencial aplicação para diferentes setores industriais.


\section{Definição do problema e abordagens existentes}
\label{sec:problemDefinition}

Como apresentado por Mauro Oliveira~\cite{MauroVitordeOliveira2005}, a validação de sinal pode ser
definida como a detecção, isolamento e caracterização de sinais falhos. Em sistemas OLM, a
validação de sinais também é referida como a identificação de falhas em sensores
acompanhada da estimativa ou predição das medições corretas, durante o funcionamento da
planta ou processo.

Os sensores de poços são passíveis a vários tipos de falhas, como mudanças abruptas,
polarização (\textit{bias}), picos, etc. O principal tipo de falha tratado neste trabalho é
o \textit{drift} ou desvio de medição. Na literatura, o \textit{drift} é normalmente
definido como um desvio lento, contínuo ou incremental, das medições de um sensor ao longo
do tempo.

% TODO: verificar utilidade deste texto
%Uma das dificuldades da identificação de falhas em sensores é discernir entre a ocorrência de
%uma falha e a ocorrência de mudanças no processo ou na planta. Poços de petróleo possuem
%características dinâmicas que mudam ao longo da vida produtiva dos mesmos, afetando a
%correlação entre as variáveis medidas pelos sensores. Na prática, isso implica em
%insegurança na interpretação dos dados pelo operador, produção abaixo da capacidade real,
%desgaste prematuro de equipamentos, maior risco de acidentes e, consequentemente, maiores
%custos.

A abordagem por modelos empíricos baseados em dados normalmente assume uma premissa
fundamental: as variáveis medidas pelos sensores são correlacionadas, enquanto as
possíveis falhas nesses instrumentos são descorrelacionadas. Essa premissa implica que
%comparando-se situações normais e de falhas,
%ocorre uma mudança na correlação entre os dados gerados pelos sensores
existem diferenças entre as correlações dos dados gerados em situações normais e as dos
dados gerados em situações de falhas.
%em situações de falha de sensores, a correlação entre os dados gerados pelos sensores é
%diferente da correlação verdadeira entre as variáveis.
Os modelos são
normalmente desenvolvidos utilizando histórico de medições livres de erros, capturando a
correlação verdadeira entre as variáveis. Depois de construídos, esses modelos conseguem
gerar estimativas das medições corretas dos sensores, as quais são comparadas com as
medições reais com o intuito de se identificar e isolar possíveis falhas.
Casos de sucesso no emprego de tais técnicas na indústria já foram reportados, como
é o caso das plantas de energia nuclear \cite{Ma2011}.

Normalmente, os sistemas de monitoramento do desempenho de sensores baseados em modelos
empíricos segue o esquema apresentado na Fig. \ref{fig:chap1_ddfdd}.  Supondo uma matriz
de dados de treinamento $\mathbf{X} \in \mathbb{R}^{n_m \times p}$, onde $n_m$ é o número de amostras
de treino e $p$ é a quantidade de variáveis amostradas, um modelo empírico $f$ é treinado
usando $\mathbf{X}$. Quando novas medições $\mathbf{r} \in \mathbb{R}^{1\times p}$ tornam-se
disponíveis, estimações de $\mathbf{r}$ são obtidas por $\hat{\mathbf{r}} = f(\mathbf{r})$
e resíduos são gerados como $\mathbf{d} = \mathbf{r} - \hat{\mathbf{r}}$. A ocorrência de
\textit{drift} nas medições causa mudanças nas relações entre as variáveis de
$\mathbf{r}$, o que resulta em mudanças estatísticas anormais nos resíduos. Então,
avaliando estatisticamente os resíduos podem-se estabelecer as condições de operação ou
a saúde dos sensores \cite{Ma2011}.

\simbolo{$p$}{Número de sensores cujas leituras compõem uma amostra de dados}

\simbolo{$\mathbf{r}$}{$[r_1, \cdots, r_p]$, vetor que representa uma amostra de dados de
$p$ sensores}

\simbolo{$\hat{\mathbf{r}}$}{$[\hat{r}_1, \cdots, \hat{r}_p]$, estimativa de $\mathbf{r}$ gerada por um modelo
regressivo}

\simbolo{$\mathbf{d}$}{$[d_1, \cdots, d_p]$, vetor de resíduos entre $\mathbf{r}$ e
$\hat{\mathbf{r}}$}

\simbolo{$n_m$}{Quantidade de amostras de dados usados para construção dos modelos
regressivos}

\simbolo{$\mathbf{X}$}{Matriz de dimensão $n_m \times p$ de histórico de
amostras de treinamento do modelo regressivo AAKR.}

\begin{figure}[!htb]
    \centering
    \includegraphics[width=.9\textwidth]{figuras/data_driven_fdd.eps}
    \caption{Esquema de funcionamento de sistemas baseados em modelos empíricos para
    monitoramento do desempenho de sensores. Adaptado de Ma e Jiang~\cite{Ma2011}.}
    \label{fig:chap1_ddfdd}
\end{figure}

Inicialmente vários trabalhos empregaram redes neurais para o
desenvolvimento de modelos, mas atualmente as técnicas baseadas em kernel estão entre as
mais utilizadas. 

No trabalho de Hines e Uhrig~\cite{Hines1998}, um sistema de monitoramento do desempenho de
sensores foi implementado utilizando basicamente
uma rede neural auto-associativa (AANN) como modelo empírico e o algoritmo SPRT
(\textit{Sequential Probability Ratio Test}) para a análise das propriedades estatísticas
dos resíduos.
O sistema foi avaliado em dados de plantas nucleares, envolvendo problemas como
\textit{drifts} e erros grosseiros nos sensores.
%As estimações geradas pela rede eram
%comparadas às leituras dos sensores para a formação
%dos resíduos, cujas propriedades estatísticas, analisadas pelo módulo estatístico com o
%algoritmo SPRT (\textit{Sequential Probability Ratio Test}),
%indicavam a ocorrência de falhas ou \textit{drifts}.

\abreviatura{AANN}{Redes neurais artificiais auto-associativas}
\abreviatura{SPRT}{Sequential Probability Ratio Test}

Gribok, Hines e Uhrig~\cite{Gribok2000} realizaram uma comparação entre diferentes técnicas estatísticas
para a predição de dados de plantas nucleares. Entre as técnicas utilizadas, encontram-se
redes neurais, mínimos quadrados ordinários, regressão kernel, MSET (\textit{Multivariate
State Estimation Techniques}) e SVM (\textit{Support Vector Machines}). Os resultados
apontaram as técnicas baseadas em kernel como promissoras.

\abreviatura{MSET}{Multivariate State Estimation Techniques}
\abreviatura{SVM}{Support Vector Machines}

Zavaljevski e Gross~\cite{Zavaljevski2000} realizaram a validação de sensores de reatores nucleares
utilizando uma combinação de kernels MSET e do método SVM. As predições eram comparadas
com os dados dos sensores para a formação de resíduos, cujas propriedades estatísticas
eram analisadas usando SPRT para a detecção de falhas.

Garvey et al.~\cite{Garvey2007} apresentaram os resultados da aplicação da técnica de regressão
kernel auto-associativa (AAKR) a conjuntos de sensores de plantas nucleares. Diferentes
métricas são apresentadas para a avaliação de desempenho dos modelos AAKR e a detecção de
\textit{drifts} é realizada pela análise de incerteza dos modelos.

\abreviatura{AAKR}{Regressão kernel auto-associativa}

Aggrey e Davies~\cite{Davies2007} apresentaram um estudo sobre o uso de redes neurais para a predição de
dados de sensores de fundo de poços de petróleo e estimação de parâmetros de
reservatórios. A detecção de sensores degradados foi realizada por análises de limites
(\textit{thresholds}) dos valores dos resíduos.

Takruri, Rajasegarar e Challa~\cite{Takruri2008} propuseram um novo algoritmo para
correção de medições de redes de sensores sem fio. O algoritmo foi concebido para
trabalhar de forma descentralizada, sendo executado por cada sensor correlacionado de uma
rede. Cada sensor recebe as leituras de sensores correlacionados, com as quais infere a
própria leitura utilizando um modelo SVM.  A leitura inferida e a leitura real são
utilizadas por um filtro de Kalman (KF) que possui um modelo genérico de \textit{drift},
gerando uma estimação da leitura correta, ou verdadeira, do sensor em questão.

\abreviatura{KF}{Filtro de Kalman}

Neste trabalho, os modelos empíricos foram desenvolvidos utilizando AAKR ou SVM. A técnica
AAKR possui implementação simples e esforço mínimo para o desenvolvimento de modelos,
quando comparado às demais técnicas. A técnica SVM possui característica inferencial, o
treinamento dos modelos é mais simples, comparado às redes neurais, e gera resultados
estáveis.



\section{Objetivos e Contribuições}

O principal objetivo desta dissertação é apresentar o esquema de funcionamento de um
sistema para detecção e correção de desvios em sensores dentro de uma arquitetura mais
genérica para sistemas de monitoramento e manutenção baseado na condição.
Para se atingir esse objetivo principal, os seguintes objetivos são incluídos como etapas
intermediárias:

\begin{itemize}
    \item Desenvolver um sistema de detecção/correção de desvios em sensores baseado em
        modelos empíricos e técnicas de aprendizado de máquina;
    \item Ensaiar diferentes técnicas de modelagem empírica e configurações do sistema;
    \item Ensaiar e avaliar o sistema desenvolvido com dados de poços de produção de
        petróleo.
\end{itemize}

Como principais contribuições deste trabalho, podem-se destacar:

\begin{itemize}
    \item Aplicação ao cenário de poços de produção de petróleo técnicas recentes de
        modelagem empírica baseada em histórico de dados;
    \item Apresentação de uma estrutura modular para implementação do sistema de validação
        de sensores dentro de uma arquitetura mais geral para monitoramento e manutenção
        baseado na condição;
    \item Emprego de um modelo de estimação de \textit{drift} ao resíduo gerado entre um
        modelo empírico de predição auto-associativo e as leituras dos sensores.
\end{itemize}


\section{Estrutura da Dissertação}

No Capítulo \ref{chap:estrutura_sis}, é apresentada a estrutura do sistema de validação de
sensores e estabelecida uma relação entre essa estrutura e uma arquitetura mais geral para
sistemas CBM.
Em seguida, no Capítulo \ref{chap:drift}, são apresentadas as técnicas de modelagem
empírica e de monitoramento, ressaltando suas abordagens ao problema de validação de
sensores.
A descrição do sistema de validação de sensores implementado e sua avaliação em diferentes
cenários de ensaios são apresentadas no Capítulo \ref{chap:ensaios}.
Finalizando o trabalho, o Capítulo \ref{chap:conclusoes} apresenta as conclusões sobre o
desempenho do sistema de validação e dos modelos empíricos desenvolvidos e as
perspectivas de trabalhos futuros.


\chapter{Estrutura de Sistemas de Monitoramento e Validação de Sensores}
\label{chap:estrutura_sis}

Em esquemas de manutenção baseados em CBM, as condições de funcionamento de equipamentos e
sistemas são monitoradas com o intuito de otimizar as ações de manutenção. As manutenções
preventivas deixam de ser periódicas, passando a serem agendadas de forma dinâmica, de
acordo com evidências de real necessidade. A implementação de estratégias desse tipo pode
reduzir o tempo de inatividade de plantas de produção, melhorar o desempneho de sistemas e
o gerênciamento de recursos humanos limitados, prolongar a vida útil de equipamentos,
reduzir custos e tornar a produção gradualmente mais efetiva.

A tendência atual de utilização de centros integrados remotos, localizados em
terra, para suporte à operação, manutenção e otimização de unidades marítimas de produção
de petróleo
tem incentivado a utilização de ferramentas de manutenção baseadas na condição.
%Esses
%centros possuem equipes altamente capacitadas que são responsáveis pelo monitoramento do
%desempenho e diagnóstico de possíveis falhas em equipamentos críticos (compressores,
%bombas, turbinas, etc), visando a redução do número de paradas não programadas e o aumento
%da vida útil dos mesmos.
Esses centros possuem equipes altamente capacitadas que, munidas com as informações
certas e no momento adequado, são capazes de avaliar o desempenho e realizar diagnósticos
sobre equipamentos críticos (compressores, bombas, turbinas, etc).
Ferramentas CBM podem garantir o enriquecimento dos dados provenientes de plataformas ao
mesmo tempo que reduz a quantidade de informações a serem analisadas pelas equipes,
causando um consequente aumento da segurança e confiabilidade nas tomadas de decisão, além
de reduzir custos materias e humanos.

Apesar dos benefícios obtidos com a estratégia CBM, sérias dificuldades são frequentemente
encontradas para implementá-la de forma plena \cite{Campos2009}.  A quantidade de dados
coletados torna-se normalmente muito grande.  Pode haver a necessidade de coleta de dados
provindos de sistemas geograficamente dispersos. Os dados precisam ser integrados para
proverem informações úteis. Com o passar do tempo, pode ser necessário a aquisição de
dados de novas fontes e integrá-los com o restante para se obter mais informações
significativas. Finalmente, torna-se indispensável a disponibilidade de conhecimentos
especialistas para converter os dados gerados em informações úteis para manutenção.

No caso da indústria de petróleo, a implementação de um sistema CBM que envolvesse todas
as etapas do processo de produção tornaria-se altamente complexo, mesmo utilizando-se
técnicas simples para o processamento de sinais, monitoramento e detecção. Daí vem a
necessidade de uma metodologia de desenvolvimento que permitisse a implementação do
sistema de manutenção de forma bem estruturada, dentro de uma arquitetura flexível e
robusta.
A padronização da especificação de uma interface dentro da comunidade CBM poderia,
idealmente, direcionar os fornecedores de soluções CBM a produzirem componentes de
hardware e software intercambiáveis. Múltiplos desenvolvedores poderiam atuar na solução
de um mesmo sistema. Entre os potenciais benefícios de um padrão não proprietário, robusto
e largamente adotado, podem-se citar:

\begin{itemize}
    \item facilidade para atualização de componentes de sistema;
    \item aumento do número de fornecedores, resultando em mais opções de tecnologia;
    \item desenvolvimento tecnológico mais rápido;
    \item redução de custos e preços.
\end{itemize}

A seguir são apresentadas uma breve descrição sobre a arquitetura de sistemas de
manutenção baseados em CBM adotada como diretriz, a OSA-CBM, e uma proposta de
configuração de um sistema de validação de sensores dentro dessa arquitetura.

\section{OSA-CBM}

Recentemente, uma associação entre indústrias, fabricantes, universidades e a Marinha
Norte-Americana desenvolveu uma arquitetura aberta para sistemas de manutenção baseados em
CBM, conhecida como OSA-CBM (\textit{Open System Architecture Condition-Based
Maintenance}).
O foco principal dessa aliança foi desenvolver uma
arquitetura para sistemas CBM que facilitasse a interoperabilidade entre componentes de
\textit{hardware} e \textit{software}.
%módulos de software CBM
%\cite{Lebold2003}.
%Dessa forma, um sistema CBM poderia ser dividido em diferentes módulos padronizados que se
%comunicam entre si.

\abreviatura{OSA-CBM}{Open System Architecture Condition-Based Maintenance}

No OSA-CBM, a arquitetura de um sistema CBM é dividido em diferentes camadas funcionais,
cujos conteúdos devem ser implementados seguindo as interfaces definidas pelo padrão.
Atualmente, as camadas funcionais, ou módulos, somam um total de seis, seguindo a norma
ISO-13374. As camadas são: aquisição
de dados, processamento de sinais, monitoramento de condição, avaliação de
saúde (diagnóstico), a de prognóstico e a de suporte a tomada de decisão.
Cada camada possui a capacidade de requisitar dados de outras camadas funcionais quando
necessário, apesar do fluxo de dados normalmente ocorrer entre as camadas adjacentes. Na
Fig.~\ref{fig:osa_arq} é apresentado um esquema da organização dos módulos da arquitetura.

\begin{figure}[!htb]
    \centering
    \includegraphics[width=.7\textwidth]{figuras/arte/osa_cbm_camadas.eps}
    \caption{Arquitetura conceitual de sistemas baseados na arquitetura OSA-CBM
        \cite{PennStateUniversity2006}.}
    \label{fig:osa_arq}
\end{figure}

Os primeiros três blocos são específicos para determinadas tecnologias (monitoramento de
vibração, temperatura etc.) e provêem as seguintes funções \cite{PennStateUniversity2006}:

\begin{description}
    \item[Aquisição de dados:] converção da saída de um transdutor ou sensor em um dado
        digital que represente uma medida física ou uma informação relacionada (como
        tempo, qualidade dos dados etc.).

    \item[Processamento de sinal:] análises de sinal, cômputo de indicadores e derivação
        de leituras virtuais de sensores.

    \item[Monitoramento de condição:] criação e manutenção de perfis de comportamento
        normal do sistema, procura por anomalias a cada novo dado adquirido e determinação
        da zona de anormalidade no qual o sistema pode se encontrar.
\end{description}

Os três blocos restantes combinam conceitos humanos com tecnologias de monitoramento para
se determinar o estado de funcionamento corrente do sistema, realizar predições de falhas
e recomendações de possíveis ações a serem tomadas por operadores e mantenedores do
sistema. Podem-se citar as funções:

\begin{description}
    \item[Avaliação de saúde (diagnóstico):] diagnóstico das falhas e avaliação da
        condição de operação do sistema de acordo com todas as informações de estado.

    \item[Prognóstico:] previsão dos estados de operação, modos de falhas e vida útil de
        equipamentos/sistemas baseado na condição de operação corrente e no planejamento
        de carga do sistema.

    \item[Tomada de decisão:] fornecer possíveis ações relativas à manutenção e a mudanças
        de operação necessárias para otimizar a vida útil e desempenho do processo,
        equipamento ou sistema.
\end{description}


A Figura \ref{fig:osa_arq_pratico}, adaptada de Souza \cite{Souza2008}, ilustra um exemplo
mais prático da arquitetura de um sistema de manutenção CBM, apresentando algumas possíveis
técnicas presentes em cada uma das camadas.
A arquitetura é dividida em duas aplicações, aplicação servidor e aplicação cliente,
conectadas entre si por uma rede, onde compartilham informações.
A aplicação servidor é responsável por prover as funcionalidades das seis camadas do
modelo OSA-CBM, realizando a captura dos dados e o processamento inteligente.
A aplicação cliente é responsável pela apresentação, através de uma interface
gráfica, de dados técnicos e resultados provenientes do processamento realizado pela
aplicação servidor.
Possíveis aplicações da arquitetura OSA-CBM na indústria de petróleo são apresentadas por
Boechat, Moreno e Teixeira \cite{Boechat2011}.

\begin{figure}[!htb]
    \centering
    \includegraphics[width=.7\textwidth]{figuras/arq-conceitual-sistema.eps}
    \caption{Arquitetura conceitual de sistemas baseados na arquitetura OSA-CBM. Adaptada
        de Souza \cite{Souza2008}.}
    \label{fig:osa_arq_pratico}
\end{figure}

A OSA-CBM também está relacionada a outra arquitetura, a OSA-EAI (\textit{Open System
Architecture for Enterprise Application Integration}).
A OSA-EAI define estruturas de dados para armazenamento e movimentação de informações
coletivas sobre todos os aspectos dos equipamentos dentro das atividades empresariais.
Isso inclui a configuração física de plataformas assim como a confiabilidade, condição e
manutenção de plataformas, sistemas e subsistemas.
Vários elementos definidos pela OSA-EAI são utilizados pela OSA-CBM.
Segundo Swearingen~\cite{Swearingen2007}, espera-se que no futuro a OSA-CBM esteja
totalmente mapeada dentro da OSA-EAI, sem que seja possível distingui-las.
A Figura \ref{fig:osa_eai} ilustra a atual relação entre entre a OSA-CBM e a OSA-EAI.

\begin{figure}[!htb]
    \centering
    \includegraphics[width=.6\textwidth]{figuras/cbm-eai.eps}
    \caption{Relações entre as arquiteturas OSA-CBM e OSA-EAI. Adaptada de
        Swearingen~\cite{Swearingen2007}.}
    \label{fig:osa_eai}
\end{figure}

\abreviatura{OSA-EAI}{\textit{Open System Architecture for Enterprise Application
Integration}}

\section{Validação de Sensores e o Modelo OSA-CBM}

Considerando a arquitetura OSA-CBM, um sistema básico de validação de sensores poderia ser
composto por quatro diferentes módulos e uma base de dados de histórico, como ilustrado na
Fig. \ref{fig:osa_drift}.
As principais funcionalidades presentes em cada módulo são:

\begin{figure}[bt]
    \centering
    \includegraphics[width=\textwidth]{figuras/osa_cbm_drift.eps}
    \caption{Arquitetura do sistema de validação de sensores baseada no modelo OSA-CBM.}
    \label{fig:osa_drift}
\end{figure}

\begin{description}
    \item[Aquisição de dados:] composta basicamente por sensores e transdutores,
        responsáveis pela mensuração de grandezas físicas e pela transformação dessas
        medidas para dados digitais. Contando com um sistema de banco de dados, as medidas
        são armazenadas para futuras análises de histórico.

    \item[Processamento:] responsável pela extração de informações relevantes sobre a
        condição de funcionamento dos sensores a partir das medições realizadas pelos
        sensores. Este módulo pode ser subdividido em pelo menos três etapas:
        \begin{description}
            \item[Pré-processamento:] consiste na preparação e condicionamento dos dados
                aos algoritmos de regressão.

            \item[Predição:] responsável pela construção de modelos regressivos a partir
                do histórico de medidas dos sensores, predição de sinais e geração de
                resíduos.

            \item[Pós-processamento:] não intrinsecamente necessária, realiza a estimação de
                desvios nos sinais dos sensores para maior robustez dos modelos regressivos.
        \end{description}

    \item[Monitoramento de condição:] realiza a tarefa de monitorar os indicadores de
        falhas nos sensores a partir da detecção de mudanças nas propriedades estatísticas
        dos resíduos ou das estimativas de desvio. Alertas e alarmes podem ser gerados
        para indicarem falhas em sensores específicos.

    \item[Interface gráfica:] módulo de apresentação de resultados e indicadores para os
        usuários, realiza a tarefa de apresentar as informações relevantes para cada grupo
        de usuários, como o de manuntenção, operação da planta ou o grupo responsável por
        tomadas de decisões estratégicas de negócio.
\end{description}

Vale destacar ainda uma das principais vantagens da adoção de uma arquitetura padronizada
como a OSA-CBM: a facilidade de inserção de novos algoritmos para cada um dos módulos do
sistema de manutenção.
Através das interfaces padronizadas dos módulos, algoritmos de diagnóstico, para a
identificação de diferentes tipos de falhas, e de prognóstico, previsão das condições
futuras de funcionamento, por exemplo, poderiam ser incluídos sem praticamente nenhuma
mudança nos algoritmos e módulos já presentes no sistema.


\chapter{Processamento de Sinais para Detecção e Correção de Drift}
\label{chap:drift}

% Definição formal de drift de sensores.
% Teoria geral sobre o emprego de modelos empíricos para validação de medidas de sensores.
% Diferenças entre identificação de sistemas (density estimation) e a regressão por modelos
% empíricos (livro ``Learning from data'').
% Explicação básica sobre detecção por métodos estatísticos.

Pode-se dividir o processo de validação de sensores em três etapas principais:
pré-processamento, processamento, pós-processamento dos sinais e o monitoramento de
condição.
Cada uma dessas etapas são detalhadas a seguir.

%Como discutido no Capítulo 1, o monitoramento do desempenho de sensores é composto
%basicamente por três etapas: predição das leituras dos sensores por um modelo empírico, a
%geração de resíduos e a avaliação desses resíduos gerados. A seguir são apresentados
%detalhes sobre a metodologia adotada em cada etapa.

\section{Pré-processamento dos Sinais}

A etapa de pré-processamento dos sinais consiste na preparação dos dados que serão
utilizados pelos modelos empíricos, tanto para o treinamento quanto para a predição.
O condicionamento dos dados às técnicas de modelagem normalmente são
necessárias para que os modelos consigam extrair dos sinais as informações corretas e
realmente relevantes para futuras predições.

Pode-se dividir a etapa de pré-processamento em quatro tarefas: limpeza dos dados,
normalização, seleção das variáveis de entrada do modelo e seleção das amostras de
treinamento.

\subsection{Limpeza dos Dados}

A limpeza dos dados consiste na filtragem e remoção de dados espúrios.

A filtragem dos sinais tem por objetivo retirar ou reduzir os ruídos normalmente presentes
nas medições dos sensores.
``O uso de sinais filtrados tende a facilitar o processo de treinamento dos modelos, uma vez
que se reduz a complexidade dos sinais a serem aprendidos pelo modelo''
\cite{MauroVitordeOliveira2005}.
Entretanto, é importante garantir que o processo de filtragem não remova informações
``verdadeiras'' sobre a variável mensurada, o que poderia comprometer o desempenho dos
modelos.

Dados espúrios ou \textit{outliers} são dados inconsistentes com a maioria das medidas
coletadas.
Medidas espúrias são normalmente causadas por erros grosseiros na medição, erros no
armazenamento, e/ou outros eventos anormais.
Tais dados não representativos podem afetar seriamente os
modelos~\cite{cherkassky2007learning} e devem ser corrigidos ou simplesmente removidos do
conjunto de dados utilizados para treinamento.

% \subsubsection{Aquisição e Qualidade dos Dados}
% 
% Como apresentado por Hines \cite{Hines2006},
% o primeiro passo para o desenvolvimento de um modelo é a coleta de dados representativos.
% Os dados devem ser cuidadosamente analisados para se garantir sua qualidade. Dados
% espúrios, anomalias e condições de falhas de equipamentos devem ser corrigidos ou
% simplesmente excluídos do conjunto de dados selecionado para treinamento do modelo. Apesar
% de existirem procedimentos automáticos para remoção de erros, a inspeção visual ainda é
% muito importante para se garantir a qualidade dos dados.
% 
% \textcolor{red}{FIXME:} que dados são esses? treinamento? tomar cuidado com essa palavra. Filtragem dos
% dados para redução de complexidade do modelo, remoção de dados espúrios. Normalização dos dados.
% Pontos de operação podem ser identificados por técnicas de clusterização/classificação.
% 
% Além disso, os dados devem cobrir completamente os futuros
% pontos de operação e estarem livres de pontos de operação atípicos. Como as técnicas de
% modelagem empírica baseada em dados aprendem sua relação funcional a partir dos dados de
% treinamento, os modelos são incapazes de gerarem predições confiáveis fora da região de
% operação dos dados de treinamento. Se estados de operação anômalos, como \textit{drift} em
% um sensor ou falha em equipamento, são incluídos no conjunto de treinamento, os
% modelos irão incorporar essas condições como comportamentos normais.

% Neste trabalho, a análise dos dados de treinamento foi realizada por inspeção visual.

\subsection{Normalização}

A normalização dos dados consiste em tornar igual a escala de valores dos sinais de todos
os sensores envolvidos.
Diferentes variáveis mensuradas pelos sensores naturalmente possuem diferentes escalas, ou
seja, suas próprias unidades de medida.
Para algumas técnicas de modelagem, a escala das variáveis não representa um problema,
entretanto, outros métodos, principalmente os baseados em distância, são sensíveis às
escalas das variáveis de entrada.
Nestes métodos, variáveis caracterizando pressão, por exemplo, possuiriam maior influência
quando expressadas em Pascal que em kgf/m$^2$.

Para técnicas de aprendizagem de máquina, uma das formas comuns de se normalizar sinais é
escalá-los no hipercubo $[0,1]^p$, onde $p$ é o número de variáveis de entrada do modelo.
Neste caso, a normalização de uma amostra $r_p \in \mathbb{R}$ obtida de um sensor $p$ é dada
pela Eq.~(\ref{eq:scaling}), onde $r_{norm,p}$ é o valor normalizado de $r_p$ e
$r_{max,p}$ e $r_{min,p}$ são os valores máximos e mínimos dos dados de treinamento
relativos ao sensor $p$.

\begin{equation}
    r_{norm,p} = \frac{r_p - r_{min,p}}{r_{max,p} - r_{min,p}}
    \label{eq:scaling}
\end{equation}


\subsection{Seleção das Variáveis de Entrada}

Este passo consiste na seleção de quais variáveis, ou sensores, serão incorporados no
modelo, com o objetivo de agrupar aquelas que possuem certo grau de correlação.
Como os modelos empíricos baseiam suas predições nas correlações das variáveis de entrada,
o agrupamento é uma tarefa de fundamental importância.
A adição de variáveis não relevantes (sem correlação com a variável a ser predita) tende a
gerar modelos instáveis, cujas predições apresentam alta variância.
Entretanto, para algumas técnicas de regressão, variáveis altamente correlacionadas podem
causar singularidade na matriz de dados entrada e, consequentemente, predições de baixa
qualidade.
Além disso, quanto maior o número de variáveis de entrada de um modelo empírico de
regressão, maior deve ser o número de amostras de treinamento para que o modelo cubra o
mínimo possível do espaço de entrada.

Para os casos de redundância de \textit{hardware} com técnicas de regressão que suportam
colinearidades, o processo de seleção é simples, uma vez que apenas
sensores redundantes são incluídos em um modelo.
Para os casos onde redundâncias não necessariamente existem, o
conjunto de sensores que se deseja monitorar deve ser separado em grupos menores altamente
correlacionados.
Segundo Hines e Seibert\cite{Hines2006}, agrupamentos ótimos normalmente contém menos
de 30 sensores e que a adição de sinais irrelevantes acaba por aumentar a variância das
predições de um modelo, enquanto a ausência de sinais relevantes tende a causar
polarização.

Um indicador de agrupamento normalmente utilizado é o coeficiente de correlação
(covariância entre os sinais dividida pelo produto dos desvios padrão de cada um) para
cada par de sensores. Se o coeficiente de correlação ultrapassa um determinado valor,
então o correspondente par de sensores deve participar do mesmo grupo. Entretanto, este
método não garante a otimalidade de agrupamento, pois variáveis que são fortemente
correlacionadas fisicamente podem apresentar baixos coeficientes de correlação devido a
ilusões estatísticas de conjunto de dados polarizados.
Normalmente, esse método é utilizado acompanhado de senso de engenharia, ou seja,
selecionam-se as variáveis considerando também conhecimentos especialistas sobre a
dinâmica do processo.

Técnicas de exploração do espaço de possibilidades também podem ser empregadas para o
agrupamento das variáveis, como algoritmos genéticos~\cite{MauroVitordeOliveira2005} e a
\textit{stepwise grouping}~\cite{An2011}.
Basicamente, essas técnicas tentam minimizar o número de tentativas possíveis para se
alcançar um solução ótima ou subótima de agrupamento.
Cada tentativa implica na criação de um diferente modelo e na avaliação da qualidade das
predições geradas por ele.
Através de uma heurística, reduz-se o espaço de possibilidades de combinação das
variáveis para, finalmente, selecionar aquele agrupamento que gera o modelo com melhor
qualidade de predição.

% Como
% apresentado por An \cite{An2011}, técnicas como a \textit{stepwise grouping} podem
% realizar bons agrupamentos de sensores. Basicamente, a \textit{stepwise grouping} realiza
% os agrupamentos de forma incremental, ou seja, adiciona-se um novo sensor a grupo,
% constroi-se um modelo a partir dessa junção e compara-se a qualidade da predição desse novo
% modelo em relação ao modelo anterior, sem a nova variável. Caso a qualidade da predição
% tenha sido melhorada, a nova variável permanece no grupo; caso constrário, a variável é
% descartada, permanecendo o agrupamento anterior. O procedimento é realizado até que todos
% so sensores possíveis tenham sido analisados.


\subsection{Seleção das Amostras de Treinamento}

Dois aspectos principais, intrinsicamente relacionados, devem ser considerados para a
seleção das amostras para o treinamento dos modelos: quantidade e representatividade.

Normalmente, quanto maior a quantidade de amostras que se tem de um sistema, mais
informações ficam disponíveis e mais preciso é o modelo que se pode obter para representá-lo.
Entretanto, os limites físicos de armazenamento de dados e a capacidade computacional para
processá-los devem ser considerados ao se implementar um sistema OLM.
Quantidades excessivas de dados podem custar muito tempo para treinamento dos modelos e
para os cálculos das predições, a um ganho insignificante de informações sobre o sistema.

A representatividade está relacionada justamente à quantidade de informações relevantes
sobre um sistema presentes em um conjunto de dados.
Normalmente, a quantidade de amostras de um conjunto de dados não é linearmente
relacionado à representatividade deste.
Em muitos casos é possível obter pequenos conjuntos de dados que possuem praticamente a
mesma representatividade que conjuntos volumosos~\cite{HinesGarvey2008}.

Portanto, a seleção das amostras de treinamento de um modelo regressivo deve considerar
primeiramente a cobertura de todos os futuros pontos de operação da planta ou poço para,
finalmente, se fazer uma análise de ganho de precisão das predições em relação à
quantidade de amostras.
Além disso, é de suma importantância certificar que as amostras não correspondem à pontos
de operação atípicos, como em casos de falha em equipamento ou de desvios em sensores.
Se presentes no conjunto de treinamento do modelo, os pontos de operação atípicos são
aprendidos pelo modelo como comportamento normal dos sensores.

Em sistemas dinâmicos como poços de petróleo, onde não se tem dados de histórico que
abranja todos os possíveis pontos de operação futuros devido às mudanças das
características do próprio poço, normalmente torna-se necessário o retreinamento do modelo
regressivo com novas amostras ao longo da vida útil do poço.


% Geralmente, a quantidade de variáveis de entrada do modelo dita uma quantidade mínima de
% amostras necessárias para se ``capturar'' a correlação entre elas.
% % Com poucas observações, tende-se a obter predições degradadas por falta de informação; com
% % quantidade excessiva, o custo computacional de cada predição torna-se muito alto.
% Entretanto, essas amostras precisam representar as condições de operação que se espera
% encontrar quando o modelo estiver funcional.

% Para a maioria dos modelos empíricos, os dados devem ser separados em pelo menos dois
% conjuntos, o de treinamento e o de validação. Os dados de treinamento são usados pelo
% modelo para o aprendizado das relações entre os sensores e otimização de seus parâmetros.
% Os dados de validação servem para avaliar o desempenho do modelo construído. Hines
% \cite{Hines2007} normalmente divide os dados em três conjuntos, treinamento, verificação e
% validação. A diferença consiste na separação de um conjunto específico para otimização dos
% parâmetros do modelo, o conjunto de verificação.
% 
% \textcolor{red}{Importância da escolha de dados significativos, livre de erros, etc}

% TODO: talvez seja mover para a próxima subseção
%Os modelos baseados em regressão por kernel, como o AAKR, requerem que um
%subconjunto dos dados de treinamento seja armazenado como uma matriz de memória usada para
%as futuras predições. A seleção desse subconjunto possui efeitos consideráveis no
%desempenho do modelo; armazenando poucas observações, as predições são degradadas por
%falta de informação; armazenando uma quantidade excessiva, o custo computacional de cada
%predição torna-se muito alto.



\section{Processamento dos Sinais}

% Listar modelos estudados e as razões da escolha destes.
% -> Premissas

O processamento dos sinais é a etapa de predição propriamnente dita. A partir de novas
amostras das variáveis de entrada, o modelo empírico gera predições sobre a variável de
saída.
Os principais aspectos a serem considerados nesta etapa são: a escolha do tipo de
estrutura do modelo, a escolha da técnica de regressão e a construção/otimização do
modelo.

% Antes da predição das leituras de sensores propriamente dita, é necessário construir um
% modelo empírico baseado no histórico de sensores correlacionados.
% Independente da técnica utilizada para modelagem e predição, existem alguns passos básicos
% comuns empregados para o desenvolvimento de modelos empíricos baseados em histórico.
% 
% A seguir são descritos os passos básicos para o desenvolvimento de um modelo baseado em
% histórico de dados e as técnicas empregadas para modelagem/predição neste trabalho.

\subsection{Seleção do Tipo de Estrutura}

Normalmente, a estrutura dos modelos pode ser classificada em três diferentes tipos:
inferencial, hetero-associativa ou auto-associativa.

Um modelo inferencial utiliza um conjunto de variáveis de entrada $[r_1, \cdots, r_n]$
para inferir o valor de uma única variável de saída $y$.
Esse modelo pode ser expandido para um estrutura hetero-associativa, onde um conjunto de
variáveis de entrada $[r_1, \cdots, r_p]$ é usado para predizer os valores de um conjunto
de variáveis de saída $[y_1, \cdots, y_q]$.

\simbolo{$y$}{$f(\mathbf{r}) = y$, saída ou predição de um modelo inferencial a partir de
um vetor $\mathbf{r}$}

Um modelo auto-associativo é normalmente treinado para emular as próprias variáveis de
entrada, ou seja, um conjunto de variáveis $[r_1, \cdots, r_p]$ é usado para
gerar predições $[\hat{r}_1, \cdots, \hat{r}_p]$, que correspondem aos valores
``corrigidos'' das variáveis de entrada de acordo com o conjunto de dados de treinamento
usado para a contrução do modelo.
Dessa forma, se as variáveis de entrada possuem a mesma correlação existente nos dados de
treinamento, os valores de saída do modelo auto-associativo tendem a ser iguais aos
valores de entrada.
Pequenas alterações nessas correlações, como as causadas por algumas falhas em sensores,
tendem a ser corrigidas pela correlação capturada pelo modelo através dos dados de
treinamento.


\subsection{Técnicas de Regressão}
\label{sec:tec_regressao}

%% Present the quality metrics for each technique

%Duas das técnicas de modelagem baseada em histórico que têm apresentado aplicações em
%sistemas de monitoramento do desempenho de sensores~\cite{Gribok2000}: a regressão por
%kernel auto-associativa (AAKR) e a \textit{support vector machines} (SVM).

As duas técnicas de regressão abordadas neste trabalho são: AAKR e SVM.

\subsubsection{AAKR}
%TODO: Figuras explicativas

A regressão por kernel auto-associativa é uma técnica não paramétrica para modelagem
baseada em histórico de dados, cujas predições se baseiam na similaridade entre as
entradas do modelo e um histórico de dados armazenado.
A arquitetura do modelo AAKR apresentada a seguir é uma variação da regressão inferencial
multivariável por kernel, apresentada por Wand e Jones \cite{wand1995kernel}.
%Baseando-se na similaridade entre o vetor de leituras de um conjunto de sensores e o
%conjunto de vetores do histórico, armazenado como uma memória, o modelo AAKR 

Considerando $\mathbf{X}$ uma matriz de histórico de amostras livres de erros, ou memória,
$x_j^{(i)}$ representa a i-ésima observação da j-ésima variável/sensor.
Para $n_m$ vetores de memória e $p$ variáveis, a matriz $\mathbf{X}$ é definida como


$$
{\mathbf{X}} = \left[ {\begin{array}{*{20}{c}}
{{x_1^{(1)}}}&{{x_2^{(1)}}}& \cdots &{{x_p^{(1)}}}\\
{{x^{(2)}_1}}&{{x^{(2)}_2}}& \cdots &{{x_p^{(2)}}}\\
 \vdots & \vdots & \ddots & \vdots \\
 {{x^{(n_m)}_1}}&{{x^{(n_m)}_2}}& \cdots &{{x^{(n_m)}_p}}
\end{array}} \right] \mbox{.}
$$

As entradas do modelo são definidas pelo vetor de amostras $\mathbf{r}$, definido por

$$
{\mathbf{r}} = \left[ {\begin{array}{*{20}{c}}
{{r_1}}&{{r_2}}& \cdots &{{r_p}}
\end{array}} \right] \mbox{.}
$$

A predição do valor corrigido de $\mathbf{r}$ é calculada como uma média ponderada das
observações livres de erros contidas em $\mathbf{X}$.
O funcionamento do modelo AAKR é composto de três passos básicos.
Primeiro, calcula-se as distâncias entre $\mathbf{r}$ e cada linha da matriz de memória
$\mathbf{X}$.
Dentre as possíveis métricas de distância, a distância Euclidiana é a mais comumente
utilizada~\cite{Hines2008}, dada pela Eq.~(\ref{eq:aakr_distance}), onde $u_i$ é a distancia Euclidiana
entre o vetor de memória $\mathbf{x}^{(i)}$ e a entrada $\mathbf{r}$.

\simbolo{$u_i$}{Distância Euclidiana entre o vetor de memória $\mathbf{x}^{(i)}$ e um vetor de
entrada $\mathbf{r}$.}

\begin{equation}
    {u_i}\left( {{{\mathbf{X}}^{(i)}},{\mathbf{r}}} \right) = \sqrt {{{\left(
        {{x_1^{(i)}} - {r_1}} \right)}^2} + {{\left( {{x_2^{(i)}} - {r_2}} \right)}^2} +  \cdots
        {{\left( {{x_p^{(i)}} - {r_p}} \right)}^2}} 
    \label{eq:aakr_distance}
\end{equation}

\noindent Este cálculo é repetido para todos os $n_m$ vetores de memória da matriz $\mathbf{X}$,
resultando em um vetor coluna de distâncias

$$
{\mathbf{u}} = \left[ {\begin{array}{*{20}{c}}
{{u_1}}\\
{{u_2}}\\
 \vdots \\
{{u_{{n_m}}}}
\end{array}} \right] .
$$

Em seguida, as distâncias são convertidas em medidas de similaridade ou pesos através
da função kernel, como a Gaussiana apresentada na Eq.~(\ref{eq:gauss_kernel}), onde
$\overline{w}_i$ é o i-ésimo peso relativo a i-ésima distância $u_i$ e $h$ é a largura de banda da
função kernel $\textsf{K}$.

\simbolo{$\textsf{K}$}{Função kernel}

\simbolo{$h$}{Largura de banda da função kernel Gaussiana}

\simbolo{$\overline{w}_i$}{Peso relativo ao vetor $u_i$ e à largura de banda $h$}

\begin{equation}
    {\overline{w}_i} = \textsf{K} ({u_i}) = \frac{1}{{\sqrt {2\pi {h^2}} }}{\; \exp
    \left(- \frac{{u_{_i}^2}}{{{h^2}}} \right) } \mbox{,}
    \label{eq:gauss_kernel}
\end{equation}

Por fim, através da Eq.~(\ref{eq:aakr_var_pred}), os pesos são combinados com os vetores
de memória para produzir uma estimativa $\hat{r}_j$ de cada variável $r_j$.
Calculando as estimativas para $j = \{1, 2, \cdots, p\}$, obtém-se a saída do modelo, a
predição $\hat{\mathbf{r}}$.
Alternativamente, definindo $a = {\sum\limits_{i = 1}^{{n_m}} {{\overline{w}_i}} }$, o estimador AAKR
pode ser apresentado pela Eq.~(\ref{eq:aakrPred}).

\begin{equation}
    \hat{r}_j = \frac{\sum\limits_{i = 1}^{n_m} {\overline{w}_i}\cdot
        x_j^{(i)}  }{{\sum\limits_{i = 1}^{{n_m}} {{\overline{w}_i}} }}
    \label{eq:aakr_var_pred}
\end{equation}

\begin{equation}
    {\hat \mathbf{r}} = \frac{{{{\mathbf{\overline{w}}}^T}{\mathbf{X}}}}{a}
    \label{eq:aakrPred}
\end{equation}

\paragraph{Seleção dos vetores de memória}

A seleção dos vetores de memória é uma tarefa crítica para o desenvolvimento de modelos
não paramétricos como o AAKR \cite{HinesGarvey2008}, onde as predições do modelo se
baseiam na similaridade entre suas entradas e cada um dos vetores de memória.
Um conjunto de dados de treinamento muito grande tornaria muito elevado o custo
computacional de cada predição.
O que normalmente se faz é selecionar um subconjunto dos dados de treinamento, visando
diminuir o custo computacional sem perder informações significantes sobre a correlação
entre as variáveis.

Basicamente, duas questões devem ser consideradas para a seleção dos vetores de memória: 
qual é a \emph{quantidade} adequada e \emph{como} realizar essa seleção.
Em relação à quantidade, normalmente existe um número crítico para cada conjunto de dados:
quantidades menores pioram o desempenho do modelo drasticamente, quantidades maiores
melhoram discretamente o desempenho ao custo de aumentos drásticos no tempo
computacional~\cite{HinesGarvey2008}.
Em relação à forma de seleção dos vetores, dois métodos simples e comumente utilizados são
a seleção por mínimos-máximos e a seleção por ordenamento dos vetores.

O método de seleção por mínimos-máximos é dividido em duas etapas.
Primeiro, particiona-se o conjunto de dados em $n_b$ bandas, de acordo com a
Eq.~(\ref{eq:aakrMinMax}), onde $n_m$ é o número de vetores a serem selecionados e
$p$ é a quantidade de variáveis nos dados.
Em seguida, para cada banda gerada, selecionam-se os vetores que contenham os valores
máximos e mínimos de cada variável, sem repetição de vetores.

\begin{equation}
    n_b = \frac{n_m}{2p}
    \label{eq:aakrMinMax}
\end{equation}

No método de seleção por ordenamento de vetores, primeiramente ordenam-se os vetores de
treinamento de acordo com a norma Euclidiana.
A Equação~(\ref{eq:aakrVecOrd}) apresenta o cálculo da norma Euclidiana $N_i$ para um
vetor $\mathbf{x}^{(i)}$ de treinamento.
Em seguida, selecionam-se $n_m$ vetores amostrando de forma periódica.
É importante destacar que este método é intrinsecamente relacionado com a localização da
origem do espaço da matriz de dados de treinamento, o que torna importante escalar as
variáveis antes da utilização deste método de seleção.

\begin{equation}
    N_i = \sqrt{x_1^{(i) \; 2} + x_2^{(i) \; 2} + \cdots + x_p^{(i) \; 2}}
    \label{eq:aakrVecOrd}
\end{equation}

Um outra forma de realizar a seleção dos vetores de memória é a combinação dos dois
métodos anteriores.
Como normalmente o método de seleção por mínimos-máximos não obtém o número $n_m$ de
vetores desejado (um mesmo vetor pode conter os valores máximos ou mínimos de mais de uma
variável), usa-se o método de ordenamento de vetores para selecionar a quantidade de
vetores necessária para se obter $n_m$.

\subsubsection{SVM}

Na técnica de SVM para regressão, um conjunto de dados de treinamento
$\{(\mathbf{r}^{(1)}, y^{(1)}), \ldots, (\mathbf{r}^{(n_m)}, y^{(n_m)})\}$, onde $\mathbf{r}
\in \mathbb{R}^p$ e $y \in \mathbb{R}$,
é usado para estimar uma
função $f(\mathbf{r})$ que correlaciona as $p$ variáveis de $\mathbf{r}$ com uma variável
dependente $y$ a partir de $n_m$ observações independentes e identicamente
distribuídas.
Dessa forma, um modelo SVM apresenta estrutura do tipo inferencial.

A técnica corresponde à minimização da Eq.~(\ref{eq:DF_svm_minimize}),
onde $f(\mathbf{r}) = \left< \mathbf{w,r} \right> + b$, com $w \in \mathbb{X}$ (espaço de
características) e $b \in \mathbb{R}$, é o estimador da função de dependência entre $\mathbf{r}$
e $y$.
A solução da Eq.~(\ref{eq:DF_svm_minimize}) pode ser escrita como a Eq.~(\ref{eq:DF_svm_fx}).
Essa formulação torna a solução esparsa no sentido que erros menores que $\varepsilon$ são
ignorados, ou seja, a solução torna-se ``$\varepsilon$-insensível''.

\begin{equation}
    \begin{array}{ll}
        \mbox{Minimizar} & \frac{1}{2} || \mathbf{w}||^2 + C \sum\limits^n_{i=1} \left(
        \xi^{(i)} + \xi^{* \; (i)} \right) \\[.5cm]
        \mbox{Sujeito a} &
        \left\{
        \begin{array}{rl}
            y^{(i)} - \left<\mathbf{w}, \mathbf{r}^{(i)} \right> - b & \le \varepsilon
            + \xi^{(i)} \\[7pt]
            \left<\mathbf{w}, \mathbf{r}^{(i)} \right> + b - y^{(i)} & \le \varepsilon +
            \xi^{* \; (i)} \\[7pt]
            \xi^{(i)}, \xi^{* \; (i)} & \ge 0
        \end{array}
        \right\} \\
    \end{array}
    \label{eq:DF_svm_minimize}
\end{equation}

\begin{equation}
    f(\mathbf{r}) = \sum\limits_{j=1}^p w_j \; r_j + b
    \label{eq:DF_svm_fx}
\end{equation}

O primeiro termo da equação (\ref{eq:DF_svm_minimize}) é um termo de regularização que
evita o mau condicionamento do problema de estimação, contribuindo na simplicidade do
estimador da função.
O segundo termo é a função de perda $\varepsilon$-insensível, a qual
mede o quanto os valores estimados estão próximos dos valores $y$. As variáveis $\xi^{(i)}$ e
$\xi^{* \; (i)}$ são chamadas de variáveis de folga, que determinam o grau de penalização
aplicados às estimativas com erros maiores que $\varepsilon$.
A Figura
\ref{fig:DF_svm_insensibilidade} ilustra a zona de insensibilidade formada por $\varepsilon$
e a penalização efetuada pelas variáveis de folga. Por isso, qualquer erro absoluto menor
que $\varepsilon$ não necessita de valores diferentes de zero para as variáveis $\xi^{(i)},
\xi^{* \; (i)}$ na função objetiva, o que causa a esparsividade da solução.
A constante $C$ determina o custo-benefício entre a complexidade da função $f$ e a
quantidade tolerada de desvios maiores que $\varepsilon$.

\begin{figure}[!htb]
    \centering
    \includegraphics[width=.6\textwidth]{./figuras/svm_etube.eps}
    \caption{Zona de insensibilidade e penalização no modelo SVM \cite{Smola2004}.}
    \label{fig:DF_svm_insensibilidade}
\end{figure}

Escrevendo a Eq.~(\ref{eq:DF_svm_minimize}) na forma dual e resolvendo por diferenciação
em relação às variáveis primais, o problema resulta em maximizar a função $W(\alpha^*,
\alpha)$ na Eq.~(\ref{eq:DF_svm_dual}), onde $\alpha, \alpha^*$ são multiplicadores de
Lagrange e $\textsf{K}(\mathbf{r}^{(i)}, \mathbf{r}^{(j)})$ é a função kernel que substitui o
que seriam os produtos internos $\left<\mathbf{r}^{(i)}, \mathbf{r}^{(j)}\right>$ e permite lidar
com não linearidades do espaço de entrada do modelo.

\begin{equation}
    \begin{array}{rrr}
        \lefteqn{\mbox{Maximizar}}\\ 
        & & W(\alpha^*, \alpha) = - \varepsilon \sum\limits_{i=1}^{n_m} (\alpha^{(i)} + \alpha^{* \; (i)}) +
        \sum\limits_{i=1}^{n_m}  y^{(i)} (\alpha^{(i)} - \alpha^{* \; (i)})  - \\[7pt]
        & & \frac{1}{2} \sum\limits_{i,j=1}^{n_m} (\alpha^{(i)} - \alpha^{* \; (i)}) (\alpha_j -
        \alpha_j^*) \; \textsf{K}(\mathbf{r}^{(i)}, \mathbf{r}^{(j)}) \\[12pt]
    \lefteqn{\mbox{Sujeito a}
    \left\{
    \begin{array}{c}
        \sum\limits_{i=1}^{n_m} (\alpha^{* \; (i)} - \alpha^{(i)})  = 0\\
        0 \le \alpha^{(i)}, \alpha^{* \; (i)} \le C
    \end{array}
\right\}} \\
    \end{array}
    \label{eq:DF_svm_dual}
\end{equation}

A função $f(\mathbf{r})$ passa a ser dada pela Eq.~(\ref{eq:DF_svm_func_dual}).
Os vetores $\{\mathbf{r}^{(1)}, \cdots, \mathbf{r}^{(N_{sv})}\}$, pertencentes ao conjunto
inicial de treinamento, são chamados de ``vetores suporte'', onde $N_{sv}$ (normalmente
$N_{sv} << n_m$) é o número de vetores suporte correspondentes à quantidade de valores de
$\{y^{(1)}, \cdots, y^{(n_m)}\}$ que estão pelo menos $\varepsilon$ afastados de suas
estimativas $\{f(\mathbf{r}^{(1)}), \cdots, f(\mathbf{r}^{(n_m)})\}$.

\begin{equation}
    f(\mathbf{r}) = \sum\limits_{i=1}^{N_{sv}} (\alpha^{* \; (i)} - \alpha^{(i)}) \;
    \textsf{K}(\mathbf{r}, \mathbf{r}^{(i)}) + b
    \label{eq:DF_svm_func_dual}
\end{equation}


As condições de Kuhn-Tucker demandam que o produto entre as variáveis duais e as
restrições devem desaparecer para otimalidade. Por isso, para $|f(\mathbf{r}^{(i)}) - y^{(i)}| \ge
\varepsilon$, os multiplicadores de Lagrange são diferentes de zero; e para pontos dentro
da região $\varepsilon$-insensível, os coeficientes $\alpha^{* \; (i)}, \alpha^{(i)}$ devem
desaparecer. Os vetores com coeficientes diferentes de zero são os chamados vetores
suporte. Basicamente, os vetores suporte são os vetores que suportam a ``superfície de
decisão'' ou o ``hiperplano'' que melhor se adequa aos dados, de acordo com o critério
especificado na Eq.~(\ref{eq:DF_svm_minimize}).

A configuração do modelo SVM consiste na escolha da função kernel e de seus parâmetros, e
na especificação de $\varepsilon$ e $C$.
Uma função kernel largamente utilizada para regressão é a função de base radial (RBF),
apresentada na Eq.~(\ref{eq:DF_svm_kernel}),
onde $\gamma$ é a largura de banda, o parâmetro de configuração.

\begin{equation}
    \textsf{K}(\mathbf{r}, \mathbf{r}^{(i)}) = \exp \left( - \frac{||\mathbf{r}-\mathbf{r}^{(i)}||^2}{2 \gamma^2} \right)
    \label{eq:DF_svm_kernel}
\end{equation}

\abreviatura{RBF}{Função de base radial}

A constante $C$ determina o custo-benefício entre a complexidade do modelo (suavidade) e o
grau de tolerância dos desvios maiores que $\varepsilon$ em (\ref{eq:DF_svm_minimize})
\cite{Cherkassky2004}.
Valores muito grandes de $C$ tornam o problema sem restrição; valores pequenos atribuem
mais peso para a regularização.
O parâmetro $\varepsilon$ controla a largura da zona de insensibilidade, usada para
adequar os dados de treinamento.
O valor de $\varepsilon$ é o parâmetro que possui maior efeito sobre o número de vetores
suporte.
Quanto maior for $\varepsilon$, menos vetores suporte são utilizados e mais ``suave''
torna-se a função $f$.


\subsection{Construção e Otimização dos Modelos}
%%%%%%%%%%%%%%%
% Falar sobre o objetivo dos modelos de predição, diferenciando-os da identificação de
% sistemas. (Learning from data)
% * Figura esquemática.
% * Minimização de um função custo
% * Detalhes sobre o AAKR (hines)
% * Detalhes sobre o SVM (Smola)
%%%%%%%%%%%%%%%

%Diferentemente da identificação de sistemas, os modelos empíricos de predição normalmente
%são construídos 
%%visando minimizar uma função custo
%com o objetivo de ``imitar'' as saídas de um sistema de forma mais precisa possível
%\cite{cherkassky2007learning}.
%A identificação de sistemas não depende da distribuição probabilística das observações de
%entrada, mas bons modelos de predição são normalmente dependentes dessa distruição, que
%geralmente é desconhecida. %% USAR FIGURA

%Considere o esquema apresentado na Figura . Segundo as técnicas de aprendizado
%preditivo, um modelo preditivo deve capturar as correlações entre as variáveis
%$\mathbf{r} \in \mathbb{R}^p$.

Partindo-se de uma técnica de regressão, constrói-se um modelo empírico a partir de um
conjunto de amostras de treinamento, compostas por pares entrada/saída.
As amostras de treinamento são exemplares de valores das variáveis de entrada juntamente
com os valores das variáveis de saída que se espera do modelo.
No caso de um modelo SVM, as amostras são compostas pelos valores de $p$ variáveis de
entrada e um valor correspondente à variável de saída.  Para um modelo AAKR, os pares
entrada/saída possuem o mesmo valor.

Para ambas as técnicas, a complexidade dos modelos podem ser especificadas por parâmetros
e deve ser ajustada para que se adeque à complexidade dos dados de treinamento.
Se o modelo não é flexível, ele não será capaz de modelar as relações dos dados de
treinamento; se o modelo é excessivamente complexo, problemas de sobreajustamento
(\textit{overfitting}) dos dados podem ocorrer, incluindo ruídos na modelagem.
Considerando o uso de funções kernel do tipo Gaussiana ou RBF, a complexidade dos modelos
(o grau de ajustamento do modelo aos dados de treinamento) SVM é determinada pelos
parâmetros $C$, $\varepsilon$ e $\gamma$; nos modelos AAKR, pelo parâmetro $h$.
Em muitas aplicações, esses valores podem são encontrados por tentativa e erro, ou
\textit{grid search}, onde treinam-se vários modelos com diferentes permutações de valores
de configuração e avalia-se a qualidade das predições destes atráves de um novo conjunto
de amostras.
O modelo com a configuração de melhor desempenho é adotado como o modelo final para o
sistema de validação.

Durante a construção de um modelo regressivo, um método simplório utilizado para se
determinar a complexidade adequada do modelo ao problema de aplicação consiste nos
seguintes passos:

\begin{enumerate}
    \item obter dois diferentes conjuntos de dados além do conjunto de treinamento, que
        podem ser chamados de conjunto de otimização e conjunto de teste;
    \item calcular o erro de predição de modelos de diferentes complexidades para o
        conjunto de otimização;
    \item selecionar o modelo que tenha apresentado o menor erro de predição do conjunto
        de dados de otimização;
    \item confirmar o desempenho do modelo selecionado calculando o erro de predição para
        o conjunto de teste.
\end{enumerate}

\noindent Os conjuntos de dados de otimização e teste devem ser semelhantes ao conjunto de
treinamento, no sentido de corresponder a comportamentos semelhantes do sistema, como
pontos de operação de uma planta.
O erro de predição é calculado a partir do resultado $f(\mathbf{r})$ do modelo e a saída
real $y$ do sistema para uma dada entrada $\mathbf{r}$.
Geralmente se usa o erro quadrático médio, como apresentado pela Eq.~(\ref{eq:mse}), como
representante do erro de predição, onde $n$ é a quantidade de observações utilizadas para a
construção do modelo.

\abreviatura{MSE}{Erro quadrático médio}

\begin{equation}
    \mbox{MSE} = \frac{1}{n} \sum \limits^n_{i=1} (y^{(i)} - f(\mathbf{r}^{(i)})) 
    \label{eq:mse}
\end{equation}

% TODO: identificação de sistemas x predição 
%Diferentemente da identificação de sistemas, os modelos empíricos de
%predição normalmente são construídos 
%%visando minimizar uma função custo
%com o objetivo de ``imitar'' as saídas de um sistema para uma determinada entrada.
%%\cite{cherkassky2007learning}.
%Entretanto, a construção do modelo é realizada a partir de um número finito $n$ de
%observações $\mathbf{r}$, consequentemente o modelo só pode ser uma estimação da solução
%ótima.

Segundo Cherkassky e Mulier~\cite{cherkassky2007learning}, existe o seguinte consenso: para métodos
flexíveis de aprendizado  com um número finito de amostras (como os métodos baseados em
kernel utilizados neste trabalho), as predições com melhor desempenho são obtidas por
modelos de complexidade ótima.
Deve-se preferir modelos mais simples a modelos complexos e otimizar a relação entre
complexidade e acurácia do modelo para o conjunto de dados de treinamento.

Existem métodos mais completos para o desenvolvimento e avaliação de modelos
regressivos\footnote{http://www.cedar.buffalo.edu/~srihari/CSE574/Chap3/Bias-Variance.pdf
\\http://blog.stephenpurpura.com/post/13052575854/managing-bias-variance-tradeoff-in-machine-learning
\\http://www.cedar.buffalo.edu/~srihari/CSE555/Chap9.Part2.pdf}, mas o método descrito
anteriormente é suficiente para a proposta deste trabalho. 

%% Flexibilidade x Complexidade
%% Minimização da incerteza


\section{Pós-processamento dos Sinais}

A etapa de pós-processamento dos sinais consiste na estimação dos desvios entre as
predições dos modelos empíricos e as variáveis que se deseja estimar.
A partir das estimativas dos desvios, é possível realizar uma ``pré-correção'' das
leituras provenientes dos sensores que servem como entrada dos modelos empíricos,
permitindo que as predições fiquem mais próximas dos verdadeiros valores das variáveis.

%Como dito na Seção \ref{sec:problemDefinition},
%os resíduos correspondem à diferença entre as predições do modelos e as medições dos
%sensores correspondentes.
%Considerando o sistema sensoriado operando na região de treinamento do modelo,
%as predições são virtualmente iguais às medidas realizadas pelos sensores quando estes se
%encontram funcionando corretamente, e os resíduos tendem a apresentar média zero e
%variância semelhante a do sensor.
%Anomalias nas medições dos sensores, como \textit{drift}, \textit{outliers}, mudanças
%abruptas, aumento da variância (errático) etc., causam mudanças nas características
%estatísticas esperadas nos resíduos e normalmente podem ser detectadas por técnicas
%estatísticas de detecção, como apresentado na Seção~\ref{sec:deteccao_drift}.

A seguir, apresenta-se a construção de um filtro de Kalman para a correção de sensores que
apresentem \textit{drift}.

\subsection{Filtro de Kalman}
\label{sec:kf}

Um possível modelo matemático usado para estimar a amplitude do \textit{drift} $d$ de um
sensor é apresentado na Eq. (\ref{eq:kf_dmodel}), onde $v^{(k)}$ é considerado um ruído
Gaussiano de média zero e variância $\sigma_v$. 

\begin{equation}
    {d}^{(k)} = {d}^{(k-1)} + {v}^{(k)}, \quad {v}^{(k)} \sim \mathcal{N} ({0}, \sigma_v)
    \label{eq:kf_dmodel}
\end{equation}

Em rastreamento de alvos (\textit{target tracking}), a Equação (\ref{eq:kf_dmodel})
é conhecida como o modelo matemático do comportamento dinâmico do alvo~\cite{Takruri2008}.
No caso de detecção de \textit{drift}, o objetivo é rastrear ou acompanhar a amplitude do
\textit{drift} de um sensor.
Se for assumido que um sensor apresenta desvios de forma suave, vagarosamente
crescente, linear ou exponencial, pode-se considerar o modelo da Eq. (\ref{eq:kf_dmodel})
como uma aproximação razoável.
Uma outra consideração deste modelo é a descorrelação entre \textit{drifts} de diferentes
sensores, mesmo sendo as variáveis de processo correlacionadas.

A observação do desvio no sensor estimado, dado por $$z = r - \hat{r},$$ não
corresponde ao valor verdadeiro do desvio, uma vez que este valor não está disponível.
Então, pode-se descrever a equação de medição como a Eq.~(\ref{eq:kf_observ}), onde
${q}^{(k)}$ é um ruído Gaussiano de variância $\sigma_q$.

\begin{equation}
    {z} = {d}^{(k)} +{q}^{(k)}, \quad {q}^{(k)} \sim
    \mathcal{N} ({0}, \sigma_q)
    \label{eq:kf_observ}
\end{equation}

Quando uma nova observação $r$ e a estimação de seu valor corrigido $\hat{r}$ estiverem
disponíveis, os seguintes passos são executados para se obter uma nova estimação do desvio
$d^{(k)}$ eventualmente presente no sensor:

\begin{enumerate}
    \item predição, $$\hat{d}^{(k|k-1)} = \hat{d}^{(k-1)}$$
    \item MSE mínimo da predição, $$M^{(k|k-1)} = M^{(k-1)} + \sigma_v$$
    \item ganho de Kalman, $$K = \frac{M^{(k|k-1)}}{\sigma_q + M^{(k|k-1)}}$$
    \item correção da estimativa, $$\hat{d}^{(k|k)} = \hat{d}^{(k|k-1)} + K (z -
        \hat{d}^{(k|k-1)})$$
    \item mínimo MSE, $$M^{(k|k)} = (1 - K) M^{(k|k-1)}.$$
\end{enumerate}

Para o emprego deste modelo de filtro de Kalman na estimação de desvios em sensores é
necessário determinar os valores dos parâmetros $\sigma_v$ e $\sigma_q$ para cada uma das
variáveis monitoradas.
No trabalho de Takruri~\cite{Takruri2008}, os parâmetros são escolhidos por tentativa e
erro.
Se um valor alto é usado para $\sigma_q$, as estimativas do desvio demoram mais para
seguir o desvio real; para valores pequenos de $\sigma_q$, as estimativas seguem qualquer
pequena diferença entre as predições $\hat{r}$ e as leituras $r$ do sensor.
O valor de $\sigma_v$ possui efeito contrário: valores altos emplicam em estimativas
instáveis do desvio que seguem qualquer pequena diferença entre as predições $\hat{r}$ e
as leituras $r$ do sensor; valores baixos implicam em maior lentidão para as estimativas
seguirem o desvio real.

As estimativas do desvio de um sensor podem ser usadas pelo menos de duas formas: indicar
a ocorrência de desvios intoleráveis e a consequente necessidade de manutenção do sensor;
e corrigir as leituras do sensor antes mesmo de serem utilizadas para predição pelo modelo
empírico, o que teoricamente proporcionaria predições mais próximas do valor verdadeiro da
variável mensurada.

\section{Monitoramento de Condição}
\label{sec:deteccao_drift}

A etapa de monitoramento da condição visa monitorar a condição de funcionamento dos
sensores, detectando a ocorrência de eventos e mudanças de estado.

A detecção de anomalias nos sensores é baseada na análise do erro entre as predições do
modelo e as medidas produzidas por eles, ou seja, o resíduo $d$ calculado pela Eq.
(\ref{eq:residuo}), onde $y$ é representa uma medida realizada pelo sensor que se deseja
monitorar e $f(\mathbf{r})$ é uma estimativa dessa medida a partir das medidas
$\mathbf{r}$ de sensores correlacionados.

\begin{equation}
    d = y - f(\mathbf{r})
    \label{eq:residuo}
\end{equation}

Considerando o sistema sensoriado operando na região de treinamento do modelo,
as predições são virtualmente iguais às medidas realizadas pelos sensores quando estes se
encontram funcionando corretamente, e os resíduos tendem a apresentar média zero e
variância semelhante a do sensor.
Anomalias nas medições dos sensores, como \textit{drift}, \textit{outliers}, mudanças
abruptas, aumento da variância (errático) etc., causam mudanças nas características
estatísticas esperadas nos resíduos e normalmente podem ser detectadas por técnicas
estatísticas de detecção~\cite{MauroVitordeOliveira2005}.
Dentre essas técnicas, podem-se citar: verificação de limites das propriedades
estatísticas, como média e a variância; auto-correlação dos resíduos; densidade de
potência dos resíduos; e o método SPRT.

No caso da detecção específica de \textit{drifts}, a verificação da incerteza das
predições do modelo também pode ser empregada~\cite{Hines2008a}.
Os métodos analíticos para os cálculos de incerteza são específicos para cada técnica de
modelagem empírica, enquanto métodos baseados em simulações Monte Carlo são gerais, mas
podem ser computacionalmente custosos.

Pela simplicidade de implementação e abrangência de anomalias detectáveis, neste
trabalho emprega-se o método SPRT, descrito a seguir.

\subsection{SPRT}

O método conhecido por SPRT, desenvolvido por Wald~\cite{wald1947sequential}, consiste em
testes estatísticos de hipóteses e tem sido aplicado frequentemente para a detecção de
anomalias em sistemas.
No caso de detecção de falhas em sensores, duas hipóteses são testadas a cada nova amostra
de dados do sistema: modo normal de operação, ou $H_0$, e modo degradado de operação, ou
$H_1$.
Aplicado aos resíduos gerados pela Eq.~(\ref{eq:residuo}), para cada nova amostra
$d^{(i)}$ do resíduo gerado para o sensor monitorado, uma das duas possíveis hipóteses é
aceita através da execução do seguinte procedimento:

\begin{enumerate}
    \item cálculo do logaritmo da razão de verossimilhança, dado pela
        Eq.~(\ref{eq:loglikelihood});
        \begin{equation}
            \Lambda^{(i)} = \ln \frac{P(d^{(i)} | H_1)}{P(d^{(i)} | H_0)}
            \label{eq:loglikelihood}
        \end{equation}
    \item cálculo da soma acumulativa de $\Lambda$, dado pela
        Eq.~(\ref{eq:cumulative_loglikelihood});
        \begin{equation}
            S^{(i)} = S^{(i-1)} + \Lambda^{(i)}
            \label{eq:cumulative_loglikelihood}
        \end{equation}
    \item verificação da regra de parada, um esquema simples de verificação de limites:
        \begin{itemize}
            \item se $\ln A < S^{(i)} < \ln B$, continua-se o monitoramento e o cálculo de
                $S^{(i+1)} = S^{(i)} + \Lambda^{(i+1)}$ (passo 2);
            \item se $S^{(i)}_p \le \ln A$, $H_0$ é aceita;
            \item se $S^{(i)}_p \ge \ln B$, $H_1$ é aceita e um aviso ou alarme é emitido.
        \end{itemize}
\end{enumerate}

\noindent $P(d^{(i)} | H_1)$ é a probabilidade de observar $d^{(i)}$ dado que $H_1$ é
verdadeira. $A$ e $B$ são respectivamente o limite inferior e superior, cujos valores
podem ser definidos pela probabilidade de ocorrência de falsos alarmes, $\alpha$, e pela
probabilidade de ocorrência de alarmes perdidos, $\beta$, como 
$$
A = \frac{\beta}{1 - \alpha}, \quad B = \frac{1 - \beta}{\alpha}.
$$

Supondo os resíduos como Gaussianos, normalmente o modo $H_0$ corresponde a um
sinal com média zero e variância semelhante a do sensor em questão, enquanto o modo $H_1$
corresponde a uma média diferente de zero ou a uma mudança no valor da variância.
Neste trabalho, assume-se que o \textit{drift} corresponda a uma mudança $\pm M$ na média
dos resíduos, enquanto a variância $\sigma^2$ se mantem inalterada.
Portanto, a função de distribuição de probabilidade dos resíduos de um sensor para o modo
$H_0$ é dada pela Eq.~(\ref{eq:pdf}).

\begin{equation}
    P(d^{(i)} | H_0) = \frac{1}{2 \pi \sigma^2} \exp \left(\frac{-{d^{(i)}}^2}{2 \sigma^2}
    \right)
    \label{eq:pdf}
\end{equation}

Considerando o modo degradado $H_1$ representado por mudanças positivas ($+M$) ou
negativas ($-M$) na média, o logaritmo da razão de verossimilhança é dado pela
Eq.~(\ref{eq:pdfM}).
Como sugerido por Hines e Garvey~\cite{Hines2008a}, o valor de $M$ pode ser determinado
numericamente aplicando o SPRT em conjuntos de dados livres de falhas e localizando um
valor de $M$ que resulte em uma probabilidade de alarmes falsos semelhante a $\alpha$.

\begin{equation}
    \Lambda^i =
    \left\{
        \begin{array}{ll}
            M / \sigma^2 (d^i - M/2), \quad \mbox{for a positive change} \\
            M / \sigma^2 (- d^i - M/2), \quad \mbox{for a negative change}
        \end{array}\right.
    \label{eq:pdfM}
\end{equation}


\chapter{Aplicação dos Sistemas Implementados a Dados de Poços de Petróleo}
\label{chap:ensaios}

% Descrição do sistema completo implementado, ou seja, sistema integrando os modelos
% empíricos de predição e o módulo estatístico de decisão.
% Palavras: predictive learning.

Neste capítulo são apresentados os sistemas implementados para monitoramento e validação
de sensores de poços de petróleo.
Os sistemas implementados são avaliados com diferentes conjuntos de dados, gerados a
partir de simulações ou a partir de sensores reais.
As métricas de desempenho e os resultados das avaliações também são apresentados a seguir.

\section{Sistemas de Validação de Sensores}

Descrevem-se a seguir três diferentes sistemas de validação de sensores implementados
neste trabalho, os quais se diferem pela técnica de modelagem e/ou pelo emprego do KF.

\subsection{Sistema 1 --- AAKR-SPRT}

O Sistema 1 é semelhante a um dos sistemas utilizados por
Hines et al.~\cite{Hines2008}, onde a técnica de modelagem utilizada é a AAKR e a
detecção de desvios é realizada pelo algoritmo SPRT.
Na Figura \ref{fig:aakr_sprt} é ilustrado o esquema de funcionamento do Sistema 1.

\begin{figure}[!htb]
    \centering\hspace*{-.7cm}
    \includegraphics[width=1.1\textwidth]{figuras/aakr_sprt.eps}
    \caption{Diagrama do processo de monitoramento pelo Sistema 1.}
    \label{fig:aakr_sprt}
\end{figure}

O modelo regressivo AAKR é desenvolvido usando o conjunto de dados $\mathbf{X}_{n_m \times
p}$, que permanece armazenado como memória para geração de predições.
Quando um novo vetor de leituras dos sensores $\mathbf{r}_{1 \times p}$ está disponível,
uma nova predição $\hat{\mathbf{r}}_{1 \times p}$ é calculada.
A diferença entre a leitura $\mathbf{r}_{1 \times p}$ e sua predição $\hat{\mathbf{r}}_{1
\times p}$, o resíduo $\mathbf{d}_{1 \times p}$, é analisada pelo algoritmo estatístico
SPRT para a indicação de ocorrências de falhas ou desvios, $D \in [0,1]$.

\subsection{Sistema 2 --- SVM-SPRT}

O Sistema 2 é composto por um modelo de regressão SVM e pelo algoritmo estatístico SPRT.
Como descrito na Seção \ref{sec:tec_regressao}, um modelo SVM possui estrutura
inferencial, sendo capaz de gerar predições para apenas uma variável.
Por consequência, para gerar predições de $p$ variáveis, como o modelo AAKR, são
necessários $p$ diferentes modelos SVM.
Na Figura \ref{fig:svm_sprt} é apresentado o esquema de funcionamento do Sistema 2 para o
monitoramento de uma variável.

\begin{figure}[!htb]
    \centering\hspace*{-.7cm}
    \includegraphics[width=1.1\textwidth]{figuras/svm_sprt.eps}
    \caption{Diagrama do processo de monitoramento de um único sensor pelo Sistema 2.}
    \label{fig:svm_sprt}
\end{figure}

Considerando o monitoramento de uma variável dentre um conjunto de $p$ variáveis
correlacionadas, quando novas leituras $\mathbf{r}_{1 \times p-1}$ e $y$ (onde $y$ corresponde
à leitura do sensor monitorado) estão disponíveis, uma nova predição $\hat{y}$ é calculada
pelo modelo SVM.
A diferença entre a leitura $y$ do sensor monitorado e sua predição $\hat{y}$, o resíduo
$d$, é analisada pelo algoritmo estatístico SPRT para a indicação de ocorrência de falhas
ou desvios, $D \in [0,1]$.

\subsection{Sistema 3 --- AAKR-KF-SPRT}

O Sistema 3 é composto por um modelo de regressão SVM, um filtro de Kalman e o algoritmo
estatístico SPRT.
Na Figura \ref{fig:aakr_kf_sprt} é ilustrado o esquema de funcionamento do Sistema 3.

\begin{figure}[!htb]
    \centering\hspace*{-.7cm}
    \includegraphics[width=1.1\textwidth]{figuras/aakr_kf_sprt.eps}
    \caption{Diagrama do processo de monitoramento pelo Sistema 3.}
    \label{fig:aakr_kf_sprt}
\end{figure}

No Sistema 3, as entradas do modelo AAKR correspondem às leituras corrigidas
$\mathbf{x}_{1\times p}$ dos $p$ sensores a partir de uma estimativa inicial dos
desvios $\hat{\mathbf{d}}_{1 \times p}^{k-1}$ e das leituras reais $\mathbf{r}_{1 \times p}$.
As predições $\hat{\mathbf{x}}_{1 \times p}$ geradas pelo modelo AAKR e as leituras reais
$\mathbf{r}_{1 \times p}$ são usadas como entradas do filtro de Kalman para a atualização
das estimativas dos desvios, $\hat{\mathbf{d}}_{1 \times p}^k$.
Finalmente, as novas estimativas $\hat{\mathbf{d}}_{1 \times p}^k$ são analisadas pelo
algoritmo SPRT para a indicação de ocorrência de falhas ou desvios, $D \in [0,1]$.


\section{Métricas de Desempenho}

Segundo Hines e Garvey~\cite{Hines2008a}, tradicionalmente o desempenho de sistemas de
monitoramento de calibração de sensores é mensurada a partir de três indicadores:
acurácia, autosensibilidade e sensibilidade cruzada.
A acurácia mensura a habilidade do modelo para gerar predições corretas e precisas das
leituras dos sensores.
A autosensibilidade indica a habilidade do modelo para gerar predições corretas de um
determinado sensor quando as leituras deste estão incorretas devido a algum tipo de falha.
Já a sensibilidade cruzada mensura o efeito dos dados de um sensor defeituoso sobre as
predições dos demais sensores.

A capacidade do modelo de predizer precisamente e corretamente os valores do sensor é
medido pelo erro de acurácia ($E_a$) que é normalmente apresentada como o erro médio
quadrático (MSE) entre as predições e as medições dos sensores.
A Equação (\ref{eq:ea_mse}) apresenta o cálculo de $E_a$ para uma variável, onde $N$ é o
número de amostras, $r^{(i)}$ é a amostra $i$ de um sensor livre de falhas e
$\hat{r}^{(i)}$ é a respectiva predição.

\simbolo{$E_a$}{Erro de acurácia}

\begin{equation}
    E_a = \frac{1}{N} \sum \limits_{i=1}^N \left( \hat{r}^{(i)} - r^{(i)} \right)^2
    \label{eq:ea_mse}
\end{equation}

A autosensibilidade $(S_A)$ mede a habilidade do modelo predizer corretamente quando a
própria medida do sensor está incorreta em razão de alguma falha (esta métrica não é
aplicada a modelos inferenciais como o SVM).
A Equação (\ref{eq:autosensibilidade}) apresenta o cálculo de $S_a$ para um determinado
sensor $k$, onde $\hat{r}^{(i)}_{drift}$ é a predição com desvio, $\hat{r}^{(i)}$ é a
predição sem desvio, enquanto $r^{(i)}_{drift}$ e $r^{(i)}$ são as entradas com e sem
desvio, respectivamente.

\simbolo{$S_A$}{Autosensibilidade}

\begin{equation}
    S_{A_k} = \frac{1}{N} \sum \limits_{i=1}^N \frac{\left| \hat{r}_{k, drift}^{(i)} -
    \hat{r}^{(i)}_{k} \right|}{\left| r_{k,drift}^{(i)} - r^{(i)}_{k} \right|}
    \label{eq:autosensibilidade}
\end{equation}

O efeito de uma entrada de sensor falho na predição das outras variáveis é calculado pela
sensibilidade cruzada $(S_C)$. Para um sensor sem desvio $j$ e um sensor com
desvio $k$, a sensibilidade cruzada é calculada como a Eq.
(\ref{eq:sensibilidade_cruzada}).

\simbolo{$S_C$}{Sensibilidade cruzada}

\begin{equation}
    S_{C_k} = \frac{1}{N} \sum \limits_{i=1}^N \frac{\left| \hat{r}_{j,drift}^{(i)} -
    \hat{r}^{(i)}_{j} \right|}{\left| r_{k,drift}^{i} - r_{k}^{(i)} \right|}
    \label{eq:sensibilidade_cruzada}
\end{equation}

Além das métricas tradicionais, adota-se neste trabalho uma métrica relativa ao erro de
predição ($E_p$) para entradas do modelo que podem conter desvios, calculado também pelo
MSE.
Diferentemente de $E_a$, onde as entradas não devem conter falhas ou desvios, o valor de
$E_p$ mede o erro das predições na presença de desvios em uma ou mais entradas do modelo.

\simbolo{$E_p$}{Erro de predição no caso de ocorrência de desvios nas entradas do sistema}

% predição ($E_p$) para sensores conhecidamente falhos, com presença de desvios em suas medições.
% Esta métrica é calculada pelo MSE entre a predição gerada pelo modelo regressivo, cujas
% entradas são as medidas de sensores que podem sofrer desvios, e o valor verdadeiro da variável
% monitorada pelo respectivo sensor, como apresentado na Eq. (\ref{eq:erro_predicao}), onde
% $\hat{r}^{(i)}_{|drift|}$.
% Sistemas de predição com menores valores de $E_a$ não apresentam necessariamente menores
% valores de $E_p$.
% 
% \begin{equation}
%     E_p = \frac{1}{N} \sum\limits^N_{i=1} \left( \hat{r}^{(i)}_{|drift|} - r^{(i)}
%     \right)^2
%     \label{eq:erro_predicao}
% \end{equation}

Os melhores sistemas para predição dos sensores de poços são aqueles com baixos valores de
$E_a$, $S_A$, $S_C$ e $E_p$.


\section{Ensaios}

Os ensaios apresentados a seguir visam avaliar a aplicabilidade dos sistemas desenvolvidos
a sensores de poços de petróleo.
A aplicabilidade é avaliada em dois aspectos principais:

\begin{itemize}
    \item consistência e qualidade das predições, ou seja, quão próximas estãos as
        predições e os valores corretos/verdadeiros que os sensores deveriam gerar;

    \item capacidade de detecção de desvios, ou seja, os sistemas devem detectar a
        ocorrência de desvios nas leituras de sensores e identificar qual ou quais deles
        estão defeituosos.
\end{itemize}

Os ensaios consistem em utilizar os sistemas implementados a conjuntos de dados e
simular situações em que se esperam os benefícios do uso de tais sistemas.
Os conjuntos de dados são compostos por amostras de diferentes sensores correlacionados,
localizados em diferentes pontos de um poço.
Inserindo desvios em algum dos sensores, os sistemas devem ser capazes de detectar a
ocorrência da falha, de acordo com um determinado valor de tolerância, e identificar qual
o sensor do grupo está defeituoso.

Os valores das métricas $E_a$ e $E_p$ indicam numericamente a proximidade das predições do
sistema em relação aos valores corretos dos sensores, que também pode ser notada pelos
gráficos comparativos das figuras.
As métricas de sensibilidade indicam a possibilidade de degradação das predições na
ocorrência de desvios em algum dos sensores.
Sistemas com grande sensibilidade a desvios podem gerar predições que seguem os próprios
desvios, o que impossibilita a detecção dos mesmos, ou que se tornam gradativamente mais
distantes das leituras do sensor correspondente mesmo quando este se encontra em bom
estado de funcionamento, acarretando em falsos alarmes de desvios.
A tolerância aceitável para a sensibilidade dos sistemas pode ser definida de acordo com
os resultados do algoritmo SPRT.
O algoritmo SPRT deve gerar alarmes para níveis intoleráveis de desvios (definidos pelo
valor de $M$) para o sensor defeituoso e gerar o mínimo possível de falsos alarmes para os
demais sensores, de forma que não comprometa a identificação do sensor defeituoso.

Com o intuito de verificar e entender o funcionamento dos sistemas, o primeiro ensaio foi
realizado com um conjunto de dados gerados pela simulação do modelo de um poço.
Aos corresponder as expectativas de aplicabilidade no primeiro ensaio, o segundo ensaio
foi realizado com um conjunto de dados coletados de sensores reais de um poço de produção
de petróleo.

\subsection{Ensaios com Dados de Simulação}

Os dados simulados foram gerados por um modelo de poço construído com simulador
OLGA\footnote{Mais informações o simulador são encontradas em
http://www.sptgroup.com/Products/olga/}.  
O modelo representa um poço operado por \textit{gas-lift} com um tubo de produção de 2500
metros de profundidade.
A pressão do separador foi mantida em 1000 kPa e o reservatório foi ajustado com uma
pressão de 18000 kPa.
Os dados simulados foram coletados durante 100 horas de produção de poço, enquanto a
vazão de gás injetado foi ajustado em diferentes valores, representando diferentes
condições de operação.
O conjunto de dados é composto pela pressão de fundo de poço
(PT$_f$), no topo do tubo de produção (PT$_t$), no topo do anular (PT$_g$) e a montante do
\textit{choke} de injeção (PT$_m$), como ilustrado na Fig. \ref{fig:poco_sim}.
A taxa de amostragem é de uma amostra por minuto. Um ruído branco com SNR (Relação
Sinal-Ruído) igual a $0.3$ foi adicionado às medições.
Os dados de cada uma das variáveis são apresentados na Fig. \ref{fig:sim_dataset}.

\begin{figure}[bt]
    \centering
    \includegraphics[width=.5\textwidth]{figuras/poco_simulado.ps}
    \caption{Esquema do poço usado para gerar os dados de simulação.}
    \label{fig:poco_sim}
\end{figure}

\begin{figure}[bt]
    \centering
    \includegraphics[trim=1.2cm 1.2cm 1.5cm 1cm,clip=true,width=.6\textwidth]{figuras/sim_dataset.eps}
    \caption{Dados de variáveis gerados pela simulação de um poço de petróleo.}
    \label{fig:sim_dataset}
\end{figure}

As 60 primeiras horas de dados foram usados para treinamento dos modelos AAKR e SVM. O
restante dos dados foi dividido em duas partes: 20 horas como conjunto de otimização e 20
horas como conjunto de testes.

Para os Sistemas 1 e 3 foram utilizados o mesmo modelo AAKR, construído a partir dos dados
de treinamento  e cujos parâmetros são $h = 0.1$ e $n_m = 600$ (20\% das amostras do
conjunto de treinamento).
Os parâmetros escolhidos advêm dos resultados apresentados no gráfico da Fig.
\ref{fig:mse_aakr_sim}, onde os melhores parâmetros são aqueles que apresentam menor
valor de MSE médio (ou $E_a$ médio) entre o conjunto de dados de otimização e suas
predições gerados pelo modelo.
Apesar de maiores quantidades de amostras resultarem em menores valores de MSE médio, a
partir de 600 amostras o ganho de desempenho foi insignificante.

\begin{figure}[bt]
    \centering
    \includegraphics[width=.7\textwidth]{figuras/mse_aakr_sim.eps}
    \caption{Relação entre o MSE médio e diferentes valores de largura de banda $h$ e
    vetores de memória $n_m$ para o modelo AAKR na predição do conjunto de dados de
    otimização gerados por simulação.}
    \label{fig:mse_aakr_sim}
\end{figure}

As configurações dos modelos SVM (um para cada variável monitorada) também foram obtidas a
partir do treinamento com o conjunto de dados de treinamento e da minimização do MSE entre
o conjunto de dados de otimização e suas predições.
Na Tabela \ref{tab:svm_sim_pars} são apresentados as configurações dos modelos.

\begin{table}[bt]
    \centering
    \caption{\label{tab:svm_sim_pars}Configuração dos modelos SVM construídos com
    conjunto de dados de treinamento gerados por simulação.}
    \begin{tabular}{lcccc}
        \toprule
        Variável & $\varepsilon$ & $C$ & $\gamma$ & Vetores suporte \\
        \midrule
        PT$_f$ & 0.05 & 0.5 & 0.25 & 234 \\
        PT$_t$ & 0.1 & 1 & 8 & 246 \\
        PT$_m$ & 0.1 & 8 & 4 & 331 \\
        PT$_g$ & 0.12 & 32 & 2 & 316 \\
        \bottomrule
    \end{tabular}
\end{table}

Para o Sistema 3, foi necessário determinar apenas os valores de $\sigma_v$ e $\sigma_q$
para cada uma das variáveis do modelo AAKR, uma vez que o modelo é o mesmo usado pelo
Sistema 1.
Inserindo desvios no conjunto de dados de otimização, foram selecionados os
valores de $\sigma_v$ e $\sigma_q$ que geraram estimativas mais próximas dos desvios
inseridos: $\sigma_v = 0.0001$ e $\sigma_q = 1$.

Na Tabela \ref{tab:DF_sensibilidades} são apresentados os resultados da análise de
sensibilidade e acurácia dos sistemas, avaliados com o conjunto de dados de teste.
Para tal análise, um desvio linearmente crescente terminando com uma magnitude
de $3\sigma$ (três vezes o desvio padrão dos dados da variável) foi introduzido
sequencialmente (em uma variável por vez) no conjunto de dados de teste.

\begin{table}[bt]
    \centering
    \caption{\label{tab:DF_sensibilidades} Valores médios das métricas de desempenho para
    os sistemas de monitoramento e validação de sensores:
    ($E_a$), autosensibilidade ($S_A$), sensibilidade cruzada ($S_C$) e erro de predição
($E_p$).} 
    \begin{tabular}{lcccc}
        \toprule
        & $E_a$ & $S_A$ & $S_C$ & $E_p$ \\
        \midrule
        Sistema 1 & 0.0020 & 0.2675 & 0.2682 & 0.0105 \\
        Sistema 2 & 0.0039 & & 0.3356 & 0.0139 \\
        Sistema 3 & 0.0023 & 0.2002 & 0.1997 & 0.0046 \\
        \bottomrule
    \end{tabular}
\end{table}

Nota-se pela Tab. \ref{tab:DF_sensibilidades} que o Sistema 1 apresentou maior acurácia dentre
os três sistemas, mas foi mais sensível a desvios quando comparado ao Sistema 3.
Apesar de apresentar menor acurácia e maior sensibilidade cruzada dentre os sistemas,
o Sistema 2 apresenta a vantagem de apresentar autosensibilidade nula, ou seja, as
predições relativas a um sensor com desvio não sofrem influência desta falha.
Apesar do melhor desempenho na presença de desvios, no Sistema 3  o filtro de Kalman acaba
estimando pequenos desvios mesmo na ausência de desvios reais, o que implicou em menor acurácia
em relação ao Sistema 1.

Na Figura \ref{fig:sim_pred_drift4} são ilustradas as predições dos três sistemas na
condição de ocorrência de desvios nas leituras da variável PT$_g$.
Nesta figura é possível notar as diferenças de desempenho retratadas pelos valores de
autosensibilidade ($S_A$), sensibilidade cruzada ($S_C$) e erro de predição ($E_p$).
O Sistema 1, com valores intermediários de $S_C$ e $E_p$, aparentemente apresenta predições
com menores $E_p$ que o Sistema 2 para as variáveis PT$_t$ e PT$_m$, mas piores
que o Sistema 3; no caso da variável PT$_f$, o modelo regressivo do Sistema 2 parece ser
mais independete dos valores de PT$_g$, uma vez que suas predições praticamente não foram
afetadas pelos desvios presentes em PT$_g$.
Com excessão das variáveis PT$_f$ e PT$_g$, o Sistema 2 foi o mais afetado pelos desvios,
confirmando seu maior valor de $S_C$, entretanto, as predições de PT$_g$
permanceram inalteradas pelos desvios, uma vez que a autosensibilidade do seu modelo
regressivo é nula.
O Sistema 3 apresenta, em geral, o melhor desempenho aparente entre os três sistemas,
confirmando as métricas de desempenho, gerando predições muito próximas do desejado mesmo
na ocorrência de desvios; entretanto, pelo valor de $E_a$, na ausência de desvios nas
leituras o Sistema 3 tende a ser menos preciso que o Sistema 1.

\begin{figure}[bt]
    \centering
    \includegraphics[trim=1cm .7cm 1cm .1cm, clip=true,width=.32\textwidth]{figuras/sim_sys1_pred_d4.eps}
    \includegraphics[trim=1cm .7cm 1cm .1cm, clip=true,width=.32\textwidth]{figuras/sim_sys2_pred_d4.eps}
    \includegraphics[trim=1cm .7cm 1cm .1cm, clip=true,width=.32\textwidth]{figuras/sim_sys3_pred_d4.eps}
    \caption{Predições dos sistemas para o conjunto de dados de testes gerados por
    simulação, com inserção de desvios na variável PT$_g$. Linhas vermelhas são
    as predições, linhas verdes são as leituras das variáveis (sujeitas a falhas) usadas
    como entradas dos sistemas e linhas azuis são os valores verdadeiros das variáveis
    (diferentes das linhas verdes apenas na ocorrência de falhas). Todos os dados foram
escalados no intervalo $[0,1]$.}
    \label{fig:sim_pred_drift4}
\end{figure}

Para a detecção automática de desvios e falhas, os algoritmos SPRT de cada um dos sistemas
foram configurados a partir do conjunto de dados de otimização.
Os valores de $M$ foram definidos como os menores valores para os quais o algoritmo SPRT
não gera nenhum falso alarme para os resíduos gerados por seus respectivos sistemas.
A Tabela \ref{tab:sim_sprt_conf} contem os valores de $M$ utilizados por cada um sistema e
para cada uma das variáveis monitoradas.

\begin{table}[bt]
    \centering
    \caption{\label{tab:sim_sprt_conf}Configurações do algoritmo SPRT para o conjunto de
dados de teste gerados por simulação.}
    \begin{tabular}{lcccc}
        \toprule
        & \multicolumn{4}{c}{Valores de $M$ por variável} \\
        & PT$_f$ & PT$_t$ & PT$_m$ & PT$_g$ \\
        \midrule
        Sistema 1 & 0.3 & 0.4 & 0.4 & 0.5 \\
        Sistema 2 & 0.2 & 0.45 & 0.5 & 0.6 \\
        Sistema 3 & 0.2 & 0.2 & 0.2 & 0.2 \\
        \bottomrule
    \end{tabular}
\end{table}

Para o caso de ocorrência de desvios nas leituras da variável PT$_g$, por exemplo, os
resultados da detecção automática pelos Sistemas 1 e 2 são ilustrados nas Figs.
\ref{fig:sim_sys1_sprt} e \ref{fig:sim_svm_sprt}.
Apesar dos falsos alarmes para as variáveis sem falhas, os Sistemas 1 e 2 detectaram
corretamente a ocorrência de desvios nas leituras de PT$_g$.
O impacto dos falsos alarmes pode ser reduzido ou até mesmo eliminado usando outras regras
simples sobre os resultados do algoritmo SPRT, como um limite para o número de decisões
positivas (ocorrência de desvios) consecutivas.
Por exemplo, poderia-se considerar a ocorrência de desvios apenas quando o algoritmo SPRT
gerasse $n$ ou mais resultados positivos consecutivos.
Outra alternativa é a sintonia mais precisa dos parâmetros do algoritmo SPRT.

\begin{figure}[bt]
    \centering
    \includegraphics[trim=1.5cm .7cm 1.1cm .7cm,clip=true,width=.4\textwidth]{figuras/sim_sys1_resid_d4.eps}
    \includegraphics[trim=1.5cm .7cm 1.1cm .7cm,clip=true,width=.4\textwidth]{figuras/sim_sys1_sprt_d4.eps}
    \caption{Resíduos gerados pelo Sistema 1 e resultados do algoritmo SPRT para o
    caso de ocorrência de desvios em PT$_g$ do conjunto de dados de simulação.}
    \label{fig:sim_sys1_sprt}
\end{figure}

\begin{figure}[bt]
    \centering
    \includegraphics[trim=1.5cm .7cm 1.1cm .7cm,clip=true,width=.4\textwidth]{figuras/sim_svm_resid_d4.eps}
    \includegraphics[trim=1.5cm .7cm 1.1cm .7cm,clip=true,width=.4\textwidth]{figuras/sim_svm_sprt_d4.eps}
    \caption{Resíduos gerados pelo Sistema 2 e resultados do algoritmo SPRT para o
    caso de ocorrência de desvios em PT$_g$ do conjunto de dados de simulação.}
    \label{fig:sim_svm_sprt}
\end{figure}

No caso do Sistema 3, a estimativa dos desvios sofreu menos interferência dos ruídos de
leitura, como pode ser notado na Fig. \ref{fig:sim_sys3_sprt}.
A correção efetuada pelo filtro de Kalman contribuíram para a melhoria da qualidade das
predições do modelo AAKR, gerando diferenças nítidas nas estimativas dos desvios das
leituras de cada variável.
Desta forma, o algoritmo SPRT conseguiu detectar corretamente e mais rapidamente a
ocorrência de desvios, além de ter gerado menos falsos alarmes.

\begin{figure}[bt]
    \centering
    \includegraphics[trim=1.5cm .7cm 1.1cm .7cm,clip=true,width=.4\textwidth]{figuras/sim_sys3_resid_d4.eps}
    \includegraphics[trim=1.5cm .7cm 1.1cm .7cm,clip=true,width=.4\textwidth]{figuras/sim_sys3_sprt_d4.eps}
    \caption{Resíduos gerados pelo Sistema 3 e resultados do algoritmo SPRT para o
    caso de ocorrência de desvios em PT$_g$ do conjunto de dados de simulação.}
    \label{fig:sim_sys3_sprt}
\end{figure}

\subsection{Ensaios com Dados Reais}

O conjunto de dados reais é composto pelas leituras de pressão de três diferentes
sensores de um poço de petróleo: um de fundo de poço (PDG), um na árvore de natal
(TPT) e outro a montante do \textit{choke} de injeção (PT$_m$).
Os dados foram coletados durante 955 horas de operação de poço, amostrados a uma taxa de 1
amostra/minuto.
Na Figura \ref{fig:real_dataset} são apresentados os gráficos de todo o conjunto de dados reais.
Os visíveis \textit{outliers} negativos representam, na verdade, leituras perdidas, não
armazenadas por algum motivo desconhecido.

As primeiras 400 horas de dados foram separadas como conjunto de treinamento dos modelos,
enquanto as 100 horas consecutivas foram usadas como conjunto de otimização e o restante
como conjunto de testes.

\begin{figure}[bt]
    \centering
    \includegraphics[trim=2cm .7cm 2cm .7cm,clip=true,width=.9\textwidth]{figuras/real_dataset.eps}
    \caption{Dados coletados por sensores de um poço de petróleo real, amostrados à taxa
    de uma amostra por minuto.}
    \label{fig:real_dataset}
\end{figure}

Novamente, os Sistemas 1 e 2 compartilharam o mesmo modelo AAKR, construído com $h=0.05$ e
$n_m=4800$ (~20\% do conjunto de dados de treinamento).
Assim como feito com os dados de simulação, os parâmetros do modelo foram selecionados
visando minizar o MSE das predições do conjunto de dados de otimização.
Neste caso, devido ao volume do conjunto de dados de treinamento, a quantidade $n_m$ de
amostras impactou significativamente no custo de tempo das predições.
Considerou-se 4800 amostras uma quantidade razoável para a relação entre desempenho
(valores de MSE) e custo das predições.

As configurações dos modelos SVM, obtidos a partir do conjunto de treinamento, são
apresentadas na Tab. \ref{tab:svm_real_pars}.
Os valores dos parâmetros foram obtidos por \textit{grid search} visando minimizar o MSE
das estimativas do conjunto de otimização.

\begin{table}[bt]
    \centering
    \caption{\label{tab:svm_real_pars}Configuração dos modelos SVM construídos com
    conjunto de dados reais de treinamento.}
    \begin{tabular}{lcccc}
        \toprule
        Variável & $\varepsilon$ & $C$ & $\gamma$ & Vetores suporte \\
        \midrule
        PDG & 0.12 & 256 & 512 & 5807 \\
        TPT & 0.08 & 32 & 128 & 2286 \\
        PT$_m$ & 0.05 & 4 & 0.0625 & 4176 \\
        \bottomrule
    \end{tabular}
\end{table}

Para o Sistema 3, utilizando o mesmo modelo AAKR do Sistema 1, foram selecionados os
parâmetros como $\sigma_v = 0.0001$ e $\sigma_q = 500$.
Em relação ao ensaio com dados de simulação, o valor mais alto de $\sigma_q$ se deve aos
sinais mais ruidosos dos dados reais, tornando as observações $z$ dos desvios (vide Seção
\ref{sec:kf}) menos confiáveis.

Na Tabela \ref{tab:real_sensibilidades} são apresentados os resultados da análise de
sensibilidade e acurácia dos sistemas, avaliados com o conjunto de dados de teste.
Novamente, um desvio linearmente crescente terminando com uma magnitude
de $3\sigma$ (três vezes o desvio padrão dos dados da variável) foi introduzido
sequencialmente (em uma variável por vez) no conjunto de dados de teste.

\begin{table}[bt]
    \centering
    \caption{\label{tab:real_sensibilidades} Valores médios das métricas de desempenho para
    os sistemas de monitoramento e validação de sensores:
    ($E_a$), autosensibilidade ($S_A$), sensibilidade cruzada ($S_C$) e erro de predição
($E_p$).} 
    \begin{tabular}{lcccc}
        \toprule
        & $E_a$ & $S_A$ & $S_C$ & $E_p$ \\
        \midrule
        Sistema 1 & 0.0035 & 0.3106 & 0.2806 & 0.0078 \\
        Sistema 2 & 0.0069 &  & 0.4754 & 0.0190 \\
        Sistema 3 & 0.0040 & 0.2418 & 0.2189 & 0.0046 \\
        \bottomrule
    \end{tabular}
\end{table}

Os resultados apresentados na Tab. \ref{tab:real_sensibilidades} corroboram as análises
dos sistemas com os dados gerados por simulação.
Apesar de possuir autosensibilidade nula, ou seja, a insensibilidade do sistema para gerar
estimativas de uma variável cujo sensor apresenta desvios, o Sistema 2 apresentou maior
sensibilidade aos desvios quando estes estão presentes em alguma das entradas do modelo
regressivo, como se pode constatar pelos valores mais altos de $E_a$, $E_p$ e $S_C$.
Além disso, o Sistema 2 possui a menor acurácia, ou seja, gerou estimativas piores mesmo
na ausência de falhas.
O Sistema 1 apresentou as melhores estimativas na ausência de desvios, entretanto,
apresentou maior sensibilidade em comparação ao Sistema 3.
Apesar das correções realizadas pelo filtro de Kalman na presença de desvios, o Sistema 3
estima pequenos desvios a partir das variações dos resíduos mesmo na ausência de desvios
reais nas leituras das variáveis, o que implicou em menor acurácia em relação ao Sistema
1.

As estimativas dos três sistemas na condição de ocorrência de desvios no
sensor PDG são ilustradas na Fig. \ref{fig:real_pred_d1}.
Os Sistemas 1 e 3 apresentaram estimativas bem semelhantes, porém as correções efetuadas
pelo filtro de Kalman no Sistema 3 tornaram as estimativas mais próximas das leituras
originais, no caso dos sensores PDG e TPT, e mais estáveis, no caso do sensor PT$_m$.
As estimativas do Sistema 2 apresentaram grande variância, mesmo no caso da estimação das
leituras do sensor PDG, onde as entradas do modelo regressivo não apresentavam desvios.
Além do próprio ruído original dos sensores, possivelmente as informações apenas de dois
dos sensores disponíveis são insuficientes para inferir com melhor qualidade as leituras
do terceiro.

\begin{figure}[bt]
    \centering
    \includegraphics[trim=1cm .7cm .8cm .1cm, clip=true,width=.32\textwidth]{figuras/real_aakr_pred_d1.eps}
    \includegraphics[trim=1cm .7cm .8cm .1cm, clip=true,width=.32\textwidth]{figuras/real_svm_pred_d1.eps}
    \includegraphics[trim=1cm .7cm .8cm .1cm, clip=true,width=.32\textwidth]{figuras/real_aakr_kf_pred_d1.eps}
    \caption{Predições dos sistemas para o conjunto de dados reais de testes, com inserção
        de desvios nas leituras do PDG. Linhas vermelhas são as predições,
        linhas verdes são as leituras dos sensores (sujeitas a falhas) usadas como
        entradas dos sistemas e linhas azuis são as leituras originais dos sensores
        (diferentes das linhas verdes apenas na ocorrência de falhas). Todos os dados
        foram escalados no intervalo $[0,1]$.}
        \label{fig:real_pred_d1}
\end{figure}

Para a detecção automática de desvios e falhas, os algoritmos SPRT de cada um dos sistemas
foram configurados a partir do conjunto de dados de otimização.
Os valores de $M$ foram definidos como os menores valores para os quais o algoritmo SPRT
não gera nenhum falso alarme para os resíduos gerados por seus respectivos sistemas.
A Tabela \ref{tab:real_sprt_conf} contem os valores de $M$ utilizados por cada um sistema e
para cada uma das variáveis monitoradas.

\begin{table}[bt]
    \centering
    \caption{\label{tab:real_sprt_conf}Configurações do algoritmo SPRT para o conjunto de
dados reais de teste.} 
    \begin{tabular}{lccc}
        \toprule
        & \multicolumn{3}{c}{Valores de $M$ por variável} \\
        & PDG & TPT & PT$_m$ \\
        \midrule
        Sistema 1 & 0.4 & 0.4 & 0.4 \\
        Sistema 2 & 1.0 & 0.5 & 0.5 \\
        Sistema 3 & 0.1 & 0.1 & 0.1 \\
        \bottomrule
    \end{tabular}
\end{table}

Para o caso de ocorrência de desvios no PDG, por exemplo, os resultados da detecção
automática pelos Sistemas 1, 2 e 3 são ilustrados nas Figs. \ref{fig:real_sys1_sprt},
\ref{fig:real_svm_sprt} e \ref{fig:real_sys3_sprt}, respectivamente.
Apesar dos falsos alarmes para os sensores TPT e PT$_m$, os resultados do algoritmo SPRT
do Sistema 1 apontaram corretamente a 
Pelos resultados do algoritmo SPRT na Fig. \ref{fig:real_sys1_sprt}, o Sistema 1 detectou
corretamente a ocorrência de desvios no PDG antes da ocorrência de vários falsos alarmes
consecutivos nos demais sensores.
Os falsos alarmes gerados próximos do instante 100 e 150 horas devem-se à uma possível
anomalia (visível também próximo do instante 600 horas na Fig. \ref{fig:real_dataset}) e a
um \textit{outlier}, citado anteriormente.
Na verdade, estes resultados apontam a possibilidade de emprego do sistema para a
indicação de outros tipos de falhas, como mudanças abruptas; entretanto, é de suma
importância se certificar que o conjunto de treinamento dos modelos regressivos abrange o
ponto de operação atual do poço.

\begin{figure}[bt]
    \centering
    \includegraphics[trim=1.5cm .7cm 1.1cm .7cm,clip=true,width=.4\textwidth]{figuras/real_sys1_res_d1.eps}
    \includegraphics[trim=1.5cm .7cm 1.1cm .7cm,clip=true,width=.4\textwidth]{figuras/real_sys1_sprt_d1.eps}
    \caption{Resíduos gerados pelo Sistema 1 e resultados do algoritmo SPRT para o
    caso de ocorrência de desvios nas leituras do PDG do conjunto de dados reais.}
    \label{fig:real_sys1_sprt}
\end{figure}


\begin{figure}[bt]
    \centering
    \includegraphics[trim=1.5cm .7cm 1.1cm .7cm,clip=true,width=.4\textwidth]{figuras/real_sys2_res_d1.eps}
    \includegraphics[trim=1.5cm .7cm 1.1cm .7cm,clip=true,width=.4\textwidth]{figuras/real_sys2_sprt_d1.eps}
    \caption{Resíduos gerados pelo Sistema 2 e resultados do algoritmo SPRT para o
    caso de ocorrência de desvios nas leituras do PDG do conjunto de dados reais.}
    \label{fig:real_svm_sprt}
\end{figure}

\begin{figure}[bt]
    \centering
    \includegraphics[trim=1.5cm .7cm 1.1cm .7cm,clip=true,width=.4\textwidth]{figuras/real_sys3_res_d1.eps}
    \includegraphics[trim=1.5cm .7cm 1.1cm .7cm,clip=true,width=.4\textwidth]{figuras/real_sys3_sprt_d1.eps}
    \caption{Resíduos gerados pelo Sistema 3 e resultados do algoritmo SPRT para o
    caso de ocorrência de desvios nas leituras do PDG do conjunto de dados reais.}
    \label{fig:real_sys3_sprt}
\end{figure}

Os resultados da detecção pelo Sistema 2, apresentados na Fig. \ref{fig:real_svm_sprt},
refletem o pior desempenho do sistema verificado pelas análises de sensibilidade da Tab.
\ref{tab:real_sensibilidades}.
Apesar de aparentar média próxima de zero, a grande variância das estimativas das leituras
do sensor TPT causaram a indicação incorreta de que o sensor com desvios seria o TPT.
Aparentemente, a ocorrência de desvios no PDG afetou de tal forma as estimativas das
leituras do TPT que a variância dos resíduos foi bem supeior à variância dos resíduos nas
estimativas do conjunto de otimização, usado para a configuração do algoritmo SPRT.

Pela Figura \ref{fig:real_sys3_sprt}, apesar das estimativas de desvios no TPT e
PT$_m$, nota-se que o Sistema 3 estimou corretamente o desvio verdadeiro no PDG, dada a
diferença de amplitudade entre os desvios estimados.
As estimativas dos desvios do PDG não conseguiram corrigir perfeitamente as leituras do
sensor, pois desvios crescentes, apesar de menor amplitude, também foram estimados no TPT
e no PT$_m$.
Entretanto, as correções efetuadas pelo filtro de Kalman do sistema foram suficientes para
uma indicação clara da ocorrência de desvios apenas no sensor PDG.
No caso do Sistema 3, o monitoramento e detecção de outros tipos de falhas deve ser
realizado pela análise dos resíduos (que neste caso não apontam desvios, uma vez que foram
subtraídos das entradas do modelo) entre as estimativas geradas pelo modelo regressivo e as
leituras dos sensores.


% \chapter{Versão antiga dos ensaios}
% \section{Ensaio --- Construção dos Modelos Empíricos}
% 
% \textcolor{red}{Escrever introdução}
% 
% Testes sem o filtro de Kalman com AAKR e SVM. Verificar qualidade das predições.
% Testes do AAKR com KF. Se possível, testar o SVM também, pelo menos para algumas
% variáveis.
% Testes com sinais filtrados (fácil para o caso de simulação).
% 
% \subsection{Dados de Simulação}
% 
% \subsubsection{AAKR}
% 
% O resultado do processo de otimização dos parâmetros do modelo AAKR é apresentado na
% Fig.~\ref{fig:mse_aakr_sim}.
% Modelos com valores altos de $h$ apresentaram grandes valores de MSE total, independente
% da quantidade de vetores de memória, $n_m$.
% Maiores valores de $n_m$ combinados com menores valores de $h$ tenderam a apresentar
% modelos com menor MSE total.
% Porém, apesar de não ser perceptível pela Fig.~\ref{fig:mse_aakr_sim}, para valores muito
% pequenos de $h$ ocorreram leves acréscimos no MSE total, para todos as quantidades
% $n_m$.
% Para evitar \textit{overfitting} e o armazenamento de grandes quantidades de dados
% desnecessariamente, escolheu-se $h = 0.1$ e $n_m = 600$ (20\% da quantidade amostras dos
% dados de treinamento).
% 
% %Nota-se que modelos com menor MSE apresentam maior equilíbrio entre acurácia e
% %capacidade de generalização, ou seja, são aqueles localizados entre modelos com pequena
% %largura de banda e alta variância e modelos com largura de banda maiores e estimações
% %polarizadas. Em relação ao tamanho da matriz de memória, matrizes maiores não implicam em
% %menor MSE; a partir de um certo tamanho, a inclusão de mais vetores não aumenta a acurácia
% %do modelo. Os parâmetros selecionados para a contrução do modelo final foram $h = $ e
% % vetores de memória.
% 
% % \begin{figure}[!htb]
% %     \centering
% %     \includegraphics[width=.7\textwidth]{figuras/mse_aakr_sim.eps}
% %     \caption{Relação entre o MSE total e diferentes valores de largura de banda $h$ e
% %     vetores de memória $n_m$ para o modelo AAKR aplicado aos dados de simulação para
% % otimização.}
% %     \label{fig:mse_aakr_sim}
% % \end{figure}
% 
% \subsubsection{SVM}
% 
% Os resultados da otimização dos parâmetros do modelo SVM são apresentados nas Tabelas
% \ref{tab:svm_sim_v1}, \ref{tab:svm_sim_v2}, \ref{tab:svm_sim_v3} e \ref{tab:svm_sim_v4}.
% Para cada valor de $\varepsilon$, os valores de $C$ e $\gamma$ são obtidos por busca em
% grade, variando-se os valores em potências de 2.
% Nota-se que o valor de $\varepsilon$ parece ser o principal determinante da quantidade de
% vetores suporte armazenados pelo modelo.
% Menores valores de $\varepsilon$ implicaram em maiores números de vetores suporte e
% menores valores do MSE.
% Entretanto, maior número de vetores suporte indicam modelos mais complexos, e modelos
% excessivamente complexos tendem a incluir ruídos na modelagem.
% Portanto, modelos com a mínima complexidade possível para se atingir valores de MSE
% toleráveis são normalmente as melhores opções.
% 
% \begin{table}[!hbt]
%     \centering
%     \caption{\label{tab:svm_sim_v1}Relação entre parâmetros do modelo SVM e o impacto no MSE na predição
% da variável PT$_f$ dos dados de simulação.}
%     \begin{tabular}{ccccc}
%         \toprule
%         $\varepsilon$ & $C$ & $\gamma$ & Vetores suporte & MSE ($\times 10^{-3}$)\\
%         \midrule
%         0.03 & 0.0625 & 2 & 813 & 0.752\\
%         \rowcolor{gray}0.05 & 0.5 & 0.25 & 234 & 0.778 \\
%         0.1 & 2 & 0.5 & 50 & 1.20 \\
%         0.2 & 2 & 2 & 15 & 3.90 \\
%         \bottomrule
%     \end{tabular}
% \end{table}
% 
% 
% 
% \begin{table}[!hbt]
%     \centering
%     \caption{\label{tab:svm_sim_v2}Relação entre parâmetros do modelo SVM e o impacto no MSE na predição
% da variável PT$_t$ dos dados de simulação.}
%     \begin{tabular}{ccccc}
%         \toprule
%         $\varepsilon$ & $C$ & $\gamma$ & Vetores suporte & MSE ($\times 10^{-3}$)\\
%         \midrule
%         0.05 & 32 & 2 & 1149 & 2.974 \\
%         \rowcolor{gray}0.1 & 1 & 8 & 246 & 2.991 \\
%         0.15 & 0.5 & 2 & 36 & 3.125 \\
%         0.2 & 4 & 0.125 & 7 & 3.408 \\
%         \bottomrule
%     \end{tabular}
% \end{table}
% 
% 
% \begin{table}[!hbt]
%     \centering
%     \caption{\label{tab:svm_sim_v3}Relação entre parâmetros do modelo SVM e o impacto no MSE na predição
% da variável PT$_m$ dos dados de simulação.}
%     \begin{tabular}{ccccc}
%         \toprule
%         $\varepsilon$ & $C$ & $\gamma$ & Vetores suporte & MSE ($\times 10^{-3}$)\\
%         \midrule
%         0.05 & 0.25 & 16 & 1220 & 3.572 \\
%         \rowcolor{gray}0.1 & 8 & 4 & 331 & 3.555 \\
%         0.15 & 0.5 & 8 & 52 & 3.624 \\
%         0.2 & 8 & 0.5 & 17 & 4.145 \\
%         \bottomrule
%     \end{tabular}
% \end{table}
% 
% 
% \begin{table}[!hbt]
%     \centering
%     \caption{\label{tab:svm_sim_v4}Relação entre parâmetros do modelo SVM e o impacto no MSE na predição
% da variável PT$_g$ dos dados de simulação.}
%     \begin{tabular}{ccccc}
%         \toprule
%         $\varepsilon$ & $C$ & $\gamma$ & Vetores suporte & MSE ($\times 10^{-3}$) \\
%         \midrule
%         0.1 & 0.125 & 8 & 525 & 5.642 \\
%         \rowcolor{gray}0.12 & 32 & 2 & 316 & 5.694 \\
%         0.15 & 0.25 & 4 & 133 & 5.764 \\
%         0.2 & 32 & 1 & 29 & 5.814 \\
%         \bottomrule
%     \end{tabular}
% \end{table}
% 
% Os modelos selecionados para o sistema de validação estão destacados nas Tabelas
% \ref{tab:svm_sim_v1}, \ref{tab:svm_sim_v2}, \ref{tab:svm_sim_v3} e \ref{tab:svm_sim_v4}.
% Foram priorizados modelos cujo número de vetores suporte fosse próximo ao número de vetores
% de memória do modelo AAKR, ou seja, próximo de 20\% do número de amostras do conjunto de
% treinamento.
% 
% 
% 
% \subsection{Dados Reais}
% 
% \subsubsection{AAKR}
% 
% O resultado do processo de otimização dos parâmetros do modelo AAKR é apresentado na
% Fig.~\ref{fig:mse_aakr_real}.
% Para este conjunto de dados, menores valores de $h$ realmente geraram menores valores de
% MSE total, exceto para quantidades $n_m$ muito pequenas.
% Entretanto, modelos com $h < 0.07$ apresentaram problemas
% numéricos para a predição dos dados de otimização, pois valores muito pequenos de
% $h$ geram modelos com baixa capacidade de generalização, onde os denominadores da
% Eq.~\ref{eq:aakr_var_pred} são muito próximos de zero.
% Para diminuir a possibilidade de problemas numéricos por baixa capacidade de generalização
% e ao mesmo tempo obter baixos valores de MSE total, adotou-se $h = 0.15$.
% %Considerou-se $h = 0.15$ como um valor equilibrado entre acurácia e capacidade de
% %generalização.
% %Portanto, assim como ocorreu com os dados de simulação, 
% %modelos com menor MSE apresentam maior equilíbrio entre acurácia e
% %capacidade de generalização.
% 
% Em relação ao número de vetores de memória, foi escolhido $n_m = 4800$, que corresponde a
% $20\%$ do conjunto de dados de treinamento. Maiores valores de $n_m$ apresentaram
% impacto insignificante na redução do MSE (alterações a partir da quarta casa decimal).
% 
% \begin{figure}[!hbt]
%     \centering
%     \includegraphics[width=.7\textwidth]{figuras/mse_aakr_real.eps}
%     \caption{Relação entre o MSE total e diferentes valores de largura de banda $h$ e
%     vetores de memória $n_m$ para o modelo AAKR aplicado aos dados reais para
% otimização.}
%     \label{fig:mse_aakr_real}
% \end{figure}
% 
% 
% \subsubsection{SVM}
% 
% Os resultados da otimização dos parâmetros do modelo SVM são apresentados nas Tabelas
% \ref{tab:svm_real_v1}, \ref{tab:svm_real_v2} e \ref{tab:svm_real_v3}.
% Para cada valor de $\varepsilon$, os valores de $C$ e $\gamma$ são obtidos por busca em
% grade, variando-se os valores em potências de 2.
% Nota-se que o comportamento dos modelos é semelhante para o conjunto de dados de
% simulação: o valor de $\varepsilon$ apresenta-se como principal determinante do número de
% vetores suporte e do limite inferior do MSE.
% Os modelos selecionados para o sistema de validação estão destacados nas Tabelas
% \ref{tab:svm_real_v1}, \ref{tab:svm_real_v2} e \ref{tab:svm_real_v3}.
% 
% \begin{table}[!hbt]
%     \centering
%     \caption{\label{tab:svm_real_v1}Relação entre parâmetros do modelo SVM e o impacto no MSE na predição
% do sensor PDG dos dados reais.}
%     \begin{tabular}{ccccc}
%         \toprule
%         $\varepsilon$ & $C$ & $\gamma$ & Vetores suporte & MSE \\
%         \midrule
%         0.5 & 0.5 & 1 & 19621 & 7.19 \\
%         0.8 & 32 & 0.25 & 17109 & 7.12 \\
%         1 & 0.25 & 0.5 & 15886 & 6.97 \\
%         \rowcolor{gray} 2 & 0.5 & 2 & 10662 & 7.00 \\
%         5 & 0.25 & 2 & 2221 & 8.86 \\
%         \bottomrule
%     \end{tabular}
% \end{table}
% 
% \begin{table}[!hbt]
%     \centering
%     \caption{\label{tab:svm_real_v2}Relação entre parâmetros do modelo SVM e o impacto no
% MSE na predição do sensor TPT dos dados reais.}
%     \begin{tabular}{ccccc}
%         \toprule
%         $\varepsilon$ & $C$ & $\gamma$ & Vetores suporte & MSE \\
%         \midrule
%         0.8 & 0.03125 & 0.03125 & 16775 & 4.36 \\
%         1.5 & 0.0625 & 0.5 & 10535 & 4.30 \\
%         2 & 0.0625 & 0.5 & 6922 & 4.25 \\
%         \rowcolor{gray}3 & 0.03125 & 0.5 & 3026 & 4.19 \\
%         4 & 0.03125 & 0.25 & 1087 & 4.22 \\
%         \bottomrule
%     \end{tabular}
% \end{table}
% 
% \begin{table}[!hbt]
%     \centering
%     \caption{\label{tab:svm_real_v3}Relação entre parâmetros do modelo SVM e o impacto no
% MSE na predição do sensor PT$_m$ dos dados reais.}
%     \begin{tabular}{ccccc}
%         \toprule
%         $\varepsilon$ & $C$ & $\gamma$ & Vetores suporte & MSE \\
%         \midrule
%         0.1 & 0.03125 & 32 & 20834 & 0.48 \\
%         0.5 & 0.03125 & 8 & 10117 & 0.47 \\
%         \rowcolor{gray}1 & 0.015625 & 0.25 & 2852 & 0.50 \\
%         2 & 128 & 0.125 & 143 & 0.80 \\
%         \bottomrule
%     \end{tabular}
% \end{table}
% 
% % \subsubsection{Comentários}
% % 
% % Para ambas as técnicas, o processo de otimização dos modelos norteada pelo MSE foi
% % fortemente influenciada pela largura de banda da função kernel.
% % Nos modelos AAKR, o MSE
% % total cresceu com o aumento dos valores de $h$, entretanto, valores muito pequenos
% % ocasionaram problemas numéricos.
% % Nos modelos SVM,
% % 
% % Não houve uma escolha automática das variáveis, usou-se senso de engenharia.
% 
% 
% \section{Ensaio --- Verificação de Acurácia}
% 
% % Supondo que exista uma seção descrevendo os critérios de avaliação.
% 
% 
% \subsection{Dados de Simulação}
% 
% \subsubsection{AAKR}
% 
% As predições do modelo AAKR para os dados de validação são apresentados na
% Fig.~\ref{fig:pred_mse_sim_aakr}.
% Nota-se que as predições correspondem à expectativa de serem bem similares aos valores
% originados obtidos na simulação, uma vez que os dados não possuem falhas de sensores.
% Os valores de MSE para as predições de cada variável do modelo são apresentados na
% Tab.~\ref{tab:mse_aakr_sim}.
% 
% \begin{figure}[!hbt]
%     \centering
%     \includegraphics[width=\textwidth]{figuras/pred_sim_aakr.eps}
%     \caption{Predição do modelo AAKR para o conjunto de dados de validação gerados por
%     simulação.}
%     \label{fig:pred_mse_sim_aakr}
% \end{figure}
% 
% \begin{table}[!hbt]
%     \centering
%     \caption{\label{tab:mse_aakr_sim}Resultados do cálculo do MSE para as predições do
% modelo AAKR para o conjunto de dados de validação gerados por simulação.}
%     \begin{tabular}{ccccc}
%         \toprule
%         & PT$_f$ & PT$_t$ & PT$_m$ & PT$_g$ \\
%         MSE & $1.0 \times 10^{-3}$ & $2.2 \times 10^{-3}$ & $2.4 \times 10^{-3}$ &
%         $2.5 \times 10^{-3}$ \\
%         \midrule
%         MSE médio & \multicolumn{4}{l}{$2.0 \times 10^{-3}$} \\
%         \bottomrule
%     \end{tabular}
% \end{table}
% 
% \subsubsection{SVM}
% 
% As predições dos modelos SVM para os dados de validação são apresentados na
% Fig.~\ref{fig:pred_mse_sim_svm}.
% Nota-se que as predições estão próximas dos valores originados pela simulação, uma
% indicação visual da qualidade das predições do modelo.
% 
% \begin{figure}[!hbt]
%     \centering
%     \includegraphics[width=\textwidth]{figuras/pred_sim_svm.eps}
%     \caption{Predição do modelo SVM para o conjunto de dados de validação gerados por
%     simulação.}
%     \label{fig:pred_mse_sim_svm}
% \end{figure}
% 
% 
% Os valores de MSE para as predições de cada variável, ou modelo, são apresentados na
% Tab.~\ref{tab:mse_svm_sim}.
% Em comparação ao modelo AAKR, em geral as predições do modelo SVM apresentaram maior MSE,
% ou seja, menor acurácia nas predições, exceto para a variável PT$_f$.
% 
% 
% \begin{table}[!hbt]
%     \centering
%     \caption{\label{tab:mse_svm_sim}Resultados do cálculo do MSE para as predições do
% modelo SVM para o conjunto de dados de validação gerados por simulação.}
%     \begin{tabular}{ccccc}
%         \toprule
%         & PT$_f$ & PT$_t$ & PT$_m$ & PT$_g$ \\
%         MSE & $0.749 \times 10^{-3}$ & $3.392 \times 10^{-3}$ & $3.996 \times 10^{-3}$ &
%         $5.621 \times 10^{-3}$ \\
%         \midrule
%         MSE médio & \multicolumn{4}{l}{$3.949 \times 10^{-3}$} \\
%         \bottomrule
%     \end{tabular}
% \end{table}
% 
% 
% \subsection{Dados Reais}
% 
% \subsubsection{AAKR}
% 
% As predições do modelo AAKR para os dados reais de validação são apresentados na
% Fig.~\ref{fig:pred_mse_real_aakr}.
% Nota-se que as predições apresentaram um comportamento mais suave que os sinais
% verdadeiros e não acompanharam tão bem as mudanças bruscas de valores.
% Tais características parecem corresponder ao agrupamento pobre de variáveis, uma vez que
% o sistema sensoriado apresenta alta complexidade e não linearidade no relacionamento entre
% as variáveis.
% Para lidar com casos deste tipo, normalmente é necessário formar agrupamentos com maior
% quantidade de variáveis correlacionadas ou, pelo menos, agrupar variáveis que apresentem
% forte correlação.
% 
% Os valores de MSE para as predições de cada variável do modelo são apresentados na
% Tab.~\ref{tab:mse_aakr_real}.
% 
% \begin{figure}[!hbt]
%     \centering
%     \includegraphics[width=\textwidth]{figuras/pred_real_aakr.eps}
%     \caption{Predição do modelo AAKR para o conjunto de dados reais de validação.}
%     \label{fig:pred_mse_real_aakr}
% \end{figure}
% 
% \begin{table}[!hbt]
%     \centering
%     \caption{\label{tab:mse_aakr_real}Resultados do cálculo do MSE para as predições do
% modelo AAKR para o conjunto de dados reais de validação.}
%     \begin{tabular}{cccc}
%         \toprule
%         & PDG & TPT & PT$_m$ \\
%         MSE & $7.9 \times 10^{-3}$ & $4.0 \times 10^{-3}$ & $2.3 \times 10^{-3}$\\
%         \midrule
%         MSE médio & \multicolumn{3}{l}{$4.7 \times 10^{-3}$} \\
%         \bottomrule
%     \end{tabular}
% \end{table}
% 
% \subsubsection{SVM}
% 
% 
% \section{Ensaio --- Análise de Sensibilidade e Detecção de \textit{Drifts}}
% 
% \subsection{Dados de Simulação}
% 
% \subsubsection{AAKR}
% 
% 
% \begin{table}[!hbt]
%     \centering
%     \caption{\label{tab:auto_sens_aakr_sim}Resultados do cálculo da autosensibilidade
%     do modelo AAKR para o conjunto de testes gerados por simulação.}
%     \begin{tabular}{cccc}
%         \toprule
%         PT$_f$ & PT$_t$ & PT$_m$ & PT$_g$ \\
%         \midrule
%         0.1038 & 0.2794 & 0.3169 & 0.3700 \\
%         \bottomrule
%     \end{tabular}
% \end{table}
% 
% 
% \begin{table}[!hbt]
%     \centering
%     \caption{\label{tab:cross_sens_aakr_sim}Resultados do cálculo da sensibilidade cruzada
%     do modelo AAKR para o conjunto de testes gerados por simulação.}
%     \begin{tabular}{llccccc}
%         \toprule
%         & \multicolumn{5}{c}{Entradas com desvio} & \multirow{2}{*}{Média}\\
%         & & PT$_f$ & PT$_t$ & PT$_m$ & PT$_g$ & \\
%         \midrule
%         \multirow{4}{*}{Saídas} & PT$_f$ & & 0.0984 & 0.0976 & 0.0952 & 0.0971 \\
%         & PT$_t$ & 0.2973 & & 0.2775 & 0.2707 & 0.2818\\
%         & PT$_m$ & 0.3253 & 0.3184 & & 0.3118 & 0.3185\\
%         & PT$_g$ & 0.3779 & 0.3748 & 0.3738 & & 0.3755\\
%         \bottomrule
%     \end{tabular}
% \end{table}
% 
% \subsubsection{SVM}
% 
% \begin{table}[!hbt]
%     \centering
%     \caption{\label{tab:cross_sens_svm_sim}Resultados do cálculo da sensibilidade cruzada
%     dos modelos SVM para o conjunto de testes gerados por simulação.}
%     \begin{tabular}{llccccc}
%         \toprule
%         & \multicolumn{5}{c}{Entradas com desvio} & \multirow{2}{*}{Média}\\
%         & & PT$_f$ & PT$_t$ & PT$_m$ & PT$_g$ & \\
%         \midrule
%         \multirow{4}{*}{Saídas} & PT$_f$ & & 0.1411 & 0.1102 & 0.0343 & 0.0952\\
%         & PT$_t$ & 0.5922 & & 0.3272 & 0.2890 & 0.4028 \\
%         & PT$_m$ & 0.6395 & 0.3618 & & 0.2704 & 0.4239 \\
%         & PT$_g$ & 0.2836 & 0.4161 & 0.5620 & & 0.4206 \\
%         \bottomrule
%     \end{tabular}
% \end{table}
% 
% 
% \subsection{Dados Reais}
% 
% \subsubsection{AAKR}
% 
% \subsubsection{SVM}
% 
% 
% \section{Ensaio --- Detecção de Desvios}
% 
% \subsection{Dados de Simulação}
% 
% \subsubsection{AAKR}
% 
% \begin{table}[!hbt]
%     \centering
%     \caption{\label{tab:sim_aakr_sprtconf}Valores de mudança na média $M$ das variáveis do
% modelo AAKR aplicado aos dados de simulação.}
%     \begin{tabular}{ccccc}
%         \toprule
%         & PT$_f$ & PT$_t$ & PT$_m$ & PT$_g$ \\
%         \midrule
%         $M$ & 0.3 & 0.4 & 0.4 & 0.5 \\
%         \bottomrule        
%     \end{tabular}
% \end{table}
% 
% \begin{figure}[!hbt]
%     \begin{center}
%         \hspace*{-3cm}
%         \includegraphics[width=1.4\textwidth]{figuras/sim_aakr_drift_detect_d1.eps}
%     \end{center}
%     \caption{Detecção de mudanças de média nos resíduos gerados pelos modelos AAKR
%     aplicados aos dados simulados de validação, com inserção de desvio artificial em
% PT$_f$.}
%     \label{fig:sim_aakr_drift_detec_d1}
% \end{figure}
% 
% 
% \subsubsection{SVM}
% 
% \begin{table}[!hbt]
%     \centering
%     \caption{\label{tab:sim_svm_sprtconf}Valores de mudança na média $M$ das variáveis do
% modelo SVM aplicado aos dados de simulação.}
%     \begin{tabular}{ccccc}
%         \toprule
%         & PT$_f$ & PT$_t$ & PT$_m$ & PT$_g$ \\
%         \midrule
%         $M$ & 0.2 & 0.4 & 0.4 & 0.5 \\
%         \bottomrule        
%     \end{tabular}
% \end{table}
% 
% Apesar da ocorrência de alarmes nas demais variáveis, grandes quantidades de decisões
% $H_1$ consecutivas só ocorreram na variável PT$_f$.
% 
% \begin{figure}[!hbt]
%     \begin{center}
%         \hspace*{-3cm}
%         \includegraphics[width=1.4\textwidth]{figuras/sim_drift_detect_d1.eps}
%     \end{center}
%     \caption{Detecção de mudanças de média nos resíduos gerados pelos modelos SVM
%     aplicados aos dados simulados de validação, com inserção de desvio artificial em
% PT$_f$.}
%     \label{fig:sim_drift_detec_d1}
% \end{figure}
% 
% \subsection{Dados Reais}
% 
% 
% \section{Ensaio --- Estimação de \textit{Drifts} com o KF}
% 
% 
% 
% % \textcolor{red}{Figura:} comportamento do mse para diferentes valores de bandwidth.
% % 
% % Pela análise dos resíduos gerados entre a predição do modelo selecionado e os dados de
% % otimização, os parâmetros selecionados para o algoritmo SPRT foram:
% % \textcolor{red}{variância}, $M = $, probabilidade de falso alarme igual a $1\%$ e
% % probabilidade de alarmes perdidos igual a $10\%$.
% % 
% % \subsubsection{AAKR-KF-SPRT}
% % 
% % Como os parâmetros $h = ?$ e $n_m = ?$ geraram o modelo com o melhor balanço entre
% % acurácia e capacidade de generalização para os dados de treinamento, tais valores também
% % foram adotados para o modelo AAKR do sistema AAKR-KF-SPRT. A busca pelos melhores valores
% % no espaço dos parâmetros $\mathbf{Q}$ e $\mathbf{V}$ do KF resultou nos valores
% % $\mathbf{Q} = \mathbf{I} \; ?$ e $\mathbf{V} = \mathbf{I} \; ?$; a Figura ?? apresenta o
% % comportamento do MSE para os diferentes valores dos parâmetros do KF.
% 
% 
% 
% 
% 
\chapter{Conclusões}
\label{chap:conclusoes}

% Revisão da importância do monitoramento de calibração.
% Revisão da sistema implementado e sua relação com a estrutura OSA-CBM.
% Revisão dos experimentos realizados e os resultados obtidos. Resumir as vantagens e
% desvantagens da abordagem escolhida, analisar de forma crítica as contribuições da
% dissertação.
% 
% Não foi realizado um estudo da escolha das variáveis/agrupamento.
% 
% Perspectivas de trabalhos futuros.

Neste trabalho foram apresentados o desenvolvimento e a implementação de sistemas de
monitoramento e validação de sensores de poços de petróleo, utilizando técnicas de
aprendizado de máquina para a construção de modelos empíricos baseados em histórico de
dados\footnote{Parte deste trabalho foi publicado no \textit{workshop} em automação e
controle em plataformas de petróleo e gás, IFAC \cite{Boechat2012}.}.
O emprego de tais sistemas visa garantir a qualidade e veracidade das informações coletadas
pelos sensores, normalmente essenciais para ações de controle, otimização da produção e
tomadas de decisões estratégicas para o negócio, além de preservar a segurança das
operações.

Pensando na complexidade de todo o processo de produção petrolífero e na possibilidade de
integração com sistemas de manutenção mais abrangentes, os sistemas propostos foram
estruturados de acordo com uma arquitetura aberta para sistemas de manutenção baseados na
condição de funcionamento (CBM), a OSA-CBM.
Para o desenvolvimento dos modelos empíricos baseados em histórico, duas diferentes
técnicas de regressão foram analisadas: a regressão por kernel auto-associativa (AAKR) e a
\textit{Support Vector Machines} (SVM).
Foi apresentado um filtro de Kalman para a estimação de desvios, visando tanto um ganho de
desempenho das predições dos modelos empíricos quanto uma alternativa para a detecção
automática de desvios nos sensores.
A detecção de desvios nos sensores foi realizado pelo algoritmo SPRT, através da análise
de mudanças nas propriedades estatísticas dos resíduos ou das estimativas de desvios
realizadas pelo filtro de Kalman.

Para verificar a aplicabilidade do trabalho desenvolvido, foram realizados ensaios com
três diferentes sistemas de validação: o Sistema 1, composto por um modelo AAKR; o Sistema
2, composto por um modelo SVM; e o Sistema 3, composto por um modelo AAKR (devido aos
melhores resultados nos ensaios quando comparado ao modelo SVM) e um filtro de Kalman.
A avaliação dos sistemas considerou quatro diferentes métricas: acurácia ($E_a$),
autosensibilidade ($S_A$), sensibilidade cruzada ($S_C$) e os erros de predição na
presença de desvios ($E_p$).
Em relação à detecção automática de desvios, avaliou-se os sistemas pela influência de
falsos positivos na decisão final do sistema.
Dois diferentes conjuntos de dados foram usados para os ensaios: um conjunto de dados
gerados pela simulação do modelo de um poço de petróleo e um conjunto de dados coletados
de sensores de um poço real.

Em ambos os ensaios, com dados simulados e reais, o Sistema 3 apresentou menor
sensibilidade a desvios e o menor erro de predição $E_p$ quando comparado ao Sistema 1,
porém apresentou menor acurácia (maior $E_a$).
Apesar das diferenças de desempenho, ambos os sistemas foram capazes de detectar
corretamente a ocorrência de desvios.
O Sistema 2, embora possua autosensibilidade nula de forma inerente, apresentou valores
piores de $E_a$, $E_p$ e $S_C$ para os dois conjuntos de dados.
No caso dos dados de simulação, o pior desempenho não impediu que o sistema detectasse
corretamente a ocorrência de desvios.
Entretanto, para o conjunto de dados reais, o Sistema 2 não foi capaz de gerar predições
consistentes e detectar a ocorrência de desvios corretamente, gerando uma quantidade
inaceitável de falsos alarmes e impossibilitando a identificação do sensor defeituoso.

Embora os resultados apontem o emprego de modelos AAKR e do filtro de Kalman como
promissores, não se pode descartar o uso de modelos SVM para sistemas de monitoramento e
validação de sensores.
É preciso considerar a pequena quantidade de sensores disponíveis no conjunto de dados
reais.
Possivelmente, em grupos maiores de sensores correlacionados os modelos SVM podem
apresentar desempenhos melhores.

Tanto os sistemas compostos por modelos AAKR quanto por modelos SVM poderiam gerar
melhores predições com o emprego de técnicas automáticas de agrupamento ótimo de sensores,
que deve ser considerado para trabalhos futuros.
Além disso, a aplicação de métodos automáticos para validação dos próprios modelos
empíricos seria desejável, uma vez que as características de um poço de petróleo mudam ao
longo de sua vida útil, assim como o comportamento da correlação entre as variáveis
mensuradas pelos sensores.
Finalmente, vislumbra-se a possibilidade de contruir modelos SVM de séries temporais, onde
a saída do modelo não dependa apenas das entradas atuais, mas também de entradas
anteriores \cite{Chen2004}.

