\chapter{Introdução}

%\textcolor{red}{Motivação. Problema de drift em sensores de poços de petróleo, demanda por
%validação de dados, dificuldades atuais, importância de sistemas de monitoramento de
%calibração.}

Na industria petrolífera, o emprego de sensores nos poços de produção possui papel
fundamental tanto na segurança quanto no desempenho das operações. Os dados coletados
fornecem medidas das condições de funcionamento de equipamentos e de parâmetros
diretamente relacionados com as ações de controle, otimização da produção e monitoramento.
O operador da planta interpreta as medições baseado na sua experiência e conhecimento do
sistema, e toma decisões que podem ser cruciais durante situações de emergência.
Entretanto, devido às condições degradantes a que ficam submetidos, os sensores de poços
normalmente apresentam algum tipo de falha ou \textit{drift} (desvio nas medidas) durante
o período produtivo de um poço. Trocas ou reparos desses sensores raramente ocorrem, mesmo
quando se sabe que as medições estão incorretas, uma vez que possuem difícil acesso e alto
custo de manutenção \cite{Davies2007}, principalmente em plataformas \textit{offshore}.
Por isso, a validação das leituras dos sensores e a determinação de seus estados de
funcionamento são competências altamente desejáveis.

Em diversos setores da indústria, a validação de sensores é realizada através dos métodos
tradicionais de manutenção, os quais envolvem a calibração periódica dos instrumentos.
Várias técnicas de calibração periódica necessitam de paradas dos processos de produção
e/ou de se retirar de operação os instrumentos de medição. Entretanto, como apresentado em
\cite{Hines2008}, estudos recentes mostraram que menos de 5\% da calibração manual
realizada é sequer necessária. Além disso, a confiabilidade de um instrumento pode ser
afetado de forma adversa pelas intervenções manuais.

%TODO: usar este texto
%\textcolor{blue}{Operador interpreta os dados dos sensores e decide sobre o estado de
%funcionamento dos mesmos. Problema para análise de uma grande quantidade de sinais,
%necessidade de conhecimentos especialistas. (Ver artigo do Rio Automação e tese do Mauto
%Vitor)}

Por essas e outras razões, como a competitividade de mercado, tem crescido a procura por
estratégias menos invasivas e mais eficientes. Técnicas de manutenção baseadas em condição
(CBM --- \textit{Condition Based Maintenance})
tendem à manutenção ótima, pois o desempenho dos instrumentos é monitorado durante a
operação da planta e recalibrações físicas são realizadas apenas esse desempenho está
degradado.  Na literatura, esses métodos têm sido chamados de monitoramento
\textit{on-line} de calibração (OLM --- \textit{On-line
Monitoring}).

\abreviatura{CBM}{Manutenção baseada em condição}
\abreviatura{OLM}{On-line Monitoring}

O monitoramento de calibração baseia-se essencialmente em estimar as medidas corretas que
deveriam ser realizadas pelos sensores, comparando-as com as reais medidas efetuadas pelos
mesmos. Para isso, existem duas abordagens atualmente utilizadas: redundância por
\textit{hardware} e redundância analítica \cite{Ma2011}.

Na redundância por
\textit{hardware}, sensores redundantes são utilizados para medirem uma mesma variável,
possibilitando formas mais simples e intuitivas de estimação dos valores corretos das
medições (pela média das medições, por exemplo). Porém, a redundância por
\textit{hardware} inclui a possível necessidade de sensores extras, além de apresentar
dificuldades na detecção de sensores descalibrados que apresentam \textit{drift} na mesma
direção. Além disso, no caso dos sensores de fundo de poço, componentes redundantes ocupam
um valioso e limitado espaço, e consomem uma energia preciosa.

A outra abordagem, por redundância analítica, consiste na estimação das medidas
dos sensores baseando-se em outras medidas correlacionadas disponíveis no sistema. Existem
duas formas principais de modelagem dessas correlações: a modelagem por equações físicas
que descrevem as interações entre as variáveis e modelagem baseada em dados. 
Os modelos
baseados em equações físicas, apesar de serem normalmente muito precisos, necessitam de
significativos esforços de engenharia e são muito sensíveis à mudanças ou degradações não
previstas no sistema. 
Os modelos empíricos baseados em dados, ou histórico, também se
baseiam em medidas correlacionadas dentro do sistema, mas essas correlações ficam
implícitas, capturadas por técnicas de inteligência artificial e aprendizado de
máquinas
durante a análise de dados de medições livres de falhas, coletados
durante situações normais de operação da planta. Apesar de serem normalmente limitados a
trabalharem em pontos de operação da planta semelhantes aos quais foram treinados, os
modelos empíricos possuem diversos benefícios práticos, como: aplicabilidade livre de contexto, ou
seja, a essência dos modelos podem ser aplicados a quaisquer tipos de sistemas, sem a
necessidade de conhecimentos específicos sobre este; simplicidade de desenvolvimento, uma
vez que não existe a necessidade de modelos explícitos, o que torna-se um atrativo quando
se trata de sistemas complexos; e flexibilidade de configuração,
facilitando a configuração dos modelos para atender a novos requisitos de
desempenho ou a mudanças na própria planta. 

Esta dissertação tem como foco o desenvolvimento e implementação de um sistema de
monitoramento do desempenho de sensores de poços de petróleo, cujas técnicas são baseadas
em técnicas de aprendizado de máquina e modelos empíricos construídos com histórico de
dados.  Como as técnicas baseadas em modelos empíricos são livres de contexto, este
trabalho possui potencial aplicação para diversas outros setores industriais.


\section{Definição do problema e abordagens existentes}
\label{sec:problemDefinition}

%\textcolor{red}{Problema de drift em sensores em geral, citando a literatura.
%Aboradagem escolhida para este trabalho e a justificativa para tal. UPDATE: focar no
%problema de validação de sensores de forma geral, não somente em drift. Falhas abruptas
%também podem ser inseridas nos sinais (seguir tabela 5.5 da tese do Mauro Vitor)}

\textcolor{red}{TODO:} Explicitar diferença entre predição e estimação.

Como apresentado em \cite{MauroVitordeOliveira2005}, a validação de sinal pode ser
definida como a detecção, isolamento e caracterização de sinais falhos. Em sistemas OLM, a
validação de sinais também é referida como a identificação de falhas em sensores
acompanhada da estimativa ou predição das medições corretas, durante o funcionamento da
planta ou processo.

Os sensores de poços são passíveis a vários tipos de falhas, como mudanças abruptas,
polarização (\textit{bias}), picos etc. O principal tipo de falha tratado neste trabalho é
o \textit{drift} ou desvio de medição. Na literatura, o \textit{drift} é normalmente
definido como um desvio lento, continuo ou incremental, das medições de um sensor ao longo
do tempo.

% TODO: verificar utilidade deste texto
%Uma das dificuldades da identificação de falhas em sensores é discernir entre a ocorrência de
%uma falha e a ocorrência de mudanças no processo ou na planta. Poços de petróleo possuem
%características dinâmicas que mudam ao longo da vida produtiva dos mesmos, afetando a
%correlação entre as variáveis medidas pelos sensores. Na prática, isso implica em
%insegurança na interpretação dos dados pelo operador, produção abaixo da capacidade real,
%desgaste prematuro de equipamentos, maior risco de acidentes e, consequentemente, maiores
%custos.

A abordagem por modelos empíricos baseados em dados normalmente assume uma premissa
fundamental: as variáveis medidas pelos sensores são correlacionadas, enquanto as
possíveis falhas nesses instrumentos são descorrelacionadas. Essa premissa implica que
%comparando-se situações normais e de falhas,
%ocorre uma mudança na correlação entre os dados gerados pelos sensores
existem diferenças entre as correlações dos dados gerados em situações normais e as dos
dados gerados em situações de falhas.
%em situações de falha de sensores, a correlação entre os dados gerados pelos sensores é
%diferente da correlação verdadeira entre as variáveis.
Os modelos são
normalmente desenvolvidos utilizando histórico de medições livres de erros, capturando a
correlação verdadeira entre as variáveis. Depois de construídos, esses modelos conseguem
gerar estimativas das medições corretas dos sensores, as quais são comparadas com as
medições reais afim de se identificar e isolar possíveis falhas.
Casos de sucesso no emprego de tais técnicas na indústria já foram reportados, como
é o caso das plantas de energia nuclear \cite{Ma2011}.

Normalmente, os sistemas de monitoramento de desempenho de sensores baseados em modelos
empíricos segue o esquema apresentado na Fig. \ref{fig:chap1_ddfdd}.  Supondo uma matriz
de dados de treinamento $\mathbf{X} \in \mathbb{R}^{n \times p}$, onde $n$ é número de amostras
de treino e $p$ é a quantidade de variáveis amostradas, um modelo empírico $f$ é treinado
usando $\mathbf{X}$. Quando novas medições $\mathbf{r} \in \Re^{1\times p}$ tornam-se
disponíveis, estimações de $\mathbf{r}$ são obtidas por $\hat{\mathbf{r}} = f(\mathbf{r})$
e resíduos são gerados como $\mathbf{d} = \mathbf{r} - \hat{\mathbf{r}}$. A ocorrência de
\textit{drift} nas medições causa mudanças nas relações entre as variáveis de
$\mathbf{r}$, o que resulta em mudanças estatísticas anormais nos resíduos. Então,
avaliando estatisticamente os resíduos podem-se estabelecer as condições de operação ou
saúde dos sensores \cite{Ma2011}.

\begin{figure}[!htb]
    \centering
    \includegraphics[width=.9\textwidth]{figuras/data_driven_fdd.eps}
    \caption{Esquema de funcionamento de sistemas baseados em modelos empíricos para
    monitoramento de desempenho de sensores. Adaptado de \cite{Ma2011}.}
    \label{fig:chap1_ddfdd}
\end{figure}

Inicialmente vários trabalhos empregaram redes neurais para o
desenvolvimento de modelos, mas atualmente as técnicas baseadas em kernel estão entre as
mais utilizadas. 

Em \cite{Hines1998}, um sistema de monitoramento de desempenho de
sensores foi implementado utilizando basicamente
uma rede neural auto-associativa (AANN) como modelo empírico e o algoritmo SPRT
(\textit{Sequential Probability Ratio Test}) para a análise das propriedades estatísticas
dos resíduos.
O sistema foi avaliado em dados de plantas nucleares, envolvendo problemas como
\textit{drifts} e erros grosseiros nos sensores.
%As estimações geradas pela rede eram
%comparadas às leituras dos sensores para a formação
%dos resíduos, cujas propriedades estatísticas, analisadas pelo módulo estatístico com o
%algoritmo SPRT (\textit{Sequential Probability Ratio Test}),
%indicavam a ocorrência de falhas ou \textit{drifts}.

\abreviatura{AANN}{Redes neurais artificiais auto-associativas}
\abreviatura{SPRT}{Sequential Probability Ratio Test}

Em \cite{Gribok2000} foi realizada uma comparação entre diferentes técnicas estatísticas
para a predição de dados de plantas nucleares. Entre as técnicas utilizadas, encontram-se
redes neurais, mínimos quadrados ordinários, regressão kernel, MSET (\textit{Multivariate
State Estimation Techniques}) e SVM (\textit{Support Vector Machines}). Os resultados
apontaram as técnicas baseadas em kernel como promissoras.

\abreviatura{MSET}{Multivariate State Estimation Techniques}
\abreviatura{SVM}{Support Vector Machines}

Em \cite{Zavaljevski2000} foi realizada a validação de sensores de reatores nucleares
utilizando uma combinação de kernels MSET e do método SVM. As predições eram comparadas
com os dados dos sensores para a formação de resíduos, cujas propriedades estatísticas
eram analisadas usando SPRT para a detecção de falhas.

Em \cite{Garvey2007} foram apresentados os resultados da aplicação da técnica de regressão
kernel auto-associativa (AAKR) a conjuntos de sensores de plantas nucleares. Diferentes
métricas são apresentadas para a avaliação de desempenho dos modelos AAKR e a detecção de
\textit{drifts} é realizada pela análise de incerteza dos modelos.

\abreviatura{AAKR}{Regressão kernel auto-associativa}

Em \cite{Davies2007} foi feito um estudo sobre o uso de redes neurais para a predição de
dados de sensores de fundo de poços de petróleo e estimação de parâmetros de
reservatórios. A detecção de sensores degradados foi realizada por análises de limites
(\textit{thresholds}) dos valores dos resíduos.

Em \cite{Takruri2008} foi proposto um novo algoritmo para correção de medições de redes de
sensores sem fio. O algoritmo foi concebido para trabalhar de forma descentralizada, sendo
executado por cada sensor correlacionado de uma rede. Cada sensor recebe as leituras de
sensores correlacionados, com as quais infere a própria leitura utilizando um modelo SVM.
A leitura inferida e a leitura real são utilizadas por um filtro de Kalman (KF) que possui um
modelo genérico de \textit{drift}, gerando uma estimação da leitura correta, ou
verdadeira, do sensor em questão.

\abreviatura{KF}{Filtro de Kalman}

Neste trabalho, os modelos empíricos foram desenvolvidos utilizando AAKR ou SVM. A técnica
AAKR possui implementação simples e esforço mínimo para o desenvolvimento de modelos,
quando comparado às demais técnicas. A técnica SVM possui característica inferencial, o
treinamento dos modelos é mais simples, comparado às redes neurais, e gera resultados
estáveis.



\section{Objetivos e Contribuições}

Esta dissertação tem como principais objetivos:

\begin{itemize}
    \item Desenvolver um sistema de validação de sensores baseado em modelos
        empíricos e técnicas de aprendizado de máquina;
    \item Ensaiar diferentes técnicas de modelagem empírica e configurações do sistema;
    \item Ensaiar e avaliar o sistema de validação de sensores para dados de poços de
        produção de petróleo;
    \item Apresentar um esquema de funcionamento do sistema de validação de sensores
        dentro de uma arquitetura mais genérica para sistemas de monitoramento e
        manutenção baseado em condição.
\end{itemize}

Como principais contribuições deste trabalho, podem-se destacar:

\begin{itemize}
    \item Aplicação ao cenário de poços de produção de petróleo técnicas recentes de
        modelagem empírica baseada em histórico de dados;
    \item Apresentação de uma estrutura modular para implementação do sistema de validação
        de sensores dentro de uma arquitetura mais geral para monitoramento e manutenção
        baseado em condição;
    \item Emprego de um modelo de estimação de \textit{drift} ao resíduo gerado entre um
        modelo empírico de predição auto-associativo e as leituras dos sensores.
\end{itemize}


\section{Estrutura da Dissertação}

No Capítulo \ref{chap:estrutura_sis}, é apresentada a estrutura do sistema de validação de
sensores e estabelecida uma relação entre essa estrutura e uma arquitetura mais geral para
sistemas CBM.
Em seguida, no Capítulo \ref{chap:drift}, são apresentadas as técnicas de modelagem
empírica e de monitoramento, ressaltando suas abordagens ao problema de validação de
sensores.
A descrição do sistema de validação de sensores implementado e sua avaliação em diferentes
cenários de ensaios são apresentadas no Capítulo \ref{chap:ensaios}.
Finalizando o trabalho, o Capítulo \ref{chap:conclusoes} apresenta as conclusões sobre o
desempenho do sistema de validação e dos modelos empíricos desenvolvidos e as
perspectivas de trabalhos futuros.


\chapter{Estrutura de Sistemas de Monitoramento e Validação de Sensores}
\label{chap:estrutura_sis}

\textcolor{blue}{Conceitos gerais sobre monitoramento baseado em condição, importância de uma estrutura
modular e bem definida.}

Em esquemas de manutenção baseados em CBM, as condições de funcionamento de equipamentos e
sistemas são monitoradas com o intuito de otimizar as ações de manutenção. As manutenções
preventivas deixam de ser periódicas, passando a serem agendadas de forma dinâmica, de
acordo com evidências de real necessidade. A implementação de estratégias desse tipo pode
reduzir o tempo de inatividade de plantas de produção, melhorar o desempneho de sistemas e
o gerênciamento de recursos humanos limitados, prolongar a vida útil de equipamentos,
reduzir custos e tornar a produção gradualmente mais efetiva.

A tendência atual de utilização de centros integrados remotos, localizados em
terra, para suporte à operação, manutenção e otimização de unidades marítimas de produção
de petróleo
tem incentivado a utilização de ferramentas de manutenção baseadas na condição.
%Esses
%centros possuem equipes altamente capacitadas que são responsáveis pelo monitoramento do
%desempenho e diagnóstico de possíveis falhas em equipamentos críticos (compressores,
%bombas, turbinas, etc), visando a redução do número de paradas não programadas e o aumento
%da vida útil dos mesmos.
Esses centros possuem equipes altamente capacitadas que, munidas com as informações
certas e no momento adequado, são capazes de avaliar o desempenho e realizar diagnósticos
sobre equipamentos críticos (compressores, bombas, turbinas, etc).
Ferramentas CBM podem garantir o enriquecimento dos dados provenientes de plataformas ao
mesmo tempo que reduz a quantidade de informações a serem analisadas pelas equipes,
causando um consequente aumento da segurança e confiabilidade nas tomadas de decisão, além
de reduzir custos materias e humanos.

Apesar dos benefícios obtidos com a estratégia CBM, sérias dificuldades são frequentemente
encontradas para implementá-la de forma plena \cite{Campos2009}.  A quantidade de dados
coletados torna-se normalmente muito grande.  Pode haver a necessidade de coleta de dados
provindos de sistemas geograficamente dispersos. Os dados precisam ser integrados para
proverem informações úteis. Com o passar do tempo, pode ser necessário a aquisição de
dados de novas fontes e integrá-los com o restante para se obter mais informações
significativas. Finalmente, torna-se indispensável a disponibilidade de conhecimentos
especialistas para converter os dados gerados em informações úteis para manutenção.

No caso da indústria de petróleo, a implementação de um sistema CBM que envolvesse todas
as etapas do processo de produção tornaria-se altamente complexo, mesmo utilizando-se
técnicas simples para o processamento de sinais, monitoramento e detecção. Daí vem a
necessidade de uma metodologia de desenvolvimento que permitisse a implementação do
sistema de manutenção de forma bem estruturada, dentro de uma arquitetura flexível e
robusta.
A padronização da especificação de uma interface dentro da comunidade CBM poderia,
idealmente, direcionar os fornecedores de soluções CBM a produzirem componentes de
hardware e software intercambiáveis. Múltiplos desenvolvedores poderiam atuar na solução
de um mesmo sistema. Entre os potenciais benefícios de um padrão não proprietário, robusto
e largamente adotado, podem-se citar:

\begin{itemize}
    \item facilidade para atualização de componentes de sistema;
    \item aumento do número de fornecedores, resultando em mais opções de tecnologia;
    \item desenvolvimento tecnológico mais rápido;
    \item redução de custos e preços.
\end{itemize}



\subsection{OSA-CBM}

\textcolor{blue}{Existência da OSA-CBM e breve descrição sobre a respectiva
arquitetura.
Como o trabalho da dissertação, um sistema de monitoramento de calibração, se relaciona
com a estrutura OSA-CBM.}

Recentemente, uma associação entre indústrias, fabricantes, universidades e a Marinha
Norte-Americana desenvolveu uma arquitetura aberta para sistemas de manutenção baseados em
CBM, conhecida como OSA-CBM (\textit{Open System Architecture Condition-Based
Maintenance}).
O foco principal dessa aliança foi desenvolver uma
arquitetura para sistemas CBM que facilitasse a interoperabilidade entre componentes de
\textit{hardware} e \textit{software}.
%módulos de software CBM
%\cite{Lebold2003}.
%Dessa forma, um sistema CBM poderia ser dividido em diferentes módulos padronizados que se
%comunicam entre si.

\abreviatura{OSA-CBM}{Open System Architecture Condition-Based Maintenance}

No OSA-CBM, a arquitetura de um sistema CBM é dividido em diferentes camadas funcionais,
cujos conteúdos devem ser implementados seguindo as interfaces definidas pelo padrão.
Atualmente, as camadas funcionais, ou módulos, somam um total de 6, seguindo a norma
ISO-13374. As camadas são: aquisição
de dados, processamento de sinais, monitoramento de condição, avaliação de
saúde (diagnóstico), a de prognóstico e a de suporte a tomada de decisão.
Cada camada possui a capacidade de requisitar dados de outras camadas funcionais quando
necessário, apesar do fluxo de dados normalmente ocorrer entre as camadas adjacentes. Na
Fig. ?? é apresentado um esquema da organização dos módulos da arquitetura.

\textcolor{red}{Figura do report da OSA 3.1.0 Primer}

Os primeiros três blocos são específicos para determinadas tecnologias e provêem as
seguintes funções \cite{PennStateUniversity2006}:

\textcolor{red}{Copiar do artigo citado}

A Fig. ?? ilustra um exemplo mais prático da estrutura de um sistema CBM.

\textcolor{red}{Figura do artigo Souza2008, no artigo do rio automacao}




%Isso
%tanto permite a integração de vários diferentes componentes 



\subsection{Detecção e Correção de Drift sob a OSA-CBM}

A maneira como os algoritmos de detecção de drift se inserem dentro da arquitetura
OSA-CBM.

\chapter{Processamento de Sinais para Detecção e Correção de Drift}
\label{chap:drift}

% Definição formal de drift de sensores.
% Teoria geral sobre o emprego de modelos empíricos para validação de medidas de sensores.
% Diferenças entre identificação de sistemas (density estimation) e a regressão por modelos
% empíricos (livro ``Learning from data'').
% Explicação básica sobre detecção por métodos estatísticos.

\textcolor{red}{TODO:} Dividir as etapas em pré-processamento, processamento e
pós-processmaneto. Incluir o KF na etapa de pós-processamento.

Pode-se dividir o processo de validação de sensores em três etapas principais:
pré-processamento, processamento, pós-processamento dos sinais e o monitoramento de
condição.
Cada uma dessas etapas são detalhadas a seguir.

%Como discutido no Capítulo 1, o monitoramento do desempenho de sensores é composto
%basicamente por três etapas: predição das leituras dos sensores por um modelo empírico, a
%geração de resíduos e a avaliação desses resíduos gerados. A seguir são apresentados
%detalhes sobre a metodologia adotada em cada etapa.

\section{Pré-processamento dos Sinais}

A etapa de pré-processamento dos sinais consiste na preparação dos dados que serão
utilizados pelos modelos empíricos, tanto para o treinamento quanto para a predição.
O condicionamento dos dados às técnicas de modelagem normalmente são
necessárias para que os modelos consigam extrair dos sinais as informações corretas e
realmente relevantes para futuras predições.

Pode-se dividir a etapa de pré-processamento em quatro tarefas: limpeza dos dados,
normalização, seleção das variáveis de entrada do modelo e seleção das amostras de
treinamento.

\subsection{Limpeza dos Dados}

A limpeza dos dados consiste na filtragem e remoção de dados espúrios.

A filtragem dos sinais tem por objetivo retirar ou reduzir os ruídos normalmente presentes
nas medições dos sensores.
``O uso de sinais filtrados tende a facilitar o processo de treinamento dos modelos, uma vez
que se reduz a complexidade dos sinais a serem aprendidos pelo modelo''
\cite{MauroVitordeOliveira2005}.
Entretanto, é importante garantir que o processo de filtragem não remova informações
``verdadeiras'' sobre a variável mensurada, o que poderia comprometer o desempenho dos
modelos.

Dados espúrios ou \textit{outliers} são dados inconsistentes com a maioria das medidas
coletadas.
Medidas espúrias são normalmente causadas por erros grosseiros na medição, erros no
armazenamento, e/ou outros eventos anormais.
Tais dados não representativos podem afetar seriamente os
modelos~\cite{cherkassky2007learning} e devem ser corrigidos ou simplesmente removidos do
conjunto de dados utilizados para treinamento.

% \subsubsection{Aquisição e Qualidade dos Dados}
% 
% Como apresentado por Hines \cite{Hines2006},
% o primeiro passo para o desenvolvimento de um modelo é a coleta de dados representativos.
% Os dados devem ser cuidadosamente analisados para se garantir sua qualidade. Dados
% espúrios, anomalias e condições de falhas de equipamentos devem ser corrigidos ou
% simplesmente excluídos do conjunto de dados selecionado para treinamento do modelo. Apesar
% de existirem procedimentos automáticos para remoção de erros, a inspeção visual ainda é
% muito importante para se garantir a qualidade dos dados.
% 
% \textcolor{red}{FIXME:} que dados são esses? treinamento? tomar cuidado com essa palavra. Filtragem dos
% dados para redução de complexidade do modelo, remoção de dados espúrios. Normalização dos dados.
% Pontos de operação podem ser identificados por técnicas de clusterização/classificação.
% 
% Além disso, os dados devem cobrir completamente os futuros
% pontos de operação e estarem livres de pontos de operação atípicos. Como as técnicas de
% modelagem empírica baseada em dados aprendem sua relação funcional a partir dos dados de
% treinamento, os modelos são incapazes de gerarem predições confiáveis fora da região de
% operação dos dados de treinamento. Se estados de operação anômalos, como \textit{drift} em
% um sensor ou falha em equipamento, são incluídos no conjunto de treinamento, os
% modelos irão incorporar essas condições como comportamentos normais.

% Neste trabalho, a análise dos dados de treinamento foi realizada por inspeção visual.

\subsection{Normalização}

A normalização dos dados consiste em tornar igual a escala de valores dos sinais de todos
os sensores envolvidos.
Diferentes variáveis mensuradas pelos sensores naturalmente possuem diferentes escalas, ou
seja, suas próprias unidades de medida.
Para algumas técnicas de modelagem, a escala das variáveis não representa um problema,
entretanto, outros métodos, principalmente os baseados em distância, são sensíveis às
escalas das variáveis de entrada.
Nestes métodos, variáveis caracterizando pressão, por exemplo, possuiriam maior influência
quando expressadas em Pascal que em kgf/m$^2$.

Para técnicas de aprendizagem de máquina, uma das formas comuns de se normalizar sinais é
escalá-los no hipercubo $[0,1]^p$, onde $p$ é o número de variáveis de entrada do modelo.
Neste caso, a normalização de uma amostra $r_p \in \Re$ obtida de um sensor $p$ é dada
pela Eq.~(\ref{eq:scaling}), onde $r_{norm,p}$ é o valor normalizado de $r_p$ e
$r_{max,p}$ e $r_{min,p}$ são os valores máximos e mínimos dos dados de treinamento
relativos ao sensor $p$.

\begin{equation}
    r_{norm,p} = \frac{r_p - r_{min,p}}{r_{max,p} - r_{min,p}}
    \label{eq:scaling}
\end{equation}


\subsection{Seleção das Variáveis de Entrada}

Este passo consiste na seleção de quais variáveis, ou sensores, serão incorporados no
modelo, com o objetivo de agrupar aquelas que possuem certo grau de correlação.
Como os modelos empíricos baseiam suas predições nas correlações das variáveis de entrada,
o agrupamento é uma tarefa de fundamental importância.
A adição de variáveis não relevantes (sem correlação com a variável a ser predita) tende a
gerar modelos instáveis, cujas predições apresentam alta variância.
Entretanto, para algumas técnicas de regressão, variáveis altamente correlacionadas podem
causar singularidade na matriz de dados entrada e, consequentemente, predições de baixa
qualidade.
Além disso, quanto maior o número de variáveis de entrada de um modelo empírico de
regressão, maior deve ser o número de amostras de treinamento para que o modelo cubra o
mínimo possível do espaço de entrada.

Para os casos de redundância de \textit{hardware} com técnicas de regressão que suportam
colinearidades, o processo de seleção é simples, uma vez que apenas
sensores redundantes são incluídos em um modelo.
Para os casos onde redundâncias não necessariamente existem, o
conjunto de sensores que se deseja monitorar deve ser separado em grupos menores altamente
correlacionados.
Hines~\cite{Hines2006} apresenta que agrupamentos ótimos normalmente contém menos
de 30 sensores e que a adição de sinais irrelevantes acaba por aumentar a variância das
predições de um modelo, enquanto a ausência de sinais relevantes tende a causar
polarização.

Um indicador de agrupamento normalmente utilizado é o coeficiente de correlação
(covariância entre os sinais dividida pelo produto dos desvios padrão de cada um) para
cada par de sensores. Se o coeficiente de correlação ultrapassa um determinado valor,
então o correspondente par de sensores deve participar do mesmo grupo. Entretanto, este
método não garante a otimalidade de agrupamento, pois variáveis que são fortemente
correlacionadas fisicamente podem apresentar baixos coeficientes de correlação devido a
ilusões estatísticas de conjunto de dados polarizados.
Normalmente, esse método é utilizado acompanhado de senso de engenharia, ou seja,
selecionam-se as variáveis considerando também conhecimentos especialistas sobre a
dinâmica do processo.

Técnicas de exploração do espaço de possibilidades também podem ser empregadas para o
agrupamento das variáveis, como algoritmos genéticos~\cite{MauroVitordeOliveira2005} e a
\textit{stepwise grouping}~\cite{An2011}.
Basicamente, essas técnicas tentam minimizar o número de tentativas possíveis para se
alcançar um solução ótima ou subótima de agrupamento.
Cada tentativa implica na criação de um diferente modelo e na avaliação da qualidade das
predições geradas por ele.
Através de uma heurística, reduz-se o espaço de possibilidades de combinação das
variáveis para, finalmente, selecionar aquele agrupamento que gera o modelo com melhor
qualidade de predição.

% Como
% apresentado por An \cite{An2011}, técnicas como a \textit{stepwise grouping} podem
% realizar bons agrupamentos de sensores. Basicamente, a \textit{stepwise grouping} realiza
% os agrupamentos de forma incremental, ou seja, adiciona-se um novo sensor a grupo,
% constroi-se um modelo a partir dessa junção e compara-se a qualidade da predição desse novo
% modelo em relação ao modelo anterior, sem a nova variável. Caso a qualidade da predição
% tenha sido melhorada, a nova variável permanece no grupo; caso constrário, a variável é
% descartada, permanecendo o agrupamento anterior. O procedimento é realizado até que todos
% so sensores possíveis tenham sido analisados.


\subsection{Seleção das Amostras de Treinamento}

Dois aspectos principais, intrinsicamente relacionados, devem ser considerados para a
seleção das amostras para o treinamento dos modelos: quantidade e representatividade.
Geralmente, a quantidade de variáveis de entrada do modelo dita uma quantidade mínima de
amostras necessárias para se ``capturar'' a correlação entre elas.
% Com poucas observações, tende-se a obter predições degradadas por falta de informação; com
% quantidade excessiva, o custo computacional de cada predição torna-se muito alto.
Entretanto, essas amostras precisam representar as condições de operação que se espera
encontrar quando o modelo estiver funcional.

% Para a maioria dos modelos empíricos, os dados devem ser separados em pelo menos dois
% conjuntos, o de treinamento e o de validação. Os dados de treinamento são usados pelo
% modelo para o aprendizado das relações entre os sensores e otimização de seus parâmetros.
% Os dados de validação servem para avaliar o desempenho do modelo construído. Hines
% \cite{Hines2007} normalmente divide os dados em três conjuntos, treinamento, verificação e
% validação. A diferença consiste na separação de um conjunto específico para otimização dos
% parâmetros do modelo, o conjunto de verificação.
% 
% \textcolor{red}{Importância da escolha de dados significativos, livre de erros, etc}

% TODO: talvez seja mover para a próxima subseção
%Os modelos baseados em regressão por kernel, como o AAKR, requerem que um
%subconjunto dos dados de treinamento seja armazenado como uma matriz de memória usada para
%as futuras predições. A seleção desse subconjunto possui efeitos consideráveis no
%desempenho do modelo; armazenando poucas observações, as predições são degradadas por
%falta de informação; armazenando uma quantidade excessiva, o custo computacional de cada
%predição torna-se muito alto.



\section{Processamento dos Sinais}

% Listar modelos estudados e as razões da escolha destes.
% -> Premissas

O processamento dos sinais é a etapa de predição propriamnente dita. A partir de novas
amostras das variáveis de entrada, o modelo empírico gera predições sobre a variável de
saída.
Os principais aspectos a serem considerados nesta etapa são: a escolha do tipo de
estrutura do modelo, a escolha da técnica de regressão e a construção/otimização do
modelo.

% Antes da predição das leituras de sensores propriamente dita, é necessário construir um
% modelo empírico baseado no histórico de sensores correlacionados.
% Independente da técnica utilizada para modelagem e predição, existem alguns passos básicos
% comuns empregados para o desenvolvimento de modelos empíricos baseados em histórico.
% 
% A seguir são descritos os passos básicos para o desenvolvimento de um modelo baseado em
% histórico de dados e as técnicas empregadas para modelagem/predição neste trabalho.

\subsection{Seleção do Tipo de Estrutura}

Normalmente, a estrutura dos modelos pode ser classificada em três diferentes tipos:
inferencial, hetero-associativa ou auto-associativa.

Um modelo inferencial utiliza um conjunto de variáveis de entrada $[r_1, \cdots, r_n]$
para inferir o valor de uma única variável de saída $y$.
Esse modelo pode ser expandido para um estrutura hetero-associativa, onde um conjunto de
variáveis de entrada $[r_1, \cdots, r_p]$ é usado para predizer os valores de um conjunto
de variáveis de saída $[y_1, \cdots, y_q]$.

Um modelo auto-associativo é normalmente treinado para emular as próprias variáveis de
entrada, ou seja, um conjunto de variáveis $[r_1, \cdots, r_p]$ é usado para
gerar predições $[\hat{r}_1, \cdots, \hat{r}_p]$, que correspondem aos valores
``corrigidos'' das variáveis de entrada de acordo com o conjunto de dados de treinamento
usado para a contrução do modelo.
Dessa forma, se as variáveis de entrada possuem a mesma correlação existente nos dados de
treinamento, os valores de saída do modelo auto-associativo tendem a ser iguais aos
valores de entrada.
Pequenas alterações nessas correlações, como as causadas por algumas falhas em sensores,
tendem a ser corrigidas pela correlação capturada pelo modelo através dos dados de
treinamento.


\subsection{Técnicas de Regressão}

%% Present the quality metrics for each technique

%Duas das técnicas de modelagem baseada em histórico que têm apresentado aplicações em
%sistemas de monitoramento do desempenho de sensores~\cite{Gribok2000}: a regressão por
%kernel auto-associativa (AAKR) e a \textit{support vector machines} (SVM).

As duas técnicas de regressão abordadas neste trabalho são: AAKR e SVM.

\subsubsection{AAKR}
%TODO: Figuras explicativas

A regressão por kernel auto-associativa é uma técnica não paramétrica para modelagem
baseada em histórico de dados, cujas predições se baseiam na similaridade entre as
entradas do modelo e um histórico de dados armazenado.
A arquitetura do modelo AAKR apresentada a seguir é uma variação da regressão inferencial
multivariável por kernel, apresentada por Wand e Jones \cite{wand1995kernel}.
%Baseando-se na similaridade entre o vetor de leituras de um conjunto de sensores e o
%conjunto de vetores do histórico, armazenado como uma memória, o modelo AAKR 

Considerando $\mathbf{X}$ uma matriz de histórico de amostras livres de erros, ou memória,
$X_{i,j}$ representa a i-ésima observação da j-ésima variável/sensor.
Para $n_m$ vetores de memória e $p$ variáveis, a matriz $\mathbf{X}$ é definida como

$$
{\mathbf{X}} = \left[ {\begin{array}{*{20}{c}}
{{X_{1,1}}}&{{X_{1,2}}}& \cdots &{{X_{1,p}}}\\
{{X_{2,1}}}&{{X_{2,2}}}& \cdots &{{X_{2,p}}}\\
 \vdots & \vdots & \ddots & \vdots \\
{{X_{{n_m},1}}}&{{X_{{n_m},2}}}& \cdots &{{X_{{n_m},p}}}
\end{array}} \right] \mbox{.}
$$

As entradas do modelo são definidas pelo vetor de amostras $\mathbf{r}$, definido por

$$
{\mathbf{r}} = \left[ {\begin{array}{*{20}{c}}
{{r_1}}&{{r_2}}& \cdots &{{r_p}}
\end{array}} \right] \mbox{.}
$$

A predição do valor corrigido de $\mathbf{r}$ é calculada como uma média ponderada das
observações livres de erros contidas em $\mathbf{X}$.
O funcionamento do modelo AAKR é composto de três passos básicos.
Primeiro, calcula-se as distâncias entre $\mathbf{r}$ e cada linha da matriz de memória
$\mathbf{X}$.
Dentre as possíveis métricas de distância, a distância Euclidiana é a mais comumente
utilizada, dada pela Eq.~(\ref{eq:aakr_distance}), onde $d_i$ é a distancia Euclidiana
entre o vetor de memória $\mathbf{X}_i$ e a entrada $\mathbf{r}$.

\begin{equation}
    {d_i}\left( {{{\mathbf{X}}_i},{\mathbf{r}}} \right) = \sqrt {{{\left(
    {{X_{i,1}} - {r_1}} \right)}^2} + {{\left( {{X_{i,2}} - {r_2}} \right)}^2} +  \cdots
    {{\left( {{X_{i,p}} - {r_p}} \right)}^2}} 
    \label{eq:aakr_distance}
\end{equation}

\noindent Este cálculo é repetido para todos os $n_m$ vetores de memória da matriz $\mathbf{X}$,
resultando em um vetor coluna de distâncias

$$
{\mathbf{d}} = \left[ {\begin{array}{*{20}{c}}
{{d_1}}\\
{{d_2}}\\
 \vdots \\
{{d_{{n_m}}}}
\end{array}} \right] .
$$

Em seguida, as distâncias são convertidas em medidas de similaridade ou pesos através
da função kernel, como a Gaussiana apresentada na Eq.~(\ref{eq:gauss_kernel}), onde
$w_i$ é o i-ésimo peso relativo a i-ésima distância $d_i$ e $h$ é a largura de banda da
função kernel $K$.

\begin{equation}
    {w_i} = K_h ({d_i}) = \frac{1}{{\sqrt {2\pi {h^2}} }}{\; \exp
    \left(- \frac{{d_{_i}^2}}{{{h^2}}} \right) } \mbox{,}
    \label{eq:gauss_kernel}
\end{equation}

Por fim, através da Eq.~(\ref{eq:aakr_var_pred}), os pesos são combinados com os vetores
de memória para produzir uma estimativa $\hat{r}_j$ de cada variável $r_j$.
Calculando as estimativas para $j = 1, 2, \cdots, p$, obtém-se a saída do modelo, a
predição $\hat{\mathbf{r}}$.
Alternativamente, definindo $a = {\sum\limits_{i = 1}^{{n_m}} {{w_i}} }$, o estimador AAKR
pode ser apresentado pela Eq.~(\ref{eq:aakrPred}).

\begin{equation}
    \hat{r}_j = \frac{\sum\limits_{i = 1}^{n_m} {w_i}\cdot
        X_{i,j}  }{{\sum\limits_{i = 1}^{{n_m}} {{w_i}} }}
    \label{eq:aakr_var_pred}
\end{equation}

\begin{equation}
    {\hat \mathbf{r}} = \frac{{{{\mathbf{w}}^T}{\mathbf{X}}}}{a}
    \label{eq:aakrPred}
\end{equation}

\paragraph{Seleção dos vetores de memória}

A seleção dos vetores de memória é uma tarefa crítica para o desenvolvimento de modelos
não paramétricos como o AAKR \cite{HinesGarvey2008}, onde as predições do modelo se
baseiam na similaridade entre suas entradas e cada um dos vetores de memória.
Um conjunto de dados de treinamento muito grande tornaria muito elevado o custo
computacional de cada predição.
O que normalmente se faz é selecionar um subconjunto dos dados de treinamento, visando
diminuir o custo computacional sem perder informações significantes sobre a correlação
entre as variáveis.

Basicamente, duas questões devem ser consideradas para a seleção dos vetores de memória: 
qual é a \emph{quantidade} adequada e \emph{como} realizar essa seleção.
Em relação à quantidade, normalmente existe um número crítico para cada conjunto de dados:
quantidades menores pioram o desempenho do modelo drasticamente, quantidades maiores
melhoram discretamente o desempenho ao custo de aumentos drásticos no tempo
computacional~\cite{HinesGarvey2008}.
Em relação à forma de seleção dos vetores, dois métodos simples e comumente utilizados são
a seleção por mínimos-máximos e a seleção por ordenamento dos vetores.

O método de seleção por mínimos-máximos é dividido em duas etapas.
Primeiro, particiona-se o conjunto de dados em $n_b$ bandas, de acordo com a
Eq.~(\ref{eq:aakrMinMax}), onde $n_m$ é o número de vetores a serem selecionados e
$p$ é a quantidade de variáveis nos dados.
Em seguida, para cada banda gerada, selecionam-se os vetores que contenham os valores
máximos e mínimos de cada variável, sem repetição de vetores.

\begin{equation}
    n_b = \frac{n_m}{2p}
    \label{eq:aakrMinMax}
\end{equation}

No método de seleção por ordenamento de vetores, primeiramente ordenam-se os vetores de
treinamento de acordo com a norma Euclidiana.
A Equação~(\ref{eq:aakrVecOrd}) apresenta o cálculo da norma Euclidiana $N_i$ para um
vetor $\mathbf{X}_i$ de treinamento.
Em seguida, selecionam-se $n_m$ vetores amostrando de forma periódica.
É importante destacar que este método é intrinsecamente relacionado com a localização da
origem do espaço da matriz de dados de treinamento, o que torna importante escalar as
variáveis antes da utilização deste método de seleção.

\begin{equation}
    N_i = \sqrt{X_{i,1}^2 + X_{i,2}^2 + \cdots + X_{i,p}^2}
    \label{eq:aakrVecOrd}
\end{equation}

Um outra forma de realizar a seleção dos vetores de memória é a combinação dos dois
métodos anteriores.
Como normalmente o método de seleção por mínimos-máximos não obtém o número $n_m$ de
vetores desejado (um mesmo vetor pode conter os valores máximos ou mínimos de mais de uma
variável), usa-se o método de ordenamento de vetores para selecionar a quantidade de
vetores necessária para se obter $n_m$.

\subsubsection{SVM}

Na técnica de SVM para regressão, uma matriz de dados de entrada $\mathbf{r} \in
\Re^{p}$, de $p$ variáveis independentes, é usada para estimar uma
função $f(\mathbf{r})$ que correlaciona as $p$ variáveis de $\mathbf{r}$ com uma variável
dependente $y \in \Re$ a partir de $n$ observações independentes e identicamente
distribuídas.
Dessa forma, um modelo SVM apresenta estrutura do tipo inferencial.

A técnica corresponde à minimização da Eq.~(\ref{eq:DF_svm_minimize}),
onde $f(\mathbf{r}) = \left< \mathbf{w,r} \right> + b$, com $w \in X$ (espaço de
características) e $b \in \Re$, é o estimador da função de dependência entre $\mathbf{r}$
e $y$.
A Equação~(\ref{eq:DF_svm_minimize}) pode ser reescrita como a Eq.~(\ref{eq:DF_svm_fx}).
Essa formulação torna a solução esparsa no sentido que erros menores que $\varepsilon$ são
ignorados, ou seja, a solução torna-se ``$\varepsilon$-insensível''.

\begin{equation}
    \frac{1}{2} || \mathbf{w}||^2 + C \sum\limits^n_{i=1} \left( \xi_i + \xi^{*} \right)
    \label{eq:DF_svm_minimize}
\end{equation}

$$
    \mbox{Sujeito a}
    \left\{
    \begin{array}{rl}
        y_i - \left<\mathbf{w}, \mathbf{r}_i \right> - b & \le \varepsilon
        + \xi_i \\
        \left<\mathbf{w}, \mathbf{r}_i \right> + b - y_i & \le \varepsilon +
        \xi_i^* \\
        \xi_i, \xi_i^* & \ge 0
    \end{array}
    \right\}
$$

\begin{equation}
    f(\mathbf{r}) = \sum\limits_{j=1}^p w_j \; r_j + b .
    \label{eq:DF_svm_fx}
\end{equation}

O primeiro termo da equação (\ref{eq:DF_svm_minimize}) é um termo de regularização que
evita o mau condicionamento do problema de estimação, contribuindo na simplicidade do
estimador da função.
O segundo termo é a função de perda $\varepsilon$-insensível, a qual
mede o quanto os valores estimados estão próximos dos valores $y$. As variáveis $\xi_i$ e
$\xi_i^*$ são chamadas de variáveis de folga, que determinam o grau de penalização
aplicados às estimativas com erros maiores que $\varepsilon$.
A Figura
\ref{fig:DF_svm_insensibilidade} ilustra a zona de insensibilidade formada por $\varepsilon$
e a penalização efetuada pelas variáveis de folga. Por isso, qualquer erro absoluto menor
que $\varepsilon$ não necessita de valores diferentes de zero para as variáveis $\xi_i,
\xi_i^*$ na função objetiva, o que causa a esparsividade da solução.
A constante $C$ determina o custo-benefício entre a complexidade da função $f$ e a
quantidade tolerada de desvios maiores que $\varepsilon$.

\begin{figure}[!htb]
    \centering
    \includegraphics[width=.6\textwidth]{./figuras/svm_etube.eps}
    \caption{Zona de insensibilidade e penalização no modelo SVM \cite{Smola2004}.}
    \label{fig:DF_svm_insensibilidade}
\end{figure}

Escrevendo a Eq.~(\ref{eq:DF_svm_minimize}) na forma dual e resolvendo por diferenciação
em relação às variáveis primais, o problema resulta em maximizar a função $W(\alpha^*,
\alpha)$ na Eq.~(\ref{eq:DF_svm_dual}).

\begin{equation}
    W(\alpha^*, \alpha) = - \varepsilon \sum\limits_{i=1}^n (\alpha_i + \alpha_i^*) +
    \sum\limits_{i=1}^n  y_i (\alpha_i - \alpha_i^*)  - \frac{1}{2}
    \sum\limits_{i,j=1}^n (\alpha_i - \alpha_i^*) (\alpha_j - \alpha_j^*) \; K(r_i, r_j)
    \label{eq:DF_svm_dual}
\end{equation}

$$
    \mbox{Sujeito a}
    \left\{
    \begin{array}{c}
        \sum\limits_{i=1}^n (\alpha_i^* - \alpha_i)  = 0\\
        0 \le \alpha_i, \alpha_i^* \le C
    \end{array}
    \right\}
$$

\noindent A função $f(\mathbf{r})$ passa a ser dada pela Eq.~(\ref{eq:DF_svm_func_dual}),
onde $\alpha, \alpha^*$ são multiplicadores de Lagrange e $K(\mathbf{r}, \mathbf{r}_i)$ é
a função kernel que substitui os produtos internos dos dados de entrada e permite lidar
com não linearidades eventualmente presente nos dados.
Os vetores $\mathbf{r}_i$ são
chamados de ``vetores suporte'' e $N_{sv}$ (normalmente $N_{sv} << n$) é o número de
vetores suporte correspondentes à quantidade de valores de $y$ que estão pelo menos
$\varepsilon$ afastados de suas estimativas $f(\mathbf{r})$.

\begin{equation}
    f(\mathbf{r}) = \sum\limits_{i=1}^{N_{sv}} (\alpha_i^* - \alpha_i) \;
    K(\mathbf{r}, \mathbf{r}_i) + b
    \label{eq:DF_svm_func_dual}
\end{equation}


As condições de Kuhn-Tucker demandam que o produto entre as variáveis duais e as
restrições devem desaparecer para otimalidade. Por isso, para $|f(\mathbf{r}_i) - y_i| \ge
\varepsilon$, os multiplicadores de Lagrange são diferentes de zero; e para pontos dentro
da região $\varepsilon$-insensível, os coeficientes $\alpha_i^*, \alpha_i$ devem
desaparecer. Os vetores com coeficientes diferentes de zero são os chamados vetores
suporte. Basicamente, os vetores suporte são os vetores que suportam a ``superfície de
decisão'' ou o ``hiperplano'' que melhor se adequa aos dados, de acordo com o critério
especificado na Eq.~(\ref{eq:DF_svm_minimize}).

A configuração do modelo SVM consiste na escolha da função kernel e de seus parâmetros, e
na especificação de $\varepsilon$ e $C$.
Uma função kernel largamente utilizada para regressão é a função de base radial (RBF),
apresentada na Eq.~(\ref{eq:DF_svm_kernel}),
onde $\gamma$ é a largura de banda, o parâmetro de configuração.

\begin{equation}
    K(\mathbf{r}, \mathbf{r}_i) = \exp \left( - \frac{||\mathbf{r}-\mathbf{r}_i||^2}{2 \gamma^2} \right)
    \label{eq:DF_svm_kernel}
\end{equation}

\abreviatura{RBF}{Função de base radial}

A constante $C$ determina o custo-benefício entre a complexidade do modelo (suavidade) e o
grau de tolerância dos desvios maiores que $\varepsilon$ em (\ref{eq:DF_svm_minimize})
\cite{Cherkassky2004}.
Valores muito grandes de $C$ tornam o problema sem restrição; valores pequenos atribuem
mais peso para a regularização.
O parâmetro $\varepsilon$ controla a largura da zona de insensibilidade, usada para
adequar os dados de treinamento.
O valor de $\varepsilon$ é o parâmetro que possui maior efeito sobre o número de vetores
suporte.
Quanto maior for $\varepsilon$, menos vetores suporte são utilizados e mais ``suave''
torna-se a função $f$.


\subsection{Construção e Otimização dos Modelos}
%%%%%%%%%%%%%%%
% Falar sobre o objetivo dos modelos de predição, diferenciando-os da identificação de
% sistemas. (Learning from data)
% * Figura esquemática.
% * Minimização de um função custo
% * Detalhes sobre o AAKR (hines)
% * Detalhes sobre o SVM (Smola)
%%%%%%%%%%%%%%%

%Diferentemente da identificação de sistemas, os modelos empíricos de predição normalmente
%são construídos 
%%visando minimizar uma função custo
%com o objetivo de ``imitar'' as saídas de um sistema de forma mais precisa possível
%\cite{cherkassky2007learning}.
%A identificação de sistemas não depende da distribuição probabilística das observações de
%entrada, mas bons modelos de predição são normalmente dependentes dessa distruição, que
%geralmente é desconhecida. %% USAR FIGURA

%Considere o esquema apresentado na Figura . Segundo as técnicas de aprendizado
%preditivo, um modelo preditivo deve capturar as correlações entre as variáveis
%$\mathbf{r} \in \Re^p$.

Partindo-se de uma técnica de regressão, constroi-se um modelo empírico a partir de um
conjunto de amostras de treinamento, compostas por pares entrada/saída.
As amostras de treinamento são exemplares de valores das variáveis de entrada juntamente
com os valores das variáveis de saída que se espera do modelo.
No caso de um modelo SVM, as amostras são compostas pelos valores de $p$ variáveis de
entrada e um valor correspondente à variável de saída.  Para um modelo AAKR, os pares
entrada/saída possuem o mesmo valor.

Para ambas as técnicas, a complexidade dos modelos podem ser especificadas por parâmetros
e deve ser ajustada para que se adeque à complexidade dos dados de treinamento.
Se o modelo não é flexível, ele não será capaz de modelar as relações dos dados de
treinamento; se o modelo é excessivamente complexo, o problema de sobreajustamento
(\textit{overfitting}) dos dados poderá ocorrer, incluindo ruídos na modelagem.
Considerando o uso de funções kernel do tipo Gaussiana ou RBF, a complexidade dos modelos
SVM é determinada pelos parâmetros $C$, $\varepsilon$ e $\gamma$; nos modelos AAKR, pelo
parâmetro $h$.
Em muitas aplicações, esses valores podem são encontrados por tentativa e erro, ou
\textit{grid search}, onde treinam-se vários modelos com diferentes permutações de valores
de configuração e avalia-se a qualidade das predições destes atráves de um novo conjunto
de amostras.
O modelo com a configuração de melhor desempenho é adotado como o modelo final para o
sistema de validação.

A construção de um modelo empírico normalmente busca minimizar o erro (ou risco de
predição) entre a predição $f(\mathbf{r})$ do modelo e a saída $y$ do sistema para uma
dada entrada $\mathbf{r}$.
A medida de qualidade que normalmente se adota é a minimização do erro quadrático médio
(MSE), como a Eq.~(\ref{eq:mse}), onde $n$ é a quantidade de observações utilizadas para a
construção do modelo.
\begin{equation}
    \mbox{MSE} = \frac{1}{n} \sum \limits^n_{i=0} (y_i - f(\mathbf{r}_i)) 
    \label{eq:mse}
\end{equation}

\abreviatura{MSE}{Erro quadrático médio}

% TODO: identificação de sistemas x predição 
%Diferentemente da identificação de sistemas, os modelos empíricos de
%predição normalmente são construídos 
%%visando minimizar uma função custo
%com o objetivo de ``imitar'' as saídas de um sistema para uma determinada entrada.
%%\cite{cherkassky2007learning}.
%Entretanto, a construção do modelo é realizada a partir de um número finito $n$ de
%observações $\mathbf{r}$, consequentemente o modelo só pode ser uma estimação da solução
%ótima.

Segundo Cherkassky e Mulier~\cite{cherkassky2007learning}, existe o seguinte consenso: para métodos
flexíveis de aprendizado  com um número finito de amostras (como os métodos baseados em
kernel utilizados neste trabalho), as predições com melhor desempenho são obtidas por
modelos de complexidade ótima.
Deve-se preferir modelos mais simples a modelos complexos e otimizar a relação entre
complexidade e acurácia do modelo para o conjunto de dados de treinamento.

%% Flexibilidade x Complexidade
%% Minimização da incerteza


\section{Pós-processamento dos Sinais}

A etapa de pós-processamento dos sinais consiste na estimação dos desvios entre as
predições dos modelos empíricos e as variáveis que se deseja estimar.
A partir das estimativas dos desvios, é possível realizar uma ``pré-correção'' das
leituras provenientes dos sensores que servem como entrada dos modelos empíricos,
permitindo que as predições fiquem mais próximas dos verdadeiros valores das variáveis.

%Como dito na Seção \ref{sec:problemDefinition},
%os resíduos correspondem à diferença entre as predições do modelos e as medições dos
%sensores correspondentes.
%Considerando o sistema sensoriado operando na região de treinamento do modelo,
%as predições são virtualmente iguais às medidas realizadas pelos sensores quando estes se
%encontram funcionando corretamente, e os resíduos tendem a apresentar média zero e
%variância semelhante a do sensor.
%Anomalias nas medições dos sensores, como \textit{drift}, \textit{outliers}, mudanças
%abruptas, aumento da variância (errático) etc., causam mudanças nas características
%estatísticas esperadas nos resíduos e normalmente podem ser detectadas por técnicas
%estatísticas de detecção, como apresentado na Seção~\ref{sec:deteccao_drift}.

A seguir, apresenta-se a construção de um filtro de Kalman para a correção de sensores que
apresentem \textit{drift}.

\subsection{Filtro de Kalman}

Um possível modelo matemático usado para estimar a amplitude do \textit{drift} $d$ de um
sensor é apresentado na Eq. (\ref{eq:kf_dmodel}), onde $v^{(k)}$ é considerado um ruído
Gaussiano de média zero e variância $\sigma_v$. 

\begin{equation}
    {d}^{(k)} = {d}^{(k-1)} + {v}^{(k)}, \quad {v}^{(k)} \sim \mathcal{N} ({0}, \sigma_v)
    \label{eq:kf_dmodel}
\end{equation}

Em rastreamento de alvos (\textit{target tracking}), a Equação (\ref{eq:kf_dmodel})
é conhecida como o modelo matemático do comportamento dinâmico do alvo~\cite{Takruri2008}.
No caso de detecção de \textit{drift}, o objetivo é rastrear ou acompanhar a amplitude do
\textit{drift} de um sensor.
Se for assumido que um sensor apresenta desvios de forma suave, vagarosamente
crescente, linear ou exponencial, pode-se considerar o modelo da Eq. (\ref{eq:kf_dmodel})
como uma aproximação razoável.
Uma outra consideração deste modelo é a descorrelação entre \textit{drifts} de diferentes
sensores, mesmo sendo as variáveis de processo correlacionadas.

A observação do desvio no sensor estimado, dado por $$z = r - \hat{r},$$ não
corresponde ao valor verdadeiro do desvio, uma vez que este valor não está disponível.
Então, pode-se descrever a equação de medição como a Eq.~(\ref{eq:kf_observ}), onde
${q}^{(k)}$ é um ruído Gaussiano de variância $\sigma_q$.

\begin{equation}
    {z} = {d}^{(k)} +{q}^{(k)}, \quad {q}^{(k)} \sim
    \mathcal{N} ({0}, \sigma_q)
    \label{eq:kf_observ}
\end{equation}

Quando uma nova observação $r$ e a estimação de seu valor corrigido $\hat{r}$ estiverem
disponíveis, os seguintes passos são executados para se obter uma nova estimação do desvio
$d^{(k)}$ eventualmente presente no sensor:

\begin{enumerate}
    \item predição, $$\hat{d}^{(k|k-1)} = \hat{d}^{(k-1)}$$
    \item MSE mínimo da predição, $$M^{(k|k-1)} = M^{(k-1)} + \sigma_v$$
    \item ganho de Kalman, $$K = \frac{M^{(k|k-1)}}{\sigma_q + M^{(k|k-1)}}$$
    \item correção da estimativa, $$\hat{d}^{(k|k)} = \hat{d}^{(k|k-1)} + K (z -
        \hat{d}^{(k|k-1)})$$
    \item mínimo MSE, $$M^{(k|k)} = (1 - K) M^{(k|k-1)}.$$
\end{enumerate}

As estimativas do desvio de um sensor podem ser usadas pelo menos de duas formas: indicar
a ocorrência de desvios intoleráveis e a consequente necessidade de manutenção do sensor;
e corrigir as leituras do sensor antes mesmo de serem utilizadas para predição pelo modelo
empírico, o que teoricamente proporcionaria predições mais próximas do valor verdadeiro da
variável mensurada.

\section{Monitoramento de Condição}
\label{sec:deteccao_drift}

A etapa de monitoramento da condição visa monitorar a condição de funcionamento dos
sensores, detectando a ocorrência de eventos e mudanças de estado.

A detecção de anomalias nos sensores é baseada na análise do erro entre as predições do
modelo e as medidas produzidas por eles, ou seja, o resíduo $d$ calculado pela Eq.
(\ref{eq:residuo}), onde $y$ é representa uma medida realizada pelo sensor que se deseja
monitorar e $f(\mathbf{r})$ é uma estimativa dessa medida a partir das medidas
$\mathbf{r}$ de sensores correlacionados.

\begin{equation}
    d = y - f(\mathbf{r})
    \label{eq:residuo}
\end{equation}

Considerando o sistema sensoriado operando na região de treinamento do modelo,
as predições são virtualmente iguais às medidas realizadas pelos sensores quando estes se
encontram funcionando corretamente, e os resíduos tendem a apresentar média zero e
variância semelhante a do sensor.
Anomalias nas medições dos sensores, como \textit{drift}, \textit{outliers}, mudanças
abruptas, aumento da variância (errático) etc., causam mudanças nas características
estatísticas esperadas nos resíduos e normalmente podem ser detectadas por técnicas
estatísticas de detecção~\cite{MauroVitordeOliveira2005}.
Dentre essas técnicas, podem-se citar: verificação de limites das propriedades
estatísticas, como média e a variância; auto-correlação dos resíduos; densidade de
potência dos resíduos; e o método SPRT.

No caso da detecção específica de \textit{drifts}, a verificação da incerteza das
predições do modelo também pode ser empregada~\cite{Hines2008a}.
Os métodos analíticos para os cálculos de incerteza são específicos para cada técnica de
modelagem empírica, enquanto métodos baseados em simulações Monte Carlo são gerais, mas
podem ser computacionalmente custosos.

Pela simplicidade de implementação e abrangência de anomalias detectáveis, neste
trabalho emprega-se o método SPRT, descrito a seguir.

\subsection{SPRT}

O método conhecido por SPRT, desenvolvido por Wald~\cite{wald1947sequential}, consiste em
testes estatísticos de hipóteses e tem sido aplicado frequentemente para a detecção de
anomalias em sistemas.
No caso de detecção de falhas em sensores, duas hipóteses são testadas a cada nova amostra
de dados do sistema: modo normal de operação, ou $H_0$, e modo degradado de operação, ou
$H_1$.
Aplicado aos resíduos gerados pela Eq.~(\ref{eq:residuo}), para cada nova amostra
$d^{(i)}$ do resíduo gerado para o sensor monitorado, uma das duas possíveis hipóteses é
aceita através da execução do seguinte procedimento:

\begin{enumerate}
    \item cálculo do logaritmo da razão de verossimilhança, dado pela
        Eq.~(\ref{eq:loglikelihood});
        \begin{equation}
            \Lambda^{(i)} = \ln \frac{P(d^{(i)} | H_1)}{P(d^{(i)} | H_0)}
            \label{eq:loglikelihood}
        \end{equation}
    \item cálculo da soma acumulativa de $\Lambda$, dado pela
        Eq.~(\ref{eq:cumulative_loglikelihood});
        \begin{equation}
            S^{(i)} = S^{(i-1)} + \Lambda^{(i)}
            \label{eq:cumulative_loglikelihood}
        \end{equation}
    \item verificação da regra de parada, um esquema simples de verificação de limites:
        \begin{itemize}
            \item se $\ln A < S^{(i)} < \ln B$, continua-se o monitoramento e o cálculo de
                $S^{(i+1)} = S^{(i)} + \Lambda^{(i+1)}$ (passo 2);
            \item se $S^{(i)}_p \le \ln A$, $H_0$ é aceita;
            \item se $S^{(i)}_p \ge \ln B$, $H_1$ é aceita e um aviso ou alarme é emitido.
        \end{itemize}
\end{enumerate}

\noindent $P(d^{(i)} | H_1)$ é a probabilidade de observar $d^{(i)}$ dado que $H_1$ é
verdadeira. $A$ e $B$ são respectivamente o limite inferior e superior, cujos valores
podem ser definidos pela probabilidade de ocorrência de falsos alarmes, $\alpha$, e pela
probabilidade de ocorrência de alarmes perdidos, $\beta$, como 
$$
A = \frac{\beta}{1 - \alpha}, \quad B = \frac{1 - \beta}{\alpha}.
$$

Supondo os resíduos como Gaussianos, normalmente o modo $H_0$ corresponde a um
sinal com média zero e variância semelhante a do sensor em questão, enquanto o modo $H_1$
corresponde a uma média diferente de zero ou a uma mudança no valor da variância.
Neste trabalho, assume-se que o \textit{drift} corresponda a uma mudança $\pm M$ na média
dos resíduos, enquanto a variância $\sigma^2$ se mantem inalterada.
Portanto, a função de distribuição de probabilidade dos resíduos de um sensor para o modo
$H_0$ é dada pela Eq.~(\ref{eq:pdf}).

\begin{equation}
    P(d^{(i)} | H_0) = \frac{1}{2 \pi \sigma^2} \exp \left(\frac{-{d^{(i)}}^2}{2 \sigma^2}
    \right)
    \label{eq:pdf}
\end{equation}

Considerando o modo degradado $H_1$ representado por mudanças positivas ($+M$) ou
negativas ($-M$) na média, o logaritmo da razão de verossimilhança é dado pela
Eq.~(\ref{eq:pdfM}).
Como sugerido por Hines e Garvey~\cite{Hines2008a}, o valor de $M$ pode ser determinado
numericamente aplicando o SPRT em conjuntos de dados livres de falhas e localizando um
valor de $M$ que resulte em uma probabilidade de alarmes falsos semelhante a $\alpha$.

\begin{equation}
    \Lambda^i =
    \left\{
        \begin{array}{ll}
            M / \sigma^2 (d^i - M/2), \quad \mbox{for a positive change} \\
            M / \sigma^2 (- d^i - M/2), \quad \mbox{for a negative change}
        \end{array}\right.
    \label{eq:pdfM}
\end{equation}


\chapter{Aplicação do Sistema Implementado a Dados de Poços de Petróleo}
\label{chap:ensaios}

% Descrição do sistema completo implementado, ou seja, sistema integrando os modelos
% empíricos de predição e o módulo estatístico de decisão.
% Palavras: predictive learning.

Neste capítulo são apresentados os sistemas implementados para monitoramento e validação
de sensores de poços de petróleo, além dos resultados da avaliação destes sistemas para
diferentes conjuntos de dados, gerados a partir de simulações ou a partir de sensores
reais.

\section{Sistemas de Validação de Sensores}

\textcolor{red}{TODO:} 3 ou 4 sistemas serão implementados? Figuras e diagramas

Descrevem-se a seguir \textcolor{red}{três} diferentes sistemas de validação de sensores
implementados neste trabalho, os quais se diferem pela técnica de modelagem e/ou pelo
emprego do KF.

\subsection{Sistema 1 --- AAKR-SPRT}

\subsection{sistema 2 --- AAKR-KF-SPRT}

\subsection{Sistema 3 --- SVM-SPRT}



\section{Avaliação}

Uma vez que o modelo tenha sido treinado e otimizado com o conjunto de dados de
treinamento, o conjunto de validação é utilizado para avaliar o desempenho do modelo
desenvolvido.
Segundo Hines~\cite{Hines2008a}, tradicionalmente o desempenho de sistemas de
monitoramento de calibração de sensores é mensurada a partir de três indicadores:
acurácia, auto-sensibilidade e sensibilidade cruzada.
A acurácia mensura a habilidade do modelo para gerar predições corretas e precisas das
leituras dos sensores.
A auto-sensibilidade indica a habilidade do modelo para gerar predições corretas de um
determinado sensor quando as leituras deste estão incorretas devido a algum tipo de falha.
Já a sensibilidade cruzada mensura o efeito dos dados de um sensor defeituoso sobre as
predições dos demais sensores.

Apesar desses indicadores qualificarem características essenciais de todo sistema de
monitoramento de calibração, a inspeção visual das predições é de fundamental importância.
Modelos com bons índices de qualidade podem gerar predições insatisfatórias, como sinais
muito suavizados, representando uma estimação muito grosseira da realidade e, por isso,
sem valor prático para a tomada de decisões.

É importante destacar ainda a possível necessidade de retreinamento do modelo com dados
mais atualizados da planta. Mudanças no ponto de operação, nas condições de equipamentos
ou nas características do meio podem afetar significativamente na forma como as variáveis
mensuradas pelos sensores se correlacionam. Assim, dependendo da instensidade da mudança,
dados atualizados podem ser simplesmete incorporados ao conjunto de treinamento anterior
ou devem compor um conjunto completamente novo.

%% FIXME: put near of the models' descriptions
%Ela é definida como o MSE entre as predições do modelo e os valores
%reais das leituras dos sensores. Por corresponder a uma medida do erro, baixos valores de
%acurácia são desejáveis. O cálculo da acurácia é realizado pela Eq.~(\ref{eq:mse}) para
%modelos inferenciais, ou pela Eq.~(\ref{eq:}) para modelos auto-associativos
%mas considerando $n$ o número de amostras do conjunto de dados de validação.

%% Describe the metrics and its equations
%% Say something about visual inspection to judge the quality


\section{Descrição dos Dados}

Seção semelhante a do artigo submetido para o ifac. 

\subsubsection{Simulação}

\subsubsection{Dados Reais}

\section{Ensaio --- Construção dos Modelos Empíricos}

\textcolor{red}{Escrever introdução}

Testes sem o filtro de Kalman com AAKR e SVM. Verificar qualidade das predições.
Testes do AAKR com KF. Se possível, testar o SVM também, pelo menos para algumas
variáveis.
Testes com sinais filtrados (fácil para o caso de simulação).

\subsection{Dados de Simulação}

\subsubsection{AAKR}

O resultado do processo de otimização dos parâmetros do modelo AAKR é apresentado na
Fig.~\ref{fig:mse_aakr_sim}.
Modelos com valores altos de $h$ apresentaram grandes valores de MSE total, independente
da quantidade de vetores de memória, $n_m$.
Maiores valores de $n_m$ combinados com menores valores de $h$ tenderam a apresentar
modelos com menor MSE total.
Porém, apesar de não ser perceptível pela Fig.~\ref{fig:mse_aakr_sim}, para valores muito
pequenos de $h$ ocorreram leves acréscimos no MSE total, para todos as quantidades
$n_m$.
Para evitar \textit{overfitting} e o armazenamento de grandes quantidades de dados
desnecessariamente, escolheu-se $h = 0.1$ e $n_m = 600$ (20\% da quantidade amostras dos
dados de treinamento).

%Nota-se que modelos com menor MSE apresentam maior equilíbrio entre acurácia e
%capacidade de generalização, ou seja, são aqueles localizados entre modelos com pequena
%largura de banda e alta variância e modelos com largura de banda maiores e estimações
%polarizadas. Em relação ao tamanho da matriz de memória, matrizes maiores não implicam em
%menor MSE; a partir de um certo tamanho, a inclusão de mais vetores não aumenta a acurácia
%do modelo. Os parâmetros selecionados para a contrução do modelo final foram $h = $ e
% vetores de memória.

\begin{figure}[!htb]
    \centering
    \includegraphics[width=.7\textwidth]{figuras/mse_aakr_sim.eps}
    \caption{Relação entre o MSE total e diferentes valores de largura de banda $h$ e
    vetores de memória $n_m$ para o modelo AAKR aplicado aos dados de simulação para
otimização.}
    \label{fig:mse_aakr_sim}
\end{figure}

\subsubsection{SVM}

Os resultados da otimização dos parâmetros do modelo SVM são apresentados nas Tabelas
\ref{tab:svm_sim_v1}, \ref{tab:svm_sim_v2}, \ref{tab:svm_sim_v3} e \ref{tab:svm_sim_v4}.
Para cada valor de $\varepsilon$, os valores de $C$ e $\gamma$ são obtidos por busca em
grade, variando-se os valores em potências de 2.
Nota-se que o valor de $\varepsilon$ parece ser o principal determinante da quantidade de
vetores suporte armazenados pelo modelo.
Menores valores de $\varepsilon$ implicaram em maiores números de vetores suporte e
menores valores do MSE.
Entretanto, maior número de vetores suporte indicam modelos mais complexos, e modelos
excessivamente complexos tendem a incluir ruídos na modelagem.
Portanto, modelos com a mínima complexidade possível para se atingir valores de MSE
toleráveis são normalmente as melhores opções.

\begin{table}[!htb]
    \centering
    \caption{\label{tab:svm_sim_v1}Relação entre parâmetros do modelo SVM e o impacto no MSE na predição
da variável PT$_f$ dos dados de simulação.}
    \begin{tabular}{ccccc}
        \toprule
        $\varepsilon$ & $C$ & $\gamma$ & Vetores suporte & MSE ($\times 10^{-3}$)\\
        \midrule
        0.03 & 0.0625 & 2 & 813 & 0.752\\
        \rowcolor{gray}0.05 & 0.5 & 0.25 & 234 & 0.778 \\
        0.1 & 2 & 0.5 & 50 & 1.20 \\
        0.2 & 2 & 2 & 15 & 3.90 \\
        \bottomrule
    \end{tabular}
\end{table}



\begin{table}[!htb]
    \centering
    \caption{\label{tab:svm_sim_v2}Relação entre parâmetros do modelo SVM e o impacto no MSE na predição
da variável PT$_t$ dos dados de simulação.}
    \begin{tabular}{ccccc}
        \toprule
        $\varepsilon$ & $C$ & $\gamma$ & Vetores suporte & MSE ($\times 10^{-3}$)\\
        \midrule
        0.05 & 32 & 2 & 1149 & 2.974 \\
        \rowcolor{gray}0.1 & 1 & 8 & 246 & 2.991 \\
        0.15 & 0.5 & 2 & 36 & 3.125 \\
        0.2 & 4 & 0.125 & 7 & 3.408 \\
        \bottomrule
    \end{tabular}
\end{table}


\begin{table}[!htb]
    \centering
    \caption{\label{tab:svm_sim_v3}Relação entre parâmetros do modelo SVM e o impacto no MSE na predição
da variável PT$_m$ dos dados de simulação.}
    \begin{tabular}{ccccc}
        \toprule
        $\varepsilon$ & $C$ & $\gamma$ & Vetores suporte & MSE ($\times 10^{-3}$)\\
        \midrule
        0.05 & 0.25 & 16 & 1220 & 3.572 \\
        \rowcolor{gray}0.1 & 8 & 4 & 331 & 3.555 \\
        0.15 & 0.5 & 8 & 52 & 3.624 \\
        0.2 & 8 & 0.5 & 17 & 4.145 \\
        \bottomrule
    \end{tabular}
\end{table}


\begin{table}[!htb]
    \centering
    \caption{\label{tab:svm_sim_v4}Relação entre parâmetros do modelo SVM e o impacto no MSE na predição
da variável PT$_g$ dos dados de simulação.}
    \begin{tabular}{ccccc}
        \toprule
        $\varepsilon$ & $C$ & $\gamma$ & Vetores suporte & MSE ($\times 10^{-3}$) \\
        \midrule
        0.1 & 0.125 & 8 & 525 & 5.642 \\
        \rowcolor{gray}0.12 & 32 & 2 & 316 & 5.694 \\
        0.15 & 0.25 & 4 & 133 & 5.764 \\
        0.2 & 32 & 1 & 29 & 5.814 \\
        \bottomrule
    \end{tabular}
\end{table}

Os modelos selecionados para o sistema de validação estão destacados nas Tabelas
\ref{tab:svm_sim_v1}, \ref{tab:svm_sim_v2}, \ref{tab:svm_sim_v3} e \ref{tab:svm_sim_v4}.
Foram priorizados modelos cujo número de vetores suporte fosse próximo ao número de vetores
de memória do modelo AAKR, ou seja, próximo de 20\% do número de amostras do conjunto de
treinamento.



\subsection{Dados Reais}

\subsubsection{AAKR}

O resultado do processo de otimização dos parâmetros do modelo AAKR é apresentado na
Fig.~\ref{fig:mse_aakr_real}.
Para este conjunto de dados, menores valores de $h$ realmente geraram menores valores de
MSE total, exceto para quantidades $n_m$ muito pequenas.
Entretanto, modelos com $h < 0.07$ apresentaram problemas
numéricos para a predição dos dados de otimização, pois valores muito pequenos de
$h$ geram modelos com baixa capacidade de generalização, onde os denominadores da
Eq.~\ref{eq:aakr_var_pred} são muito próximos de zero.
Para diminuir a possibilidade de problemas numéricos por baixa capacidade de generalização
e ao mesmo tempo obter baixos valores de MSE total, adotou-se $h = 0.15$.
%Considerou-se $h = 0.15$ como um valor equilibrado entre acurácia e capacidade de
%generalização.
%Portanto, assim como ocorreu com os dados de simulação, 
%modelos com menor MSE apresentam maior equilíbrio entre acurácia e
%capacidade de generalização.

Em relação ao número de vetores de memória, foi escolhido $n_m = 4800$, que corresponde a
$20\%$ do conjunto de dados de treinamento. Maiores valores de $n_m$ apresentaram
impacto insignificante na redução do MSE (alterações a partir da quarta casa decimal).

\begin{figure}[!htb]
    \centering
    \includegraphics[width=.7\textwidth]{figuras/mse_aakr_real.eps}
    \caption{Relação entre o MSE total e diferentes valores de largura de banda $h$ e
    vetores de memória $n_m$ para o modelo AAKR aplicado aos dados reais para
otimização.}
    \label{fig:mse_aakr_real}
\end{figure}


\subsubsection{SVM}

Os resultados da otimização dos parâmetros do modelo SVM são apresentados nas Tabelas
\ref{tab:svm_real_v1}, \ref{tab:svm_real_v2} e \ref{tab:svm_real_v3}.
Para cada valor de $\varepsilon$, os valores de $C$ e $\gamma$ são obtidos por busca em
grade, variando-se os valores em potências de 2.
Nota-se que o comportamento dos modelos é semelhante para o conjunto de dados de
simulação: o valor de $\varepsilon$ apresenta-se como principal determinante do número de
vetores suporte e do limite inferior do MSE.
Os modelos selecionados para o sistema de validação estão destacados nas Tabelas
\ref{tab:svm_real_v1}, \ref{tab:svm_real_v2} e \ref{tab:svm_real_v3}.

\begin{table}[!htb]
    \centering
    \caption{\label{tab:svm_real_v1}Relação entre parâmetros do modelo SVM e o impacto no MSE na predição
do sensor PDG dos dados reais.}
    \begin{tabular}{ccccc}
        \toprule
        $\varepsilon$ & $C$ & $\gamma$ & Vetores suporte & MSE \\
        \midrule
        0.5 & 0.5 & 1 & 19621 & 7.19 \\
        0.8 & 32 & 0.25 & 17109 & 7.12 \\
        1 & 0.25 & 0.5 & 15886 & 6.97 \\
        \rowcolor{gray} 2 & 0.5 & 2 & 10662 & 7.00 \\
        5 & 0.25 & 2 & 2221 & 8.86 \\
        \bottomrule
    \end{tabular}
\end{table}

\begin{table}[!htb]
    \centering
    \caption{\label{tab:svm_real_v2}Relação entre parâmetros do modelo SVM e o impacto no
MSE na predição do sensor TPT dos dados reais.}
    \begin{tabular}{ccccc}
        \toprule
        $\varepsilon$ & $C$ & $\gamma$ & Vetores suporte & MSE \\
        \midrule
        0.8 & 0.03125 & 0.03125 & 16775 & 4.36 \\
        1.5 & 0.0625 & 0.5 & 10535 & 4.30 \\
        2 & 0.0625 & 0.5 & 6922 & 4.25 \\
        \rowcolor{gray}3 & 0.03125 & 0.5 & 3026 & 4.19 \\
        4 & 0.03125 & 0.25 & 1087 & 4.22 \\
        \bottomrule
    \end{tabular}
\end{table}

\begin{table}[!htb]
    \centering
    \caption{\label{tab:svm_real_v3}Relação entre parâmetros do modelo SVM e o impacto no
MSE na predição do sensor PT$_m$ dos dados reais.}
    \begin{tabular}{ccccc}
        \toprule
        $\varepsilon$ & $C$ & $\gamma$ & Vetores suporte & MSE \\
        \midrule
        0.1 & 0.03125 & 32 & 20834 & 0.48 \\
        0.5 & 0.03125 & 8 & 10117 & 0.47 \\
        \rowcolor{gray}1 & 0.015625 & 0.25 & 2852 & 0.50 \\
        2 & 128 & 0.125 & 143 & 0.80 \\
        \bottomrule
    \end{tabular}
\end{table}

% \subsubsection{Comentários}
% 
% Para ambas as técnicas, o processo de otimização dos modelos norteada pelo MSE foi
% fortemente influenciada pela largura de banda da função kernel.
% Nos modelos AAKR, o MSE
% total cresceu com o aumento dos valores de $h$, entretanto, valores muito pequenos
% ocasionaram problemas numéricos.
% Nos modelos SVM,
% 
% Não houve uma escolha automática das variáveis, usou-se senso de engenharia.


\section{Ensaio --- Verificação de Acurácia}

% Supondo que exista uma seção descrevendo os critérios de avaliação.


\subsection{Dados de Simulação}

\subsubsection{AAKR}

As predições do modelo AAKR para os dados de validação são apresentados na
Fig.~\ref{fig:pred_mse_sim_aakr}.
Nota-se que as predições correspondem à expectativa de serem bem similares aos valores
originados obtidos na simulação, uma vez que os dados não possuem falhas de sensores.
Os valores de MSE para as predições de cada variável do modelo são apresentados na
Tab.~\ref{tab:mse_aakr_sim}.

\begin{figure}[!htb]
    \centering
    \includegraphics[width=\textwidth]{figuras/pred_sim_aakr.eps}
    \caption{Predição do modelo AAKR para o conjunto de dados de validação gerados por
    simulação.}
    \label{fig:pred_mse_sim_aakr}
\end{figure}

\begin{table}[!htb]
    \centering
    \caption{\label{tab:mse_aakr_sim}Resultados do cálculo do MSE para as predições do
modelo AAKR para o conjunto de dados de validação gerados por simulação.}
    \begin{tabular}{ccccc}
        \toprule
        & PT$_f$ & PT$_t$ & PT$_m$ & PT$_g$ \\
        MSE & $1.0 \times 10^{-3}$ & $2.2 \times 10^{-3}$ & $2.4 \times 10^{-3}$ &
        $2.5 \times 10^{-3}$ \\
        \midrule
        MSE médio & \multicolumn{4}{l}{$2.0 \times 10^{-3}$} \\
        \bottomrule
    \end{tabular}
\end{table}

\subsubsection{SVM}

As predições dos modelos SVM para os dados de validação são apresentados na
Fig.~\ref{fig:pred_mse_sim_svm}.
Nota-se que as predições estão próximas dos valores originados pela simulação, uma
indicação visual da qualidade das predições do modelo.

\begin{figure}[!htb]
    \centering
    \includegraphics[width=\textwidth]{figuras/pred_sim_svm.eps}
    \caption{Predição do modelo SVM para o conjunto de dados de validação gerados por
    simulação.}
    \label{fig:pred_mse_sim_svm}
\end{figure}


Os valores de MSE para as predições de cada variável, ou modelo, são apresentados na
Tab.~\ref{tab:mse_svm_sim}.
Em comparação ao modelo AAKR, em geral as predições do modelo SVM apresentaram maior MSE,
ou seja, menor acurácia nas predições, exceto para a variável PT$_f$.


\begin{table}[!htb]
    \centering
    \caption{\label{tab:mse_svm_sim}Resultados do cálculo do MSE para as predições do
modelo SVM para o conjunto de dados de validação gerados por simulação.}
    \begin{tabular}{ccccc}
        \toprule
        & PT$_f$ & PT$_t$ & PT$_m$ & PT$_g$ \\
        MSE & $0.749 \times 10^{-3}$ & $3.392 \times 10^{-3}$ & $3.996 \times 10^{-3}$ &
        $5.621 \times 10^{-3}$ \\
        \midrule
        MSE médio & \multicolumn{4}{l}{$3.949 \times 10^{-3}$} \\
        \bottomrule
    \end{tabular}
\end{table}


\subsection{Dados Reais}

\subsubsection{AAKR}

As predições do modelo AAKR para os dados reais de validação são apresentados na
Fig.~\ref{fig:pred_mse_real_aakr}.
Nota-se que as predições apresentaram um comportamento mais suave que os sinais
verdadeiros e não acompanharam tão bem as mudanças bruscas de valores.
Tais características parecem corresponder ao agrupamento pobre de variáveis, uma vez que
o sistema sensoriado apresenta alta complexidade e não linearidade no relacionamento entre
as variáveis.
Para lidar com casos deste tipo, normalmente é necessário formar agrupamentos com maior
quantidade de variáveis correlacionadas ou, pelo menos, agrupar variáveis que apresentem
forte correlação.

Os valores de MSE para as predições de cada variável do modelo são apresentados na
Tab.~\ref{tab:mse_aakr_real}.

\begin{figure}[!htb]
    \centering
    \includegraphics[width=\textwidth]{figuras/pred_real_aakr.eps}
    \caption{Predição do modelo AAKR para o conjunto de dados reais de validação.}
    \label{fig:pred_mse_real_aakr}
\end{figure}

\begin{table}[!htb]
    \centering
    \caption{\label{tab:mse_aakr_real}Resultados do cálculo do MSE para as predições do
modelo AAKR para o conjunto de dados reais de validação.}
    \begin{tabular}{cccc}
        \toprule
        & PDG & TPT & PT$_m$ \\
        MSE & $7.9 \times 10^{-3}$ & $4.0 \times 10^{-3}$ & $2.3 \times 10^{-3}$\\
        \midrule
        MSE médio & \multicolumn{3}{l}{$4.7 \times 10^{-3}$} \\
        \bottomrule
    \end{tabular}
\end{table}

\subsubsection{SVM}


\section{Ensaio --- Análise de Sensibilidade e Detecção de \textit{Drifts}}

\subsection{Dados de Simulação}

\subsubsection{SVM}

\begin{table}[!htb]
    \centering
    \caption{\label{tab:cross_sens_svm_sim}Resultados do cálculo da sensibilidade cruzada
    dos modelos SVM para o conjunto de testes gerados por simulação.}
    \begin{tabular}{llccccc}
        \toprule
        & \multicolumn{5}{c}{Entradas com desvio} & \multirow{2}{*}{Média}\\
        & & PT$_f$ & PT$_t$ & PT$_m$ & PT$_g$ & \\
        \midrule
        \multirow{4}{*}{Saídas} & PT$_f$ & & 0.1415 & 0.2225 & 0.2079 & 0.1906\\
        & PT$_t$ & 1.5432 & & 0.5252 & 0.4385 & 0.8356 \\
        & PT$_m$ & 1.8827 & 0.6805 & & 0.5350 & 1.0327 \\
        & PT$_g$ & 3.4492 & 1.2468 & 1.1739 & & 1.9566 \\
        \bottomrule
    \end{tabular}
\end{table}


\subsection{Dados Reais}

\subsubsection{AAKR}

\subsubsection{SVM}


\section{Ensaio --- Detecção de Desvios}

\subsection{Dados de Simulação}

\subsubsection{AAKR}

\subsubsection{SVM}

\begin{table}[!htb]
    \centering
    \caption{\label{tab:sim_svm_sprtconf}Valores de mudança na média $M$ das variáveis do
modelo SVM aplicado aos dados de simulação.}
    \begin{tabular}{ccccc}
        \toprule
        & PT$_f$ & PT$_t$ & PT$_m$ & PT$_g$ \\
        \midrule
        $M$ & 0.2 & 0.4 &  &  \\
        \bottomrule        
    \end{tabular}
\end{table}

\subsection{Dados Reais}


\section{Ensaio --- Estimação de \textit{Drifts} com o KF}



% \textcolor{red}{Figura:} comportamento do mse para diferentes valores de bandwidth.
% 
% Pela análise dos resíduos gerados entre a predição do modelo selecionado e os dados de
% otimização, os parâmetros selecionados para o algoritmo SPRT foram:
% \textcolor{red}{variância}, $M = $, probabilidade de falso alarme igual a $1\%$ e
% probabilidade de alarmes perdidos igual a $10\%$.
% 
% \subsubsection{AAKR-KF-SPRT}
% 
% Como os parâmetros $h = ?$ e $n_m = ?$ geraram o modelo com o melhor balanço entre
% acurácia e capacidade de generalização para os dados de treinamento, tais valores também
% foram adotados para o modelo AAKR do sistema AAKR-KF-SPRT. A busca pelos melhores valores
% no espaço dos parâmetros $\mathbf{Q}$ e $\mathbf{V}$ do KF resultou nos valores
% $\mathbf{Q} = \mathbf{I} \; ?$ e $\mathbf{V} = \mathbf{I} \; ?$; a Figura ?? apresenta o
% comportamento do MSE para os diferentes valores dos parâmetros do KF.




\chapter{Conclusões}
\label{chap:conclusoes}

Revisão da importância do monitoramento de calibração.
Revisão da sistema implementado e sua relação com a estrutura OSA-CBM.
Revisão dos experimentos realizados e os resultados obtidos. Resumir as vantagens e
desvantagens da abordagem escolhida, analisar de forma crítica as contribuições da
dissertação.

Perspectivas de trabalhos futuros.
